{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Word Vectors and Sentiment Analysis\n",
    "CS 224D Assignment 1  \n",
    "Spring 2015\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://cs224d.stanford.edu/assignment1) on the course website.*\n",
    "\n",
    "In this assignment, we will walk you through the process of implementing \n",
    "\n",
    "- A softmax function\n",
    "- A simple neural network\n",
    "- Back propagation\n",
    "- Word2vec models\n",
    "\n",
    "and training your own word vectors with stochastic gradient descent (SGD) for a sentiment analysis task. Please make sure to finish the corresponding problems in the problem set PDF when instructed by the worksheet.\n",
    "\n",
    "The purpose of this assignment is to familiarize you with basic knowledge about neural networks and machine learning, including optimization and cross-validation, and help you gain proficiency in writing efficient, vectorized code.\n",
    "\n",
    "** Please don't add or remove any code cells, as it might break our automatic grading system and affect your grade. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Honor Code:** I hereby agree to abide the Stanford Honor Code and that of the Computer Science Department, promise that the submitted assignment is my own work, and understand that my code is subject to plagiarism test.\n",
    "\n",
    "**Signature**: *(double click on this block and type your name here)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook. Don't modify anything in this cell.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from cs224d.data_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Softmax\n",
    "*Please answer the first first complementary problem before starting this part.*\n",
    "\n",
    "Given an input matrix of *N* rows and *d* columns, compute the softmax prediction for each row. That is, when the input is\n",
    "\n",
    "    [[1,2],\n",
    "    [3,4]]\n",
    "    \n",
    "the output of your functions should be\n",
    "\n",
    "    [[0.2689, 0.7311],\n",
    "    [0.2689, 0.7311]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\" Softmax function \"\"\"\n",
    "    ###################################################################\n",
    "    # Compute the softmax function for the input here.                #\n",
    "    # It is crucial that this function is optimized for speed because #\n",
    "    # it will be used frequently in later code.                       #\n",
    "    # You might find numpy functions np.exp, np.sum, np.reshape,      #\n",
    "    # np.max, and numpy broadcasting useful for this task. (numpy     #\n",
    "    # broadcasting documentation:                                     #\n",
    "    # http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)  #\n",
    "    # You should also make sure that your code works for one          #\n",
    "    # dimensional inputs (treat the vector as a row), you might find  #\n",
    "    # it helpful for your later problems.                             #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    #if len(x.shape)<=1:\n",
    "    # get the max\n",
    "    mx = np.max(x, -1)\n",
    "    mx\n",
    "    # take exp\n",
    "    #x = np.exp(np.float64(x))\n",
    "    #x = np.maximum(1e-10, x)\n",
    "    #x[np.isinf(x)] = np.finfo('f64').max\n",
    "    #print np.isinf(x)\n",
    "\n",
    "    #vector\n",
    "    if len(x.shape)<=1:\n",
    "        x -= mx\n",
    "        x = np.exp(x)\n",
    "        x = x / np.sum(x)\n",
    "    else:\n",
    "        x -= mx[:,np.newaxis]\n",
    "        # take exp\n",
    "        x = np.exp(x)\n",
    "        # sum rows\n",
    "        y = np.sum(x, axis=1)\n",
    "        #print y\n",
    "        # divide each row by its sum\n",
    "        x = np.transpose(x.T / y)\n",
    "        \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "1.0\n",
      "[[ 0.26894142  0.73105858]\n",
      " [ 0.26894142  0.73105858]]\n",
      "[[ 0.73105858  0.26894142]]\n"
     ]
    }
   ],
   "source": [
    "# Verify your softmax implementation\n",
    "\n",
    "print \"=== For autograder ===\"\n",
    "print softmax(np.array(0.5))\n",
    "print softmax(np.array([[1001,1002],[3,4]]))\n",
    "print softmax(np.array([[-1001,-1002]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural network basics\n",
    "\n",
    "*Please answer the second complementary question before starting this part.*\n",
    "\n",
    "In this part, you're going to implement\n",
    "\n",
    "* A sigmoid activation function and its gradient\n",
    "* A forward propagation for a simple neural network with cross-entropy cost\n",
    "* A backward propagation algorithm to compute gradients for the parameters\n",
    "* Gradient / derivative check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\" Sigmoid function \"\"\"\n",
    "    ###################################################################\n",
    "    # Compute the sigmoid function for the input here.                #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    x = 1 / (1 + np.exp(-x))\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return x\n",
    "\n",
    "def sigmoid_grad(f):\n",
    "    \"\"\" Sigmoid gradient function \"\"\"\n",
    "    ###################################################################\n",
    "    # Compute the gradient for the sigmoid function here. Note that   #\n",
    "    # for this implementation, the input f should be the sigmoid      #\n",
    "    # function value of your original input x.                        #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    f = np.multiply(f, (1 - f))\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "[[ 0.73105858  0.88079708]\n",
      " [ 0.26894142  0.11920292]]\n",
      "[[ 0.19661193  0.10499359]\n",
      " [ 0.19661193  0.10499359]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.     ,  1.     ],\n",
       "       [ 0.50025,  0.5    ]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check your sigmoid implementation\n",
    "x = np.array([[1, 2], [-1, -2]])\n",
    "f = sigmoid(x)\n",
    "g = sigmoid_grad(f)\n",
    "print \"=== For autograder ===\"\n",
    "print f\n",
    "print g\n",
    "\n",
    "sigmoid(np.array([[1001, 1002], [0.001, 4E-10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the functions you just implemented, fill in the following functions to implement a neural network with one sigmoid hidden layer. You might find the handout and your answers to the second complementary problem helpful for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First implement a gradient checker by filling in the following functions\n",
    "def gradcheck_naive(f, x):\n",
    "    \"\"\" \n",
    "    Gradient check for a function f \n",
    "    - f should be a function that takes a single argument and outputs the cost and its gradients\n",
    "    - x is the point (numpy array) to check the gradient at\n",
    "    \"\"\" \n",
    "\n",
    "    rndstate = random.getstate()\n",
    "    random.setstate(rndstate)  \n",
    "    fx, grad = f(x) # Evaluate function value at original point\n",
    "    h = 1e-4\n",
    "\n",
    "    # Iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "    \n",
    "        #print ix\n",
    "        ### YOUR CODE HERE: try modifying x[ix] with h defined above to compute numerical gradients\n",
    "        ### make sure you call random.setstate(rndstate) before calling f(x) each time, this will make it \n",
    "        ### possible to test cost functions with built in randomness later\n",
    "        \n",
    "        # compute f(x[ix]+h)-f(x) / h for index ix and put in numgrad\n",
    "        x_h = x.copy()\n",
    "        random.setstate(rndstate)  \n",
    "        x_h[ix] += h\n",
    "        fx_h1, _ = f(x_h)\n",
    "        \n",
    "        x_h = x.copy()\n",
    "        x_h[ix] -= h\n",
    "        random.setstate(rndstate)  \n",
    "        fx_h2, _ = f(x_h)\n",
    "        numgrad = (fx_h1 - fx_h2) / (2*h)\n",
    "    \n",
    "        #return # replace this line with your code\n",
    "        ### END YOUR CODE\n",
    "\n",
    "        # Compare gradients\n",
    "        reldiff = abs(numgrad - grad[ix]) / max(1, abs(numgrad), abs(grad[ix]))\n",
    "        if reldiff > 1e-5:\n",
    "            print \"Gradient check failed.\"\n",
    "            print \"First gradient error found at index %s\" % str(ix)\n",
    "            print \"Your gradient: %f \\t Numerical gradient: %f\" % (grad[ix], numgrad)\n",
    "            return\n",
    "    \n",
    "        it.iternext() # Step to next dimension\n",
    "\n",
    "    print \"Gradient check passed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# Sanity check for the gradient checker\n",
    "quad = lambda x: (np.sum(x ** 2), x * 2)\n",
    "\n",
    "print \"=== For autograder ===\"\n",
    "gradcheck_naive(quad, np.array(123.456))      # scalar test\n",
    "gradcheck_naive(quad, np.random.randn(3,))    # 1-D test\n",
    "gradcheck_naive(quad, np.random.randn(4,5))   # 2-D test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up fake data and parameters for the neural network\n",
    "N = 20\n",
    "dimensions = [10, 5, 10]\n",
    "data = np.random.randn(N, dimensions[0])   # each row will be a datum\n",
    "labels = np.zeros((N, dimensions[2]), dtype='int32')\n",
    "for i in xrange(N):\n",
    "    labels[i,random.randint(0,dimensions[2]-1)] = 1\n",
    "\n",
    "params = np.random.randn((dimensions[0] + 1) * dimensions[1] + (dimensions[1] + 1) * dimensions[2], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malaa: Forward/Backward Propagation\n",
    "\n",
    "* The hidden layer $$h=sigmoid(x \\times W_1 + b_1) $$\n",
    "  \n",
    "\n",
    "* The output layer $$\\hat y = softmax(h \\times W_2 + b_2 )$$  \n",
    "  \n",
    "* Cost: Cross Entropy $$J = -\\sum_n \\sum_k y_{nk} \\log \\hat y_{nk} $$ where  \n",
    " * $y_{nk}$ is the ground truth probability vector (one-hot vector) where $y_{nk}=1$ only when input $n$ has label $k$\n",
    " * $\\hat y_{nk}$ is the prediction probability from the softmax function\n",
    "   \n",
    "* Gradients: \n",
    "  * Let $$a_1 = x \\times W_1 + b_1 \\implies h = sigmoid(a_1) $$ and $$a_2 = h \\times W_2 + b_2 \\implies \\hat y = softmax(a_2)$$\n",
    "  \n",
    "  * wrt $b_2$: $$\\nabla_{b_2} J = \\frac{\\partial J}{\\partial a_2} \\frac{\\partial a_2}{\\partial b_2} = \\sum_n \\left( \\hat y_{n} - y_n \\right) $$ (can derive the first part easily by differentiating $J$ w.r.t $a_2$)\n",
    "  \n",
    "  * Call $\\delta_{2,n} = \\hat y_n - y_n$  which is like the deviation from the desired output, then the gradient becomes  $$\\nabla_{b_2} J = \\sum_n \\delta_{2,n}$$ or equivalently call  $\\delta_2 = \\hat y - y$ and the gradient becomes $$\\nabla_{b_2} J = \\mathbf{1}^T \\delta_2$$ where $\\delta_2$ is now a matrix of size $N \\times dim[2]$ and $\\mathbf{1}$ is a vector of ones of size $N$ (which is the derivative of $a_2$ wrt $b_2$)  \n",
    "    \n",
    "  * Similarly $$\\nabla_{W_2} J = \\frac{\\partial J}{\\partial a_2} \\frac{\\partial a_2}{\\partial W_2} = \\sum_n \\left( \\hat y_{n} - y_n \\right) \\circ h = h^T \\times \\delta_2$$  \n",
    "    \n",
    "  * We can now propagate the gradients backward to the first layer by first computing $\\frac{\\partial J}{\\partial h}$ then using the partial derivatives of $h$ w.r.t $W_1$ and $b_1$\n",
    "  \n",
    "  * wrt $b_1$: $$\\nabla_{b_1} J = \\frac{\\partial J}{\\partial h} \\frac{\\partial h}{\\partial b_1} = \\delta_2 \\times W_2^T \\circ \\sigma'(h)= \\mathbf{1}^T \\times \\delta_1$$ where $$\\delta_1 = \\delta_2 \\times W_1^T \\circ \\sigma'(h)$$ where $\\circ$ is the element-wise multiplication\n",
    "  \n",
    "  * Similarlty w.r.t $W_1$ we have $$\\nabla_{W_1} J = x^T \\times \\delta_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward_backward_prop(data, labels, params):\n",
    "    \"\"\" Forward and backward propagation for a two-layer sigmoidal network \"\"\"\n",
    "    ###################################################################\n",
    "    # Compute the forward propagation and for the cross entropy cost, #\n",
    "    # and backward propagation for the gradients for all parameters.  #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### Unpack network parameters (do not modify)\n",
    "    t = 0\n",
    "    W1 = np.reshape(params[t:t+dimensions[0]*dimensions[1]], (dimensions[0], dimensions[1]))\n",
    "    t += dimensions[0]*dimensions[1]\n",
    "    b1 = np.reshape(params[t:t+dimensions[1]], (1, dimensions[1]))\n",
    "    t += dimensions[1]\n",
    "    W2 = np.reshape(params[t:t+dimensions[1]*dimensions[2]], (dimensions[1], dimensions[2]))\n",
    "    t += dimensions[1]*dimensions[2]\n",
    "    b2 = np.reshape(params[t:t+dimensions[2]], (1, dimensions[2]))\n",
    "    \n",
    "    ### YOUR CODE HERE: forward propagation\n",
    "    \n",
    "    # labels is N x dim[2] which is the ground truth one-hot vector we need to estimate\n",
    "    \n",
    "    # l is the label for each input datum\n",
    "    l = labels.argmax(axis=1)\n",
    "    assert len(l) == N\n",
    "    \n",
    "    # h is the output of hidden layer: N x dim[1]\n",
    "    h = sigmoid(data.dot(W1) + b1)\n",
    "    assert h.shape == (N, dimensions[1])\n",
    "    \n",
    "    # y_hat: Nxdim[2]\n",
    "    y_hat = softmax(h.dot(W2) + b2)     \n",
    "    assert y_hat.shape == (N, dimensions[2])\n",
    "    \n",
    "    # cost: sum the neg log of probability of correct label    \n",
    "    cost = -np.sum(np.log(y_hat[range(N),l]))\n",
    "    #print cost\n",
    "    # cost = -np.sum(np.log(np.multiply(y_hat, labels)))\n",
    "    #print cost\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    ### YOUR CODE HERE: backward propagation\n",
    "    \n",
    "    # y_hat - labels where labels is the one-hot vector\n",
    "    delta2 = y_hat - labels\n",
    "    assert delta2.shape == (N, dimensions[2])\n",
    "    \n",
    "    # 1 x dim[2]\n",
    "    gradb2 = np.sum(delta2, axis=0)    \n",
    "    assert gradb2.shape == (dimensions[2],)\n",
    "    # the same but multiplied by h.T: dim[1] x dim[2]\n",
    "    gradW2 = h.T.dot(delta2)\n",
    "    assert gradW2.shape == (dimensions[1], dimensions[2])\n",
    "    \n",
    "    # propagate delta2\n",
    "    delta1 = delta2.dot(W2.T) * sigmoid_grad(h)\n",
    "    assert delta1.shape == (N, dimensions[1])\n",
    "    \n",
    "    # 1 x dim[1]: delta1 .* sigmoid_grad(h)\n",
    "    gradb1 = np.sum(delta1, axis=0)\n",
    "    assert gradb1.shape == (dimensions[1],)\n",
    "    \n",
    "    # dim[0] x dim[1]\n",
    "    gradW1 = data.T.dot(delta1)\n",
    "    assert gradW1.shape == (dimensions[0],dimensions[1])\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    ### Stack gradients (do not modify)\n",
    "    grad = np.concatenate((gradW1.flatten(), gradb1.flatten(), gradW2.flatten(), gradb2.flatten()))\n",
    "    \n",
    "    return cost, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# Perform gradcheck on your neural network\n",
    "print \"=== For autograder ===\"\n",
    "gradcheck_naive(lambda params: forward_backward_prop(data, labels, params), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word2vec\n",
    "\n",
    "*Please answer the third complementary problem before starting this part.*\n",
    "\n",
    "In this part you will implement the `word2vec` models and train your own word vectors with stochastic gradient descent (SGD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malaa: SoftMax with Cross Entropy Loss\n",
    "\n",
    "* Loss: $CE(target)=-log(prob[target]) = - \\log{\\frac{\\exp(w_{target}^T pred)}{\\sum_j \\exp(w_j^T pred)}}=-w_{target}^T pred + \\log\\sum_j \\exp(w_j^T pred)$ where this loss is for input predicted and for the specific target word\n",
    "\n",
    "* Probability: $prob=softmax(outputVectors \\times predicted)$ where $outputVectors$ has rows as word vectors and predicted is a vector (or a row vector) where the probability is the softmax of the product of the word vectors and the predicted vector $\\hat r$\n",
    "\n",
    "* Cost: $cost=- \\log(prob[target])$\n",
    "\n",
    "* Gradient wrt predicted: $gradPred=\\nabla_{predicted}=-w_{target} + \\sum_k prob[k] w_k$ where $w_k$ is the vector for word $k$ i.e. the $k^th$ row in outputVectors\n",
    "\n",
    "* Gradient wrt $w_{target}$: $\\nabla_{w_{target}}=predicted \\times (prob[target] - 1)$\n",
    "\n",
    "* Gradient wrt $w_{k}$: $\\nabla_{w_{k}}=predicted \\times prob[k]$ where $k \\ne target$\n",
    "\n",
    "\n",
    "The gradient $grad$ is the same size as $outputVectors$ and has the gradient for each row in the respective row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement your skip-gram and CBOW models here\n",
    "\n",
    "# Interface to the dataset for negative sampling\n",
    "dataset = type('dummy', (), {})()\n",
    "def dummySampleTokenIdx():\n",
    "    return random.randint(0, 4)\n",
    "def getRandomContext(C):\n",
    "    tokens = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "    return tokens[random.randint(0,4)], [tokens[random.randint(0,4)] for i in xrange(2*C)]\n",
    "dataset.sampleTokenIdx = dummySampleTokenIdx\n",
    "dataset.getRandomContext = getRandomContext\n",
    "\n",
    "def softmaxCostAndGradient(predicted, target, outputVectors):\n",
    "    \"\"\" Softmax cost function for word2vec models \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement the cost and gradients for one predicted word vector  #\n",
    "    # and one target word vector as a building block for word2vec     #\n",
    "    # models, assuming the softmax prediction function and cross      #\n",
    "    # entropy loss.                                                   #\n",
    "    # Inputs:                                                         #\n",
    "    #   - predicted: numpy ndarray, predicted word vector (\\hat{r} in #\n",
    "    #           the written component)                                #\n",
    "    #   - target: integer, the index of the target word               #\n",
    "    #   - outputVectors: \"output\" vectors for all tokens              #\n",
    "    # Outputs:                                                        #\n",
    "    #   - cost: cross entropy cost for the softmax word prediction    #\n",
    "    #   - gradPred: the gradient with respect to the predicted word   #\n",
    "    #           vector                                                #\n",
    "    #   - grad: the gradient with respect to all the other word       # \n",
    "    #           vectors                                               #\n",
    "    # We will not provide starter code for this function, but feel    #\n",
    "    # free to reference the code you previously wrote for this        #\n",
    "    # assignment!                                                     #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    # probabilities of all words: predicted has row vectors for each word\n",
    "    prob = softmax(np.dot(outputVectors, predicted))\n",
    "    \n",
    "    # cost - log softmax of inner products\n",
    "    cost = -np.log(prob[target])\n",
    "    \n",
    "    # gradient wrt predicted\n",
    "    gradPred = np.sum(outputVectors.transpose() * prob, axis=1) - outputVectors[target,:]\n",
    "    \n",
    "    # gradient wrt outputVectors\n",
    "    grad = predicted[:,np.newaxis] * prob\n",
    "    grad[:,target] -= predicted\n",
    "    grad = grad.T        \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return cost, gradPred, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malaa: Negative Sampling with Sigmoid Loss\n",
    "\n",
    "* Loss: $cost=-\\log \\sigma(w_{target}^T predicted) - \\sum_k \\log \\sigma(-w_k^T predicted)$ which is the cost for one vector (predicted) and one target word $w_{target}$ and $\\sigma(\\cdot)$ is the sigmoid function\n",
    "\n",
    "* Gradient wrt predicted: $\\nabla_{predicted}=\\left( \\sigma(w_{target}^T predicted)-1 \\right) w_{target} - \\sum_k \\left(\\sigma(w_{k}^T predicted)-1 \\right) w_k$\n",
    "\n",
    "* Gradient wrt $w_{target}$: $\\nabla_{w_{target}} = \\left( \\sigma(w_{target}^T predicted)-1 \\right) predicted$\n",
    "\n",
    "* Gradient wrt $w_k$: $\\nabla_{w_k} = -\\left( \\sigma(w_{k}^T predicted)-1 \\right) predicted$\n",
    "\n",
    "The gradient $grad$ is the same size as $outputVectors$ and has the gradient for each row in the respective row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negSamplingCostAndGradient(predicted, target, outputVectors, K=10):\n",
    "    \"\"\" Negative sampling cost function for word2vec models \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement the cost and gradients for one predicted word vector  #\n",
    "    # and one target word vector as a building block for word2vec     #\n",
    "    # models, using the negative sampling technique. K is the sample  #\n",
    "    # size. You might want to use dataset.sampleTokenIdx() to sample  #\n",
    "    # a random word index.                                            #\n",
    "    # Input/Output Specifications: same as softmaxCostAndGradient     #\n",
    "    # We will not provide starter code for this function, but feel    #\n",
    "    # free to reference the code you previously wrote for this        #\n",
    "    # assignment!                                                     #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    # sample random indices\n",
    "    #idx = []\n",
    "    #while len(idx)<K:\n",
    "    #    ii = dataset.sampleTokenIdx()\n",
    "    #    if ii != target: idx.append(ii)\n",
    "    idx = [dataset.sampleTokenIdx() for i in range(K)]\n",
    "    #print idx\n",
    "    \n",
    "    # compute cost\n",
    "    sigTarget = sigmoid(np.dot(predicted, outputVectors[target,:].T))\n",
    "    sigNeg = sigmoid(np.dot(predicted, outputVectors[idx,:].T))\n",
    "    cost = - np.log(sigTarget) - np.sum(np.log(1 - sigNeg))\n",
    "        \n",
    "    # gradPred\n",
    "    gradPred = (sigTarget - 1.) * outputVectors[target,:]\n",
    "    gradPred += np.dot(sigNeg, outputVectors[idx,:])\n",
    "    #  np.sum(outputVectors[idx,:].T * (sigNeg.ravel() - 1), axis=1)\n",
    "\n",
    "    # grad\n",
    "    # for target\n",
    "    grad = np.zeros(outputVectors.shape)\n",
    "    grad[target,:] = predicted * (sigTarget - 1)\n",
    "    # for negative samples: loop and add contributions in case of repeated negative words\n",
    "    for (i,id) in enumerate(idx):\n",
    "        grad[id,:] += predicted * sigNeg[i]\n",
    "    # grad[idx,:] /= K\n",
    "    #grad[idx,:] += -predicted * (sigNeg - 1)\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return cost, gradPred, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def skipgram(currentWord, C, contextWords, tokens, inputVectors, outputVectors, \n",
    "             word2vecCostAndGradient = softmaxCostAndGradient):\n",
    "    \"\"\" Skip-gram model in word2vec \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement the skip-gram model in this function.                 #         \n",
    "    # Inputs:                                                         #\n",
    "    #   - currrentWord: a string of the current center word           #\n",
    "    #   - C: integer, context size                                    #\n",
    "    #   - contextWords: list of no more than 2*C strings, the context #\n",
    "    #             words                                               #\n",
    "    #   - tokens: a dictionary that maps words to their indices in    #\n",
    "    #             the word vector list                                #\n",
    "    #   - inputVectors: \"input\" word vectors for all tokens           #\n",
    "    #   - outputVectors: \"output\" word vectors for all tokens         #\n",
    "    #   - word2vecCostAndGradient: the cost and gradient function for #\n",
    "    #             a prediction vector given the target word vectors,  #\n",
    "    #             could be one of the two cost functions you          #\n",
    "    #             implemented above                                   #\n",
    "    # Outputs:                                                        #\n",
    "    #   - cost: the cost function value for the skip-gram model       #\n",
    "    #   - grad: the gradient with respect to the word vectors         #\n",
    "    # We will not provide starter code for this function, but feel    #\n",
    "    # free to reference the code you previously wrote for this        #\n",
    "    # assignment!                                                     #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    # init\n",
    "    cost= 0\n",
    "    gradIn = np.zeros(inputVectors.shape)\n",
    "    gradOut = np.zeros(outputVectors.shape)\n",
    "    \n",
    "    # predicted vector\n",
    "    predIdx = tokens[currentWord]\n",
    "    predicted = inputVectors[predIdx,:]    \n",
    "    \n",
    "    # loop on the context\n",
    "    for word in contextWords:\n",
    "        # get its id\n",
    "        target = tokens[word]\n",
    "        # Compute cost and gradient\n",
    "        cost_w, gradPred_w, grad_w = word2vecCostAndGradient(predicted, target, outputVectors)\n",
    "        # update cost and gradients\n",
    "        cost += cost_w\n",
    "        gradIn[predIdx,:] += gradPred_w\n",
    "        gradOut += grad_w\n",
    "    \n",
    "    # normalize by the number of context words\n",
    "    #cost /= 2 * C\n",
    "    #gradIn /= 2 * C\n",
    "    #gradOut /= 2 * C\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return cost, gradIn, gradOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cbow(currentWord, C, contextWords, tokens, inputVectors, outputVectors, word2vecCostAndGradient = softmaxCostAndGradient):\n",
    "    \"\"\" CBOW model in word2vec \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement the continuous bag-of-words model in this function.   #         \n",
    "    # Input/Output specifications: same as the skip-gram model        #\n",
    "    # We will not provide starter code for this function, but feel    #\n",
    "    # free to reference the code you previously wrote for this        #\n",
    "    # assignment!                                                     #\n",
    "    ###################################################################\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    # init\n",
    "    gradIn = np.zeros(inputVectors.shape)\n",
    "    gradOut = np.zeros(outputVectors.shape)\n",
    "    \n",
    "    # predicted vector: loop over context and average\n",
    "    predIdx = [tokens[w] for w in contextWords]\n",
    "    predicted = np.sum(inputVectors[predIdx,:], axis=0)\n",
    "    \n",
    "    # target\n",
    "    target = tokens[currentWord]\n",
    "    \n",
    "    # Compute cost and gradient\n",
    "    cost, gradPred, grad = word2vecCostAndGradient(predicted, target, outputVectors)\n",
    "    \n",
    "    # update gradOut\n",
    "    gradOut = grad\n",
    "    \n",
    "    # update gradIn: loop on context and add the gradient to the respective input vectors\n",
    "    for idx in predIdx:\n",
    "        gradIn[idx,:] += gradPred\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return cost, gradIn, gradOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "[[ 0.6         0.8       ]\n",
      " [ 0.4472136   0.89442719]]\n"
     ]
    }
   ],
   "source": [
    "# Implement a function that normalizes each row of a matrix to have unit length\n",
    "def normalizeRows(x):\n",
    "    \"\"\" Row normalization function \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    # get sum of each row squared\n",
    "    s = np.sum(np.power(x, 2), axis=1)\n",
    "    # divide\n",
    "    x = (x.transpose() / np.sqrt(s)).transpose()\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Test this function\n",
    "print \"=== For autograder ===\"\n",
    "print normalizeRows(np.array([[3.0,4.0],[1, 2]]))  # the result should be [[0.6, 0.8], [0.4472, 0.8944]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Gradient check for skip-gram ====\n",
      "== Softmax ==\n",
      "Gradient check passed!\n",
      "== Negative Sampling ==\n",
      "Gradient check passed!\n",
      "\n",
      "==== Gradient check for CBOW      ====\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "\n",
      "=== For autograder ===\n",
      "(11.166109001533981, array([[ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [-1.26947339, -1.36873189,  2.45158957],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[-0.41045956,  0.18834851,  1.43272264],\n",
      "       [ 0.38202831, -0.17530219, -1.33348241],\n",
      "       [ 0.07009355, -0.03216399, -0.24466386],\n",
      "       [ 0.09472154, -0.04346509, -0.33062865],\n",
      "       [-0.13638384,  0.06258276,  0.47605228]]))\n",
      "(14.095272649623695, array([[ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [-3.40325278, -2.74731195, -0.95360761],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[-0.49853822,  0.22876535,  1.74016407],\n",
      "       [-0.22716495,  0.10423969,  0.79292674],\n",
      "       [-0.22764219,  0.10445868,  0.79459256],\n",
      "       [-0.94807832,  0.43504684,  3.30929863],\n",
      "       [-0.32248118,  0.14797767,  1.1256312 ]]))\n",
      "(0.79899580109066481, array([[ 0.23330542, -0.51643128, -0.8281311 ],\n",
      "       [ 0.11665271, -0.25821564, -0.41406555],\n",
      "       [ 0.11665271, -0.25821564, -0.41406555],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[ 0.80954933,  0.21962514, -0.54095764],\n",
      "       [-0.03556575, -0.00964874,  0.02376577],\n",
      "       [-0.13016109, -0.0353118 ,  0.08697634],\n",
      "       [-0.1650812 , -0.04478539,  0.11031068],\n",
      "       [-0.47874129, -0.1298792 ,  0.31990485]]))\n",
      "(12.312796216098874, array([[-5.99665734, -4.85531835,  2.30742523],\n",
      "       [-2.99832867, -2.42765918,  1.15371261],\n",
      "       [-2.99832867, -2.42765918,  1.15371261],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ]]), array([[-3.53424992, -0.95881757,  2.36165904],\n",
      "       [-0.68912523, -0.18695491,  0.46048776],\n",
      "       [ 0.        ,  0.        ,  0.        ],\n",
      "       [-2.58955401, -0.7025281 ,  1.73039366],\n",
      "       [-2.36749007, -0.64228369,  1.58200593]]))\n"
     ]
    }
   ],
   "source": [
    "# Gradient check!\n",
    "\n",
    "def word2vec_sgd_wrapper(word2vecModel, tokens, wordVectors, dataset, C, word2vecCostAndGradient = softmaxCostAndGradient):\n",
    "    batchsize = 50\n",
    "    cost = 0.0\n",
    "    grad = np.zeros(wordVectors.shape)\n",
    "    N = wordVectors.shape[0]\n",
    "    inputVectors = wordVectors[:N/2,:]\n",
    "    outputVectors = wordVectors[N/2:,:]\n",
    "    for i in xrange(batchsize):\n",
    "        C1 = random.randint(1,C)\n",
    "        centerword, context = dataset.getRandomContext(C1)\n",
    "        #print centerword, context\n",
    "        \n",
    "        if word2vecModel == skipgram:\n",
    "            denom = 1\n",
    "        else:\n",
    "            denom = 1\n",
    "        \n",
    "        c, gin, gout = word2vecModel(centerword, C1, context, tokens, inputVectors, outputVectors, word2vecCostAndGradient)\n",
    "        cost += c / batchsize / denom\n",
    "        grad[:N/2, :] += gin / batchsize / denom\n",
    "        grad[N/2:, :] += gout / batchsize / denom\n",
    "        \n",
    "    return cost, grad\n",
    "\n",
    "random.seed(31415)\n",
    "np.random.seed(9265)\n",
    "dummy_vectors = normalizeRows(np.random.randn(10,3))\n",
    "dummy_tokens = dict([(\"a\",0), (\"b\",1), (\"c\",2),(\"d\",3),(\"e\",4)])\n",
    "print \"==== Gradient check for skip-gram ====\"\n",
    "print \"== Softmax ==\"\n",
    "gradcheck_naive(lambda vec: word2vec_sgd_wrapper(skipgram, dummy_tokens, vec, dataset, 5), dummy_vectors)\n",
    "print \"== Negative Sampling ==\"\n",
    "gradcheck_naive(lambda vec: word2vec_sgd_wrapper(skipgram, dummy_tokens, vec, dataset, 5, negSamplingCostAndGradient), dummy_vectors)\n",
    "print \"\\n==== Gradient check for CBOW      ====\"\n",
    "gradcheck_naive(lambda vec: word2vec_sgd_wrapper(cbow, dummy_tokens, vec, dataset, 5), dummy_vectors)\n",
    "gradcheck_naive(lambda vec: word2vec_sgd_wrapper(cbow, dummy_tokens, vec, dataset, 5, negSamplingCostAndGradient), dummy_vectors)\n",
    "\n",
    "print \"\\n=== For autograder ===\"\n",
    "print skipgram(\"c\", 3, [\"a\", \"b\", \"e\", \"d\", \"b\", \"c\"], dummy_tokens, dummy_vectors[:5,:], dummy_vectors[5:,:])\n",
    "print skipgram(\"c\", 1, [\"a\", \"b\"], dummy_tokens, dummy_vectors[:5,:], dummy_vectors[5:,:], negSamplingCostAndGradient)\n",
    "print cbow(\"a\", 2, [\"a\", \"b\", \"c\", \"a\"], dummy_tokens, dummy_vectors[:5,:], dummy_vectors[5:,:])\n",
    "print cbow(\"a\", 2, [\"a\", \"b\", \"a\", \"c\"], dummy_tokens, dummy_vectors[:5,:], dummy_vectors[5:,:], negSamplingCostAndGradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, implement SGD\n",
    "\n",
    "# Save parameters every a few SGD iterations as fail-safe\n",
    "SAVE_PARAMS_EVERY = 1000\n",
    "\n",
    "import glob\n",
    "import os.path as op\n",
    "import cPickle as pickle\n",
    "\n",
    "def load_saved_params():\n",
    "    \"\"\" A helper function that loads previously saved parameters and resets iteration start \"\"\"\n",
    "    st = 0\n",
    "    for f in glob.glob(\"saved_params_*.npy\"):\n",
    "        iter = int(op.splitext(op.basename(f))[0].split(\"_\")[2])\n",
    "        if (iter > st):\n",
    "            st = iter\n",
    "            \n",
    "    if st > 0:\n",
    "        with open(\"saved_params_%d.npy\" % st, \"r\") as f:\n",
    "            params = pickle.load(f)\n",
    "            state = pickle.load(f)\n",
    "        return st, params, state\n",
    "    else:\n",
    "        return st, None, None\n",
    "    \n",
    "def save_params(iter, params):\n",
    "    with open(\"saved_params_%d.npy\" % iter, \"w\") as f:\n",
    "        pickle.dump(params, f)\n",
    "        pickle.dump(random.getstate(), f)\n",
    "\n",
    "def sgd(f, x0, step, iterations, postprocessing = None, useSaved = False, PRINT_EVERY=10):\n",
    "    \"\"\" Stochastic Gradient Descent \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement the stochastic gradient descent method in this        #\n",
    "    # function.                                                       #\n",
    "    # Inputs:                                                         #\n",
    "    #   - f: the function to optimize, it should take a single        #\n",
    "    #        argument and yield two outputs, a cost and the gradient  #\n",
    "    #        with respect to the arguments                            #\n",
    "    #   - x0: the initial point to start SGD from                     #\n",
    "    #   - step: the step size for SGD                                 #\n",
    "    #   - iterations: total iterations to run SGD for                 #\n",
    "    #   - postprocessing: postprocessing function for the parameters  #\n",
    "    #        if necessary. In the case of word2vec we will need to    #\n",
    "    #        normalize the word vectors to have unit length.          #\n",
    "    #   - PRINT_EVERY: specifies every how many iterations to output  #\n",
    "    # Output:                                                         #\n",
    "    #   - x: the parameter value after SGD finishes                   #\n",
    "    ###################################################################\n",
    "    \n",
    "    # Anneal learning rate every several iterations\n",
    "    ANNEAL_EVERY = 20000\n",
    "    \n",
    "    if useSaved:\n",
    "        start_iter, oldx, state = load_saved_params()\n",
    "        if start_iter > 0:\n",
    "            x0 = oldx;\n",
    "            step *= 0.5 ** (start_iter / ANNEAL_EVERY)\n",
    "            \n",
    "        if state:\n",
    "            random.setstate(state)\n",
    "    else:\n",
    "        start_iter = 0\n",
    "    \n",
    "    x = x0\n",
    "    \n",
    "    if not postprocessing:\n",
    "        postprocessing = lambda x: x\n",
    "    \n",
    "    expcost = None\n",
    "    \n",
    "    for iter in xrange(start_iter + 1, iterations + 1):\n",
    "        ### YOUR CODE HERE\n",
    "        ### Don't forget to apply the postprocessing after every iteration!\n",
    "        ### You might want to print the progress every few iterations.\n",
    "        \n",
    "        # get cost and gradient\n",
    "        cost, grad = f(x)\n",
    "        # update x\n",
    "        x -= step * grad\n",
    "        # post process\n",
    "        x = postprocessing(x)\n",
    "        \n",
    "        if iter % PRINT_EVERY == 0:\n",
    "            print \"Iteration %d - cost=%f\" % (iter, cost)\n",
    "        \n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        if iter % SAVE_PARAMS_EVERY == 0 and useSaved:\n",
    "            save_params(iter, x)\n",
    "            \n",
    "        if iter % ANNEAL_EVERY == 0:\n",
    "            step *= 0.5\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show time! Now we are going to load some real data and train word vectors with everything you just implemented!**\n",
    "\n",
    "We are going to use the Stanford Sentiment Treebank (SST) dataset to train word vectors, and later apply them to a simple sentiment analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load some data and initialize word vectors\n",
    "\n",
    "# Reset the random seed to make sure that everyone gets the same results\n",
    "random.seed(314)\n",
    "dataset = StanfordSentiment()\n",
    "tokens = dataset.tokens()\n",
    "nWords = len(tokens)\n",
    "\n",
    "# We are going to train 10-dimensional vectors for this assignment\n",
    "dimVectors = 10\n",
    "\n",
    "# Context size\n",
    "C = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 - cost=21.806413\n",
      "Iteration 20 - cost=19.518996\n",
      "Iteration 30 - cost=22.263893\n",
      "Iteration 40 - cost=22.721356\n",
      "Iteration 50 - cost=20.281477\n",
      "Iteration 60 - cost=22.721414\n",
      "Iteration 70 - cost=25.923869\n",
      "Iteration 80 - cost=22.111376\n",
      "Iteration 90 - cost=20.586438\n",
      "Iteration 100 - cost=21.653991\n",
      "Iteration 110 - cost=23.178767\n",
      "Iteration 120 - cost=20.739011\n",
      "Iteration 130 - cost=20.891506\n",
      "Iteration 140 - cost=23.026215\n",
      "Iteration 150 - cost=19.366580\n",
      "Iteration 160 - cost=24.093890\n",
      "Iteration 170 - cost=19.061503\n",
      "Iteration 180 - cost=21.043972\n",
      "Iteration 190 - cost=21.043703\n",
      "Iteration 200 - cost=23.636347\n",
      "Iteration 210 - cost=24.856342\n",
      "Iteration 220 - cost=22.568710\n",
      "Iteration 230 - cost=23.178767\n",
      "Iteration 240 - cost=21.348876\n",
      "Iteration 250 - cost=20.128810\n",
      "Iteration 260 - cost=23.483836\n",
      "Iteration 270 - cost=20.281477\n",
      "Iteration 280 - cost=22.416179\n",
      "Iteration 290 - cost=18.451684\n",
      "Iteration 300 - cost=19.061477\n",
      "Iteration 310 - cost=23.331408\n",
      "Iteration 320 - cost=21.501294\n",
      "Iteration 330 - cost=20.739001\n",
      "Iteration 340 - cost=19.366637\n",
      "Iteration 350 - cost=21.501381\n",
      "Iteration 360 - cost=23.026626\n",
      "Iteration 370 - cost=19.976374\n",
      "Iteration 380 - cost=19.976967\n",
      "Iteration 390 - cost=19.824046\n",
      "Iteration 400 - cost=19.213927\n",
      "Iteration 410 - cost=22.568253\n",
      "Iteration 420 - cost=19.366470\n",
      "Iteration 430 - cost=23.026699\n",
      "Iteration 440 - cost=19.976292\n",
      "Iteration 450 - cost=22.111391\n",
      "Iteration 460 - cost=23.483755\n",
      "Iteration 470 - cost=20.738623\n",
      "Iteration 480 - cost=27.753014\n",
      "Iteration 490 - cost=23.026196\n",
      "Iteration 500 - cost=23.026902\n",
      "Iteration 510 - cost=19.823766\n",
      "Iteration 520 - cost=22.568318\n",
      "Iteration 530 - cost=19.823175\n",
      "Iteration 540 - cost=20.738561\n",
      "Iteration 550 - cost=24.399233\n",
      "Iteration 560 - cost=21.958886\n",
      "Iteration 570 - cost=21.958802\n",
      "Iteration 580 - cost=23.788469\n",
      "Iteration 590 - cost=19.214500\n",
      "Iteration 600 - cost=24.093840\n",
      "Iteration 610 - cost=21.348788\n",
      "Iteration 620 - cost=22.111618\n",
      "Iteration 630 - cost=19.823842\n",
      "Iteration 640 - cost=19.975564\n",
      "Iteration 650 - cost=21.349128\n",
      "Iteration 660 - cost=20.586372\n",
      "Iteration 670 - cost=21.654066\n",
      "Iteration 680 - cost=23.788720\n",
      "Iteration 690 - cost=21.349076\n",
      "Iteration 700 - cost=22.568522\n",
      "Iteration 710 - cost=20.281109\n",
      "Iteration 720 - cost=21.348021\n",
      "Iteration 730 - cost=22.568715\n",
      "Iteration 740 - cost=23.178047\n",
      "Iteration 750 - cost=19.213504\n",
      "Iteration 760 - cost=24.398175\n",
      "Iteration 770 - cost=21.958769\n",
      "Iteration 780 - cost=20.890936\n",
      "Iteration 790 - cost=19.671124\n",
      "Iteration 800 - cost=22.110734\n",
      "Iteration 810 - cost=26.380596\n",
      "Iteration 820 - cost=24.398029\n",
      "Iteration 830 - cost=23.025164\n",
      "Iteration 840 - cost=21.653711\n",
      "Iteration 850 - cost=19.060986\n",
      "Iteration 860 - cost=25.008547\n",
      "Iteration 870 - cost=18.603425\n",
      "Iteration 880 - cost=21.653117\n",
      "Iteration 890 - cost=21.652058\n",
      "Iteration 900 - cost=19.670102\n",
      "Iteration 910 - cost=22.414543\n",
      "Iteration 920 - cost=22.413522\n",
      "Iteration 930 - cost=22.569346\n",
      "Iteration 940 - cost=23.177984\n",
      "Iteration 950 - cost=21.499079\n",
      "Iteration 960 - cost=25.616343\n",
      "Iteration 970 - cost=21.653200\n",
      "Iteration 980 - cost=22.415465\n",
      "Iteration 990 - cost=24.702493\n",
      "Iteration 1000 - cost=22.111778\n",
      "Iteration 1010 - cost=18.602629\n",
      "Iteration 1020 - cost=27.294981\n",
      "Iteration 1030 - cost=23.026395\n",
      "Iteration 1040 - cost=19.214284\n",
      "Iteration 1050 - cost=19.365637\n",
      "Iteration 1060 - cost=25.158354\n",
      "Iteration 1070 - cost=21.803662\n",
      "Iteration 1080 - cost=20.125568\n",
      "Iteration 1090 - cost=22.569995\n",
      "Iteration 1100 - cost=21.651920\n",
      "Iteration 1110 - cost=24.398356\n",
      "Iteration 1120 - cost=19.821407\n",
      "Iteration 1130 - cost=19.974137\n",
      "Iteration 1140 - cost=19.364061\n",
      "Iteration 1150 - cost=19.821682\n",
      "Iteration 1160 - cost=21.804639\n",
      "Iteration 1170 - cost=20.736919\n",
      "Iteration 1180 - cost=18.145886\n",
      "Iteration 1190 - cost=18.756355\n",
      "Iteration 1200 - cost=22.413936\n",
      "Iteration 1210 - cost=20.431195\n",
      "Iteration 1220 - cost=23.025448\n",
      "Iteration 1230 - cost=21.499386\n",
      "Iteration 1240 - cost=25.613404\n",
      "Iteration 1250 - cost=20.583810\n",
      "Iteration 1260 - cost=21.654949\n",
      "Iteration 1270 - cost=24.849441\n",
      "Iteration 1280 - cost=24.244626\n",
      "Iteration 1290 - cost=19.060344\n",
      "Iteration 1300 - cost=26.682993\n",
      "Iteration 1310 - cost=18.448995\n",
      "Iteration 1320 - cost=20.735738\n",
      "Iteration 1330 - cost=24.851841\n",
      "Iteration 1340 - cost=25.310123\n",
      "Iteration 1350 - cost=22.716561\n",
      "Iteration 1360 - cost=22.720242\n",
      "Iteration 1370 - cost=22.718576\n",
      "Iteration 1380 - cost=19.822646\n",
      "Iteration 1390 - cost=22.869244\n",
      "Iteration 1400 - cost=21.036414\n",
      "Iteration 1410 - cost=23.011801\n",
      "Iteration 1420 - cost=23.788188\n",
      "Iteration 1430 - cost=23.165526\n",
      "Iteration 1440 - cost=23.173318\n",
      "Iteration 1450 - cost=26.527876\n",
      "Iteration 1460 - cost=20.579489\n",
      "Iteration 1470 - cost=21.187918\n",
      "Iteration 1480 - cost=19.670997\n",
      "Iteration 1490 - cost=22.553664\n",
      "Iteration 1500 - cost=22.712037\n",
      "Iteration 1510 - cost=20.875473\n",
      "Iteration 1520 - cost=22.098879\n",
      "Iteration 1530 - cost=19.809852\n",
      "Iteration 1540 - cost=21.027504\n",
      "Iteration 1550 - cost=18.905105\n",
      "Iteration 1560 - cost=19.817476\n",
      "Iteration 1570 - cost=22.095063\n",
      "Iteration 1580 - cost=22.711626\n",
      "Iteration 1590 - cost=23.165404\n",
      "Iteration 1600 - cost=22.860651\n",
      "Iteration 1610 - cost=20.875380\n",
      "Iteration 1620 - cost=19.813642\n",
      "Iteration 1630 - cost=20.717962\n",
      "Iteration 1640 - cost=20.582333\n",
      "Iteration 1650 - cost=20.409911\n",
      "Iteration 1660 - cost=18.601153\n",
      "Iteration 1670 - cost=19.939307\n",
      "Iteration 1680 - cost=24.837007\n",
      "Iteration 1690 - cost=20.108333\n",
      "Iteration 1700 - cost=21.487232\n",
      "Iteration 1710 - cost=22.836217\n",
      "Iteration 1720 - cost=21.788947\n",
      "Iteration 1730 - cost=19.352227\n",
      "Iteration 1740 - cost=20.108714\n",
      "Iteration 1750 - cost=20.265570\n",
      "Iteration 1760 - cost=22.686841\n",
      "Iteration 1770 - cost=22.700971\n",
      "Iteration 1780 - cost=22.853133\n",
      "Iteration 1790 - cost=20.106031\n",
      "Iteration 1800 - cost=21.330662\n",
      "Iteration 1810 - cost=20.708501\n",
      "Iteration 1820 - cost=23.898665\n",
      "Iteration 1830 - cost=18.429252\n",
      "Iteration 1840 - cost=21.021793\n",
      "Iteration 1850 - cost=21.461399\n",
      "Iteration 1860 - cost=23.127789\n",
      "Iteration 1870 - cost=24.360852\n",
      "Iteration 1880 - cost=21.009743\n",
      "Iteration 1890 - cost=23.164148\n",
      "Iteration 1900 - cost=22.252014\n",
      "Iteration 1910 - cost=23.847736\n",
      "Iteration 1920 - cost=16.881066\n",
      "Iteration 1930 - cost=19.333521\n",
      "Iteration 1940 - cost=23.900666\n",
      "Iteration 1950 - cost=22.520012\n",
      "Iteration 1960 - cost=19.185642\n",
      "Iteration 1970 - cost=21.300215\n",
      "Iteration 1980 - cost=20.495616\n",
      "Iteration 1990 - cost=21.136524\n",
      "Iteration 2000 - cost=22.963392\n",
      "Iteration 2010 - cost=20.199718\n",
      "Iteration 2020 - cost=23.141344\n",
      "Iteration 2030 - cost=23.693145\n",
      "Iteration 2040 - cost=23.974299\n",
      "Iteration 2050 - cost=20.390211\n",
      "Iteration 2060 - cost=20.315663\n",
      "Iteration 2070 - cost=22.755687\n",
      "Iteration 2080 - cost=22.056143\n",
      "Iteration 2090 - cost=22.296379\n",
      "Iteration 2100 - cost=20.467019\n",
      "Iteration 2110 - cost=21.845705\n",
      "Iteration 2120 - cost=23.961635\n",
      "Iteration 2130 - cost=22.147197\n",
      "Iteration 2140 - cost=26.039776\n",
      "Iteration 2150 - cost=22.598138\n",
      "Iteration 2160 - cost=22.000841\n",
      "Iteration 2170 - cost=21.697927\n",
      "Iteration 2180 - cost=20.879973\n",
      "Iteration 2190 - cost=23.321014\n",
      "Iteration 2200 - cost=24.209590\n",
      "Iteration 2210 - cost=22.310742\n",
      "Iteration 2220 - cost=23.926943\n",
      "Iteration 2230 - cost=21.669307\n",
      "Iteration 2240 - cost=21.675647\n",
      "Iteration 2250 - cost=20.619473\n",
      "Iteration 2260 - cost=19.832502\n",
      "Iteration 2270 - cost=21.852148\n",
      "Iteration 2280 - cost=24.093888\n",
      "Iteration 2290 - cost=18.647228\n",
      "Iteration 2300 - cost=20.409617\n",
      "Iteration 2310 - cost=22.517730\n",
      "Iteration 2320 - cost=23.192281\n",
      "Iteration 2330 - cost=22.555278\n",
      "Iteration 2340 - cost=20.076201\n",
      "Iteration 2350 - cost=20.723465\n",
      "Iteration 2360 - cost=19.589986\n",
      "Iteration 2370 - cost=22.183744\n",
      "Iteration 2380 - cost=21.086439\n",
      "Iteration 2390 - cost=22.114087\n",
      "Iteration 2400 - cost=17.713713\n",
      "Iteration 2410 - cost=22.229270\n",
      "Iteration 2420 - cost=22.398248\n",
      "Iteration 2430 - cost=19.759787\n",
      "Iteration 2440 - cost=23.105233\n",
      "Iteration 2450 - cost=21.931904\n",
      "Iteration 2460 - cost=19.202802\n",
      "Iteration 2470 - cost=23.731604\n",
      "Iteration 2480 - cost=22.516192\n",
      "Iteration 2490 - cost=20.770672\n",
      "Iteration 2500 - cost=23.363332\n",
      "Iteration 2510 - cost=22.999102\n",
      "Iteration 2520 - cost=23.053634\n",
      "Iteration 2530 - cost=24.721213\n",
      "Iteration 2540 - cost=24.006309\n",
      "Iteration 2550 - cost=20.963100\n",
      "Iteration 2560 - cost=22.572776\n",
      "Iteration 2570 - cost=21.000046\n",
      "Iteration 2580 - cost=25.725787\n",
      "Iteration 2590 - cost=23.779421\n",
      "Iteration 2600 - cost=21.772166\n",
      "Iteration 2610 - cost=21.341293\n",
      "Iteration 2620 - cost=24.900910\n",
      "Iteration 2630 - cost=20.911950\n",
      "Iteration 2640 - cost=20.583281\n",
      "Iteration 2650 - cost=21.726711\n",
      "Iteration 2660 - cost=20.421864\n",
      "Iteration 2670 - cost=22.144739\n",
      "Iteration 2680 - cost=23.307344\n",
      "Iteration 2690 - cost=22.746721\n",
      "Iteration 2700 - cost=22.273922\n",
      "Iteration 2710 - cost=23.587877\n",
      "Iteration 2720 - cost=22.333679\n",
      "Iteration 2730 - cost=21.601743\n",
      "Iteration 2740 - cost=18.193400\n",
      "Iteration 2750 - cost=18.671388\n",
      "Iteration 2760 - cost=22.507650\n",
      "Iteration 2770 - cost=21.803570\n",
      "Iteration 2780 - cost=22.834571\n",
      "Iteration 2790 - cost=20.462322\n",
      "Iteration 2800 - cost=21.421348\n",
      "Iteration 2810 - cost=19.485235\n",
      "Iteration 2820 - cost=22.888219\n",
      "Iteration 2830 - cost=18.620445\n",
      "Iteration 2840 - cost=19.008720\n",
      "Iteration 2850 - cost=18.073567\n",
      "Iteration 2860 - cost=21.543010\n",
      "Iteration 2870 - cost=17.719043\n",
      "Iteration 2880 - cost=21.596430\n",
      "Iteration 2890 - cost=21.177654\n",
      "Iteration 2900 - cost=20.247657\n",
      "Iteration 2910 - cost=20.719724\n",
      "Iteration 2920 - cost=19.547639\n",
      "Iteration 2930 - cost=20.278730\n",
      "Iteration 2940 - cost=21.441755\n",
      "Iteration 2950 - cost=20.670340\n",
      "Iteration 2960 - cost=21.047471\n",
      "Iteration 2970 - cost=22.461629\n",
      "Iteration 2980 - cost=24.572806\n",
      "Iteration 2990 - cost=22.345783\n",
      "Iteration 3000 - cost=19.894412\n",
      "Iteration 3010 - cost=22.844129\n",
      "Iteration 3020 - cost=21.312354\n",
      "Iteration 3030 - cost=19.190129\n",
      "Iteration 3040 - cost=23.108406\n",
      "Iteration 3050 - cost=22.234764\n",
      "Iteration 3060 - cost=21.532473\n",
      "Iteration 3070 - cost=19.942244\n",
      "Iteration 3080 - cost=24.254995\n",
      "Iteration 3090 - cost=24.204609\n",
      "Iteration 3100 - cost=22.011974\n",
      "Iteration 3110 - cost=22.184300\n",
      "Iteration 3120 - cost=18.436894\n",
      "Iteration 3130 - cost=23.871920\n",
      "Iteration 3140 - cost=20.687697\n",
      "Iteration 3150 - cost=21.408869\n",
      "Iteration 3160 - cost=20.074683\n",
      "Iteration 3170 - cost=19.606370\n",
      "Iteration 3180 - cost=20.380931\n",
      "Iteration 3190 - cost=20.120976\n",
      "Iteration 3200 - cost=20.621322\n",
      "Iteration 3210 - cost=21.228585\n",
      "Iteration 3220 - cost=22.152373\n",
      "Iteration 3230 - cost=20.565440\n",
      "Iteration 3240 - cost=19.527303\n",
      "Iteration 3250 - cost=18.268232\n",
      "Iteration 3260 - cost=20.116232\n",
      "Iteration 3270 - cost=20.039831\n",
      "Iteration 3280 - cost=18.346121\n",
      "Iteration 3290 - cost=18.671737\n",
      "Iteration 3300 - cost=19.074610\n",
      "Iteration 3310 - cost=22.341476\n",
      "Iteration 3320 - cost=23.961102\n",
      "Iteration 3330 - cost=18.112554\n",
      "Iteration 3340 - cost=20.264251\n",
      "Iteration 3350 - cost=19.847666\n",
      "Iteration 3360 - cost=20.262888\n",
      "Iteration 3370 - cost=18.779401\n",
      "Iteration 3380 - cost=17.830316\n",
      "Iteration 3390 - cost=22.559994\n",
      "Iteration 3400 - cost=18.176296\n",
      "Iteration 3410 - cost=18.351997\n",
      "Iteration 3420 - cost=20.743042\n",
      "Iteration 3430 - cost=20.133669\n",
      "Iteration 3440 - cost=17.427549\n",
      "Iteration 3450 - cost=22.075852\n",
      "Iteration 3460 - cost=18.691948\n",
      "Iteration 3470 - cost=19.777657\n",
      "Iteration 3480 - cost=21.058524\n",
      "Iteration 3490 - cost=18.311034\n",
      "Iteration 3500 - cost=16.305100\n",
      "Iteration 3510 - cost=17.996241\n",
      "Iteration 3520 - cost=19.617440\n",
      "Iteration 3530 - cost=17.045808\n",
      "Iteration 3540 - cost=20.230199\n",
      "Iteration 3550 - cost=22.072756\n",
      "Iteration 3560 - cost=19.222627\n",
      "Iteration 3570 - cost=16.855582\n",
      "Iteration 3580 - cost=20.167007\n",
      "Iteration 3590 - cost=17.322592\n",
      "Iteration 3600 - cost=19.286341\n",
      "Iteration 3610 - cost=19.699212\n",
      "Iteration 3620 - cost=21.022862\n",
      "Iteration 3630 - cost=16.183520\n",
      "Iteration 3640 - cost=16.602891\n",
      "Iteration 3650 - cost=19.019447\n",
      "Iteration 3660 - cost=16.582034\n",
      "Iteration 3670 - cost=19.108584\n",
      "Iteration 3680 - cost=22.571009\n",
      "Iteration 3690 - cost=19.263175\n",
      "Iteration 3700 - cost=19.148073\n",
      "Iteration 3710 - cost=19.690659\n",
      "Iteration 3720 - cost=20.974547\n",
      "Iteration 3730 - cost=18.778955\n",
      "Iteration 3740 - cost=20.277206\n",
      "Iteration 3750 - cost=19.721136\n",
      "Iteration 3760 - cost=20.164786\n",
      "Iteration 3770 - cost=21.130225\n",
      "Iteration 3780 - cost=22.759541\n",
      "Iteration 3790 - cost=21.563948\n",
      "Iteration 3800 - cost=20.442957\n",
      "Iteration 3810 - cost=19.018490\n",
      "Iteration 3820 - cost=20.862633\n",
      "Iteration 3830 - cost=20.015148\n",
      "Iteration 3840 - cost=23.272233\n",
      "Iteration 3850 - cost=19.856975\n",
      "Iteration 3860 - cost=19.039586\n",
      "Iteration 3870 - cost=21.492842\n",
      "Iteration 3880 - cost=18.715403\n",
      "Iteration 3890 - cost=18.504667\n",
      "Iteration 3900 - cost=21.007857\n",
      "Iteration 3910 - cost=19.264836\n",
      "Iteration 3920 - cost=23.445824\n",
      "Iteration 3930 - cost=17.454341\n",
      "Iteration 3940 - cost=18.847309\n",
      "Iteration 3950 - cost=20.669239\n",
      "Iteration 3960 - cost=17.705166\n",
      "Iteration 3970 - cost=19.354581\n",
      "Iteration 3980 - cost=19.171099\n",
      "Iteration 3990 - cost=20.764988\n",
      "Iteration 4000 - cost=18.921735\n",
      "Iteration 4010 - cost=19.205116\n",
      "Iteration 4020 - cost=20.634042\n",
      "Iteration 4030 - cost=18.800317\n",
      "Iteration 4040 - cost=20.377690\n",
      "Iteration 4050 - cost=19.336072\n",
      "Iteration 4060 - cost=17.457325\n",
      "Iteration 4070 - cost=20.912925\n",
      "Iteration 4080 - cost=18.047841\n",
      "Iteration 4090 - cost=17.632717\n",
      "Iteration 4100 - cost=15.972298\n",
      "Iteration 4110 - cost=22.267752\n",
      "Iteration 4120 - cost=19.045845\n",
      "Iteration 4130 - cost=20.263960\n",
      "Iteration 4140 - cost=18.444026\n",
      "Iteration 4150 - cost=22.875518\n",
      "Iteration 4160 - cost=19.466385\n",
      "Iteration 4170 - cost=18.307807\n",
      "Iteration 4180 - cost=17.364021\n",
      "Iteration 4190 - cost=17.345446\n",
      "Iteration 4200 - cost=17.947020\n",
      "Iteration 4210 - cost=19.918964\n",
      "Iteration 4220 - cost=19.595971\n",
      "Iteration 4230 - cost=18.509781\n",
      "Iteration 4240 - cost=17.947840\n",
      "Iteration 4250 - cost=22.747775\n",
      "Iteration 4260 - cost=17.989502\n",
      "Iteration 4270 - cost=17.010168\n",
      "Iteration 4280 - cost=17.064973\n",
      "Iteration 4290 - cost=19.092583\n",
      "Iteration 4300 - cost=17.723217\n",
      "Iteration 4310 - cost=17.196070\n",
      "Iteration 4320 - cost=17.437225\n",
      "Iteration 4330 - cost=18.807134\n",
      "Iteration 4340 - cost=17.156378\n",
      "Iteration 4350 - cost=19.898047\n",
      "Iteration 4360 - cost=18.207059\n",
      "Iteration 4370 - cost=18.527216\n",
      "Iteration 4380 - cost=21.006210\n",
      "Iteration 4390 - cost=17.629631\n",
      "Iteration 4400 - cost=19.180622\n",
      "Iteration 4410 - cost=19.643325\n",
      "Iteration 4420 - cost=19.588715\n",
      "Iteration 4430 - cost=20.847813\n",
      "Iteration 4440 - cost=17.473650\n",
      "Iteration 4450 - cost=17.355011\n",
      "Iteration 4460 - cost=19.015112\n",
      "Iteration 4470 - cost=19.901615\n",
      "Iteration 4480 - cost=19.360218\n",
      "Iteration 4490 - cost=17.449811\n",
      "Iteration 4500 - cost=17.197128\n",
      "Iteration 4510 - cost=17.917470\n",
      "Iteration 4520 - cost=18.094089\n",
      "Iteration 4530 - cost=21.781464\n",
      "Iteration 4540 - cost=16.668672\n",
      "Iteration 4550 - cost=16.214842\n",
      "Iteration 4560 - cost=18.105412\n",
      "Iteration 4570 - cost=17.844504\n",
      "Iteration 4580 - cost=15.758425\n",
      "Iteration 4590 - cost=16.127026\n",
      "Iteration 4600 - cost=16.860011\n",
      "Iteration 4610 - cost=17.771310\n",
      "Iteration 4620 - cost=17.853615\n",
      "Iteration 4630 - cost=17.870135\n",
      "Iteration 4640 - cost=17.258849\n",
      "Iteration 4650 - cost=18.969568\n",
      "Iteration 4660 - cost=17.295973\n",
      "Iteration 4670 - cost=16.438984\n",
      "Iteration 4680 - cost=17.966241\n",
      "Iteration 4690 - cost=16.933009\n",
      "Iteration 4700 - cost=18.488081\n",
      "Iteration 4710 - cost=18.247181\n",
      "Iteration 4720 - cost=17.165296\n",
      "Iteration 4730 - cost=20.066577\n",
      "Iteration 4740 - cost=18.975840\n",
      "Iteration 4750 - cost=17.994088\n",
      "Iteration 4760 - cost=17.429257\n",
      "Iteration 4770 - cost=16.680746\n",
      "Iteration 4780 - cost=18.453248\n",
      "Iteration 4790 - cost=20.218219\n",
      "Iteration 4800 - cost=16.992773\n",
      "Iteration 4810 - cost=16.115403\n",
      "Iteration 4820 - cost=16.724035\n",
      "Iteration 4830 - cost=19.522652\n",
      "Iteration 4840 - cost=17.812003\n",
      "Iteration 4850 - cost=15.701413\n",
      "Iteration 4860 - cost=18.412765\n",
      "Iteration 4870 - cost=18.210787\n",
      "Iteration 4880 - cost=17.374538\n",
      "Iteration 4890 - cost=19.555512\n",
      "Iteration 4900 - cost=18.109727\n",
      "Iteration 4910 - cost=16.422941\n",
      "Iteration 4920 - cost=16.314538\n",
      "Iteration 4930 - cost=16.817846\n",
      "Iteration 4940 - cost=16.991055\n",
      "Iteration 4950 - cost=19.140908\n",
      "Iteration 4960 - cost=17.948296\n",
      "Iteration 4970 - cost=17.586701\n",
      "Iteration 4980 - cost=16.547707\n",
      "Iteration 4990 - cost=17.312289\n",
      "Iteration 5000 - cost=14.694793\n",
      "Iteration 5010 - cost=16.925931\n",
      "Iteration 5020 - cost=16.683452\n",
      "Iteration 5030 - cost=19.058920\n",
      "Iteration 5040 - cost=16.135871\n",
      "Iteration 5050 - cost=15.613861\n",
      "Iteration 5060 - cost=17.108154\n",
      "Iteration 5070 - cost=15.968607\n",
      "Iteration 5080 - cost=17.700770\n",
      "Iteration 5090 - cost=17.586692\n",
      "Iteration 5100 - cost=17.158362\n",
      "Iteration 5110 - cost=20.817820\n",
      "Iteration 5120 - cost=16.262347\n",
      "Iteration 5130 - cost=18.171426\n",
      "Iteration 5140 - cost=19.629668\n",
      "Iteration 5150 - cost=14.918109\n",
      "Iteration 5160 - cost=15.266086\n",
      "Iteration 5170 - cost=17.413421\n",
      "Iteration 5180 - cost=19.604513\n",
      "Iteration 5190 - cost=17.778421\n",
      "Iteration 5200 - cost=17.694229\n",
      "Iteration 5210 - cost=17.965336\n",
      "Iteration 5220 - cost=17.938234\n",
      "Iteration 5230 - cost=17.569603\n",
      "Iteration 5240 - cost=17.975711\n",
      "Iteration 5250 - cost=15.132272\n",
      "Iteration 5260 - cost=14.751981\n",
      "Iteration 5270 - cost=16.564565\n",
      "Iteration 5280 - cost=17.120471\n",
      "Iteration 5290 - cost=18.273367\n",
      "Iteration 5300 - cost=16.923763\n",
      "Iteration 5310 - cost=19.937909\n",
      "Iteration 5320 - cost=16.623255\n",
      "Iteration 5330 - cost=17.752971\n",
      "Iteration 5340 - cost=15.426546\n",
      "Iteration 5350 - cost=16.240603\n",
      "Iteration 5360 - cost=16.890468\n",
      "Iteration 5370 - cost=19.908725\n",
      "Iteration 5380 - cost=16.302990\n",
      "Iteration 5390 - cost=17.827998\n",
      "Iteration 5400 - cost=15.394559\n",
      "Iteration 5410 - cost=16.467932\n",
      "Iteration 5420 - cost=16.801409\n",
      "Iteration 5430 - cost=16.093256\n",
      "Iteration 5440 - cost=16.882977\n",
      "Iteration 5450 - cost=16.289978\n",
      "Iteration 5460 - cost=14.683098\n",
      "Iteration 5470 - cost=18.180239\n",
      "Iteration 5480 - cost=17.826449\n",
      "Iteration 5490 - cost=13.827157\n",
      "Iteration 5500 - cost=17.068378\n",
      "Iteration 5510 - cost=16.131797\n",
      "Iteration 5520 - cost=13.477419\n",
      "Iteration 5530 - cost=19.892569\n",
      "Iteration 5540 - cost=13.702061\n",
      "Iteration 5550 - cost=15.947689\n",
      "Iteration 5560 - cost=19.215939\n",
      "Iteration 5570 - cost=15.414871\n",
      "Iteration 5580 - cost=17.419935\n",
      "Iteration 5590 - cost=15.753505\n",
      "Iteration 5600 - cost=17.635525\n",
      "Iteration 5610 - cost=15.390064\n",
      "Iteration 5620 - cost=16.249917\n",
      "Iteration 5630 - cost=16.619768\n",
      "Iteration 5640 - cost=16.958674\n",
      "Iteration 5650 - cost=20.160689\n",
      "Iteration 5660 - cost=16.535334\n",
      "Iteration 5670 - cost=15.825511\n",
      "Iteration 5680 - cost=15.973730\n",
      "Iteration 5690 - cost=15.480676\n",
      "Iteration 5700 - cost=18.162590\n",
      "Iteration 5710 - cost=16.162891\n",
      "Iteration 5720 - cost=16.312540\n",
      "Iteration 5730 - cost=19.046560\n",
      "Iteration 5740 - cost=16.089496\n",
      "Iteration 5750 - cost=14.441241\n",
      "Iteration 5760 - cost=15.974581\n",
      "Iteration 5770 - cost=14.423127\n",
      "Iteration 5780 - cost=17.555501\n",
      "Iteration 5790 - cost=16.821578\n",
      "Iteration 5800 - cost=13.890879\n",
      "Iteration 5810 - cost=17.789917\n",
      "Iteration 5820 - cost=17.034761\n",
      "Iteration 5830 - cost=15.460590\n",
      "Iteration 5840 - cost=17.324799\n",
      "Iteration 5850 - cost=17.640429\n",
      "Iteration 5860 - cost=15.975177\n",
      "Iteration 5870 - cost=15.762402\n",
      "Iteration 5880 - cost=16.521487\n",
      "Iteration 5890 - cost=16.695302\n",
      "Iteration 5900 - cost=15.950952\n",
      "Iteration 5910 - cost=18.539518\n",
      "Iteration 5920 - cost=18.189529\n",
      "Iteration 5930 - cost=16.472868\n",
      "Iteration 5940 - cost=15.104281\n",
      "Iteration 5950 - cost=14.214496\n",
      "Iteration 5960 - cost=13.736812\n",
      "Iteration 5970 - cost=14.090604\n",
      "Iteration 5980 - cost=17.052351\n",
      "Iteration 5990 - cost=15.344178\n",
      "Iteration 6000 - cost=14.261920\n",
      "Iteration 6010 - cost=14.819205\n",
      "Iteration 6020 - cost=15.746568\n",
      "Iteration 6030 - cost=15.441236\n",
      "Iteration 6040 - cost=15.460578\n",
      "Iteration 6050 - cost=15.107451\n",
      "Iteration 6060 - cost=15.848926\n",
      "Iteration 6070 - cost=15.809843\n",
      "Iteration 6080 - cost=18.331330\n",
      "Iteration 6090 - cost=14.496720\n",
      "Iteration 6100 - cost=16.794948\n",
      "Iteration 6110 - cost=13.543537\n",
      "Iteration 6120 - cost=14.877287\n",
      "Iteration 6130 - cost=16.103186\n",
      "Iteration 6140 - cost=16.676014\n",
      "Iteration 6150 - cost=13.836315\n",
      "Iteration 6160 - cost=15.843359\n",
      "Iteration 6170 - cost=14.154119\n",
      "Iteration 6180 - cost=17.499226\n",
      "Iteration 6190 - cost=14.941917\n",
      "Iteration 6200 - cost=15.985186\n",
      "Iteration 6210 - cost=14.241281\n",
      "Iteration 6220 - cost=19.309695\n",
      "Iteration 6230 - cost=15.065847\n",
      "Iteration 6240 - cost=16.155221\n",
      "Iteration 6250 - cost=16.384393\n",
      "Iteration 6260 - cost=15.747067\n",
      "Iteration 6270 - cost=14.622756\n",
      "Iteration 6280 - cost=13.621270\n",
      "Iteration 6290 - cost=15.594325\n",
      "Iteration 6300 - cost=14.601660\n",
      "Iteration 6310 - cost=15.690295\n",
      "Iteration 6320 - cost=16.251884\n",
      "Iteration 6330 - cost=15.740192\n",
      "Iteration 6340 - cost=17.333726\n",
      "Iteration 6350 - cost=15.304124\n",
      "Iteration 6360 - cost=15.113092\n",
      "Iteration 6370 - cost=14.174141\n",
      "Iteration 6380 - cost=15.237411\n",
      "Iteration 6390 - cost=16.889924\n",
      "Iteration 6400 - cost=16.138212\n",
      "Iteration 6410 - cost=16.688215\n",
      "Iteration 6420 - cost=14.016533\n",
      "Iteration 6430 - cost=13.163977\n",
      "Iteration 6440 - cost=17.749902\n",
      "Iteration 6450 - cost=15.492443\n",
      "Iteration 6460 - cost=15.796690\n",
      "Iteration 6470 - cost=15.243492\n",
      "Iteration 6480 - cost=14.264819\n",
      "Iteration 6490 - cost=15.847073\n",
      "Iteration 6500 - cost=16.969346\n",
      "Iteration 6510 - cost=15.878248\n",
      "Iteration 6520 - cost=15.695757\n",
      "Iteration 6530 - cost=16.178443\n",
      "Iteration 6540 - cost=16.079163\n",
      "Iteration 6550 - cost=15.913430\n",
      "Iteration 6560 - cost=15.501567\n",
      "Iteration 6570 - cost=16.296902\n",
      "Iteration 6580 - cost=14.168927\n",
      "Iteration 6590 - cost=15.553861\n",
      "Iteration 6600 - cost=14.744057\n",
      "Iteration 6610 - cost=16.403744\n",
      "Iteration 6620 - cost=14.683002\n",
      "Iteration 6630 - cost=14.442937\n",
      "Iteration 6640 - cost=14.853056\n",
      "Iteration 6650 - cost=14.577833\n",
      "Iteration 6660 - cost=15.934389\n",
      "Iteration 6670 - cost=14.793355\n",
      "Iteration 6680 - cost=16.545435\n",
      "Iteration 6690 - cost=14.731917\n",
      "Iteration 6700 - cost=15.689112\n",
      "Iteration 6710 - cost=13.844280\n",
      "Iteration 6720 - cost=13.036644\n",
      "Iteration 6730 - cost=16.949444\n",
      "Iteration 6740 - cost=14.634582\n",
      "Iteration 6750 - cost=16.313130\n",
      "Iteration 6760 - cost=15.744664\n",
      "Iteration 6770 - cost=14.571733\n",
      "Iteration 6780 - cost=14.217781\n",
      "Iteration 6790 - cost=14.861844\n",
      "Iteration 6800 - cost=16.329662\n",
      "Iteration 6810 - cost=14.500206\n",
      "Iteration 6820 - cost=12.870170\n",
      "Iteration 6830 - cost=14.553260\n",
      "Iteration 6840 - cost=16.625643\n",
      "Iteration 6850 - cost=15.971645\n",
      "Iteration 6860 - cost=15.876171\n",
      "Iteration 6870 - cost=15.417797\n",
      "Iteration 6880 - cost=12.562421\n",
      "Iteration 6890 - cost=15.541234\n",
      "Iteration 6900 - cost=14.335506\n",
      "Iteration 6910 - cost=14.171630\n",
      "Iteration 6920 - cost=13.108727\n",
      "Iteration 6930 - cost=15.531748\n",
      "Iteration 6940 - cost=17.742772\n",
      "Iteration 6950 - cost=15.910484\n",
      "Iteration 6960 - cost=13.074960\n",
      "Iteration 6970 - cost=16.597759\n",
      "Iteration 6980 - cost=13.911425\n",
      "Iteration 6990 - cost=14.488203\n",
      "Iteration 7000 - cost=14.597730\n",
      "Iteration 7010 - cost=14.347488\n",
      "Iteration 7020 - cost=15.609406\n",
      "Iteration 7030 - cost=14.617415\n",
      "Iteration 7040 - cost=15.415017\n",
      "Iteration 7050 - cost=15.478223\n",
      "Iteration 7060 - cost=15.899066\n",
      "Iteration 7070 - cost=12.664875\n",
      "Iteration 7080 - cost=17.044694\n",
      "Iteration 7090 - cost=14.647058\n",
      "Iteration 7100 - cost=16.579352\n",
      "Iteration 7110 - cost=15.733931\n",
      "Iteration 7120 - cost=14.172713\n",
      "Iteration 7130 - cost=17.223111\n",
      "Iteration 7140 - cost=15.543231\n",
      "Iteration 7150 - cost=14.884968\n",
      "Iteration 7160 - cost=15.985133\n",
      "Iteration 7170 - cost=14.368788\n",
      "Iteration 7180 - cost=15.137814\n",
      "Iteration 7190 - cost=16.845244\n",
      "Iteration 7200 - cost=15.739036\n",
      "Iteration 7210 - cost=13.759812\n",
      "Iteration 7220 - cost=13.506234\n",
      "Iteration 7230 - cost=15.123880\n",
      "Iteration 7240 - cost=17.170342\n",
      "Iteration 7250 - cost=13.243747\n",
      "Iteration 7260 - cost=13.010578\n",
      "Iteration 7270 - cost=13.732088\n",
      "Iteration 7280 - cost=14.815699\n",
      "Iteration 7290 - cost=15.083782\n",
      "Iteration 7300 - cost=14.991094\n",
      "Iteration 7310 - cost=14.008217\n",
      "Iteration 7320 - cost=15.184132\n",
      "Iteration 7330 - cost=15.330974\n",
      "Iteration 7340 - cost=13.470436\n",
      "Iteration 7350 - cost=13.328531\n",
      "Iteration 7360 - cost=16.238189\n",
      "Iteration 7370 - cost=15.762999\n",
      "Iteration 7380 - cost=11.321713\n",
      "Iteration 7390 - cost=14.951161\n",
      "Iteration 7400 - cost=14.229935\n",
      "Iteration 7410 - cost=16.594064\n",
      "Iteration 7420 - cost=15.434603\n",
      "Iteration 7430 - cost=13.580193\n",
      "Iteration 7440 - cost=13.206236\n",
      "Iteration 7450 - cost=16.043904\n",
      "Iteration 7460 - cost=17.546834\n",
      "Iteration 7470 - cost=15.266033\n",
      "Iteration 7480 - cost=14.650362\n",
      "Iteration 7490 - cost=16.002127\n",
      "Iteration 7500 - cost=12.243114\n",
      "Iteration 7510 - cost=13.409624\n",
      "Iteration 7520 - cost=14.832522\n",
      "Iteration 7530 - cost=15.539664\n",
      "Iteration 7540 - cost=12.324055\n",
      "Iteration 7550 - cost=14.626129\n",
      "Iteration 7560 - cost=13.365624\n",
      "Iteration 7570 - cost=16.098651\n",
      "Iteration 7580 - cost=14.463780\n",
      "Iteration 7590 - cost=13.686772\n",
      "Iteration 7600 - cost=14.709859\n",
      "Iteration 7610 - cost=13.825397\n",
      "Iteration 7620 - cost=14.562266\n",
      "Iteration 7630 - cost=14.532610\n",
      "Iteration 7640 - cost=12.443887\n",
      "Iteration 7650 - cost=13.588961\n",
      "Iteration 7660 - cost=15.618629\n",
      "Iteration 7670 - cost=14.771681\n",
      "Iteration 7680 - cost=14.125451\n",
      "Iteration 7690 - cost=12.591991\n",
      "Iteration 7700 - cost=13.149483\n",
      "Iteration 7710 - cost=13.899070\n",
      "Iteration 7720 - cost=13.933858\n",
      "Iteration 7730 - cost=14.031916\n",
      "Iteration 7740 - cost=15.047836\n",
      "Iteration 7750 - cost=16.576792\n",
      "Iteration 7760 - cost=13.164645\n",
      "Iteration 7770 - cost=14.180383\n",
      "Iteration 7780 - cost=14.994514\n",
      "Iteration 7790 - cost=15.921152\n",
      "Iteration 7800 - cost=12.905185\n",
      "Iteration 7810 - cost=13.302462\n",
      "Iteration 7820 - cost=13.508181\n",
      "Iteration 7830 - cost=10.709150\n",
      "Iteration 7840 - cost=16.391736\n",
      "Iteration 7850 - cost=14.157857\n",
      "Iteration 7860 - cost=14.337820\n",
      "Iteration 7870 - cost=12.572090\n",
      "Iteration 7880 - cost=12.953854\n",
      "Iteration 7890 - cost=13.195714\n",
      "Iteration 7900 - cost=15.170749\n",
      "Iteration 7910 - cost=13.287553\n",
      "Iteration 7920 - cost=15.202649\n",
      "Iteration 7930 - cost=13.970366\n",
      "Iteration 7940 - cost=14.447991\n",
      "Iteration 7950 - cost=13.413054\n",
      "Iteration 7960 - cost=15.615971\n",
      "Iteration 7970 - cost=13.205910\n",
      "Iteration 7980 - cost=13.181150\n",
      "Iteration 7990 - cost=15.375224\n",
      "Iteration 8000 - cost=16.615532\n",
      "Iteration 8010 - cost=10.926411\n",
      "Iteration 8020 - cost=13.778522\n",
      "Iteration 8030 - cost=14.900529\n",
      "Iteration 8040 - cost=13.547740\n",
      "Iteration 8050 - cost=14.303906\n",
      "Iteration 8060 - cost=13.071337\n",
      "Iteration 8070 - cost=14.467160\n",
      "Iteration 8080 - cost=14.561636\n",
      "Iteration 8090 - cost=14.595721\n",
      "Iteration 8100 - cost=14.336197\n",
      "Iteration 8110 - cost=13.794091\n",
      "Iteration 8120 - cost=14.609088\n",
      "Iteration 8130 - cost=13.912100\n",
      "Iteration 8140 - cost=12.601117\n",
      "Iteration 8150 - cost=12.745880\n",
      "Iteration 8160 - cost=15.567507\n",
      "Iteration 8170 - cost=15.015384\n",
      "Iteration 8180 - cost=13.796104\n",
      "Iteration 8190 - cost=14.359790\n",
      "Iteration 8200 - cost=15.798486\n",
      "Iteration 8210 - cost=14.356944\n",
      "Iteration 8220 - cost=11.311188\n",
      "Iteration 8230 - cost=13.817299\n",
      "Iteration 8240 - cost=12.930007\n",
      "Iteration 8250 - cost=13.334804\n",
      "Iteration 8260 - cost=11.852247\n",
      "Iteration 8270 - cost=15.606690\n",
      "Iteration 8280 - cost=13.362103\n",
      "Iteration 8290 - cost=14.314989\n",
      "Iteration 8300 - cost=13.148695\n",
      "Iteration 8310 - cost=13.092014\n",
      "Iteration 8320 - cost=15.046873\n",
      "Iteration 8330 - cost=13.197951\n",
      "Iteration 8340 - cost=14.300829\n",
      "Iteration 8350 - cost=12.097601\n",
      "Iteration 8360 - cost=15.721397\n",
      "Iteration 8370 - cost=11.241792\n",
      "Iteration 8380 - cost=14.338213\n",
      "Iteration 8390 - cost=11.969546\n",
      "Iteration 8400 - cost=13.640187\n",
      "Iteration 8410 - cost=15.880232\n",
      "Iteration 8420 - cost=14.846911\n",
      "Iteration 8430 - cost=16.480433\n",
      "Iteration 8440 - cost=11.942740\n",
      "Iteration 8450 - cost=14.337630\n",
      "Iteration 8460 - cost=13.157654\n",
      "Iteration 8470 - cost=13.003326\n",
      "Iteration 8480 - cost=15.106808\n",
      "Iteration 8490 - cost=11.969016\n",
      "Iteration 8500 - cost=16.038170\n",
      "Iteration 8510 - cost=13.622040\n",
      "Iteration 8520 - cost=15.938158\n",
      "Iteration 8530 - cost=15.075982\n",
      "Iteration 8540 - cost=14.240866\n",
      "Iteration 8550 - cost=14.889218\n",
      "Iteration 8560 - cost=15.411344\n",
      "Iteration 8570 - cost=13.276776\n",
      "Iteration 8580 - cost=13.930873\n",
      "Iteration 8590 - cost=13.153996\n",
      "Iteration 8600 - cost=13.613048\n",
      "Iteration 8610 - cost=13.514694\n",
      "Iteration 8620 - cost=13.320754\n",
      "Iteration 8630 - cost=18.857508\n",
      "Iteration 8640 - cost=14.091458\n",
      "Iteration 8650 - cost=13.882148\n",
      "Iteration 8660 - cost=12.928392\n",
      "Iteration 8670 - cost=12.876246\n",
      "Iteration 8680 - cost=14.189083\n",
      "Iteration 8690 - cost=11.850363\n",
      "Iteration 8700 - cost=14.430770\n",
      "Iteration 8710 - cost=12.744311\n",
      "Iteration 8720 - cost=12.546324\n",
      "Iteration 8730 - cost=12.938164\n",
      "Iteration 8740 - cost=12.660978\n",
      "Iteration 8750 - cost=14.030207\n",
      "Iteration 8760 - cost=12.156088\n",
      "Iteration 8770 - cost=11.820530\n",
      "Iteration 8780 - cost=12.391301\n",
      "Iteration 8790 - cost=11.018846\n",
      "Iteration 8800 - cost=13.483256\n",
      "Iteration 8810 - cost=13.432644\n",
      "Iteration 8820 - cost=12.775067\n",
      "Iteration 8830 - cost=13.992748\n",
      "Iteration 8840 - cost=13.623962\n",
      "Iteration 8850 - cost=14.435086\n",
      "Iteration 8860 - cost=13.642120\n",
      "Iteration 8870 - cost=10.600543\n",
      "Iteration 8880 - cost=12.712947\n",
      "Iteration 8890 - cost=14.968719\n",
      "Iteration 8900 - cost=13.073793\n",
      "Iteration 8910 - cost=14.111288\n",
      "Iteration 8920 - cost=13.881566\n",
      "Iteration 8930 - cost=13.662960\n",
      "Iteration 8940 - cost=14.822626\n",
      "Iteration 8950 - cost=12.786828\n",
      "Iteration 8960 - cost=13.575263\n",
      "Iteration 8970 - cost=12.619491\n",
      "Iteration 8980 - cost=15.212629\n",
      "Iteration 8990 - cost=14.757151\n",
      "Iteration 9000 - cost=12.503156\n",
      "Iteration 9010 - cost=12.624005\n",
      "Iteration 9020 - cost=13.188094\n",
      "Iteration 9030 - cost=13.604743\n",
      "Iteration 9040 - cost=13.200360\n",
      "Iteration 9050 - cost=13.434423\n",
      "Iteration 9060 - cost=11.318387\n",
      "Iteration 9070 - cost=14.136922\n",
      "Iteration 9080 - cost=13.009471\n",
      "Iteration 9090 - cost=12.742586\n",
      "Iteration 9100 - cost=13.927126\n",
      "Iteration 9110 - cost=12.615384\n",
      "Iteration 9120 - cost=14.603105\n",
      "Iteration 9130 - cost=13.458927\n",
      "Iteration 9140 - cost=15.259544\n",
      "Iteration 9150 - cost=13.666230\n",
      "Iteration 9160 - cost=12.990449\n",
      "Iteration 9170 - cost=12.656528\n",
      "Iteration 9180 - cost=13.107244\n",
      "Iteration 9190 - cost=12.468495\n",
      "Iteration 9200 - cost=15.503300\n",
      "Iteration 9210 - cost=11.698187\n",
      "Iteration 9220 - cost=13.739088\n",
      "Iteration 9230 - cost=14.247916\n",
      "Iteration 9240 - cost=13.311983\n",
      "Iteration 9250 - cost=13.058721\n",
      "Iteration 9260 - cost=12.436200\n",
      "Iteration 9270 - cost=13.929893\n",
      "Iteration 9280 - cost=13.724977\n",
      "Iteration 9290 - cost=13.244403\n",
      "Iteration 9300 - cost=12.847786\n",
      "Iteration 9310 - cost=12.299609\n",
      "Iteration 9320 - cost=13.447538\n",
      "Iteration 9330 - cost=14.933123\n",
      "Iteration 9340 - cost=12.645244\n",
      "Iteration 9350 - cost=15.064978\n",
      "Iteration 9360 - cost=12.913851\n",
      "Iteration 9370 - cost=14.637535\n",
      "Iteration 9380 - cost=11.752619\n",
      "Iteration 9390 - cost=14.261792\n",
      "Iteration 9400 - cost=12.249982\n",
      "Iteration 9410 - cost=12.272749\n",
      "Iteration 9420 - cost=13.967187\n",
      "Iteration 9430 - cost=12.411458\n",
      "Iteration 9440 - cost=13.231451\n",
      "Iteration 9450 - cost=12.794015\n",
      "Iteration 9460 - cost=12.524641\n",
      "Iteration 9470 - cost=13.553180\n",
      "Iteration 9480 - cost=13.671855\n",
      "Iteration 9490 - cost=13.732573\n",
      "Iteration 9500 - cost=14.393418\n",
      "Iteration 9510 - cost=10.966933\n",
      "Iteration 9520 - cost=11.945688\n",
      "Iteration 9530 - cost=12.832489\n",
      "Iteration 9540 - cost=13.457558\n",
      "Iteration 9550 - cost=12.608891\n",
      "Iteration 9560 - cost=13.101453\n",
      "Iteration 9570 - cost=14.608789\n",
      "Iteration 9580 - cost=13.828775\n",
      "Iteration 9590 - cost=12.971588\n",
      "Iteration 9600 - cost=13.245330\n",
      "Iteration 9610 - cost=12.787096\n",
      "Iteration 9620 - cost=11.973548\n",
      "Iteration 9630 - cost=12.705434\n",
      "Iteration 9640 - cost=14.118528\n",
      "Iteration 9650 - cost=11.368080\n",
      "Iteration 9660 - cost=11.749661\n",
      "Iteration 9670 - cost=14.509796\n",
      "Iteration 9680 - cost=14.341175\n",
      "Iteration 9690 - cost=12.541286\n",
      "Iteration 9700 - cost=13.354874\n",
      "Iteration 9710 - cost=12.227238\n",
      "Iteration 9720 - cost=12.625068\n",
      "Iteration 9730 - cost=11.199244\n",
      "Iteration 9740 - cost=9.962351\n",
      "Iteration 9750 - cost=11.956471\n",
      "Iteration 9760 - cost=13.386944\n",
      "Iteration 9770 - cost=12.721875\n",
      "Iteration 9780 - cost=12.723613\n",
      "Iteration 9790 - cost=13.440493\n",
      "Iteration 9800 - cost=13.769270\n",
      "Iteration 9810 - cost=12.938103\n",
      "Iteration 9820 - cost=12.198411\n",
      "Iteration 9830 - cost=12.481178\n",
      "Iteration 9840 - cost=13.147569\n",
      "Iteration 9850 - cost=12.973134\n",
      "Iteration 9860 - cost=13.196954\n",
      "Iteration 9870 - cost=12.938678\n",
      "Iteration 9880 - cost=11.917634\n",
      "Iteration 9890 - cost=12.789491\n",
      "Iteration 9900 - cost=13.634603\n",
      "Iteration 9910 - cost=11.208395\n",
      "Iteration 9920 - cost=13.543954\n",
      "Iteration 9930 - cost=13.380006\n",
      "Iteration 9940 - cost=14.571817\n",
      "Iteration 9950 - cost=12.697469\n",
      "Iteration 9960 - cost=13.852265\n",
      "Iteration 9970 - cost=12.365010\n",
      "Iteration 9980 - cost=13.026583\n",
      "Iteration 9990 - cost=12.053518\n",
      "Iteration 10000 - cost=11.188037\n",
      "Iteration 10010 - cost=11.414908\n",
      "Iteration 10020 - cost=13.170858\n",
      "Iteration 10030 - cost=11.537228\n",
      "Iteration 10040 - cost=12.153861\n",
      "Iteration 10050 - cost=12.657972\n",
      "Iteration 10060 - cost=14.102380\n",
      "Iteration 10070 - cost=11.967528\n",
      "Iteration 10080 - cost=12.362463\n",
      "Iteration 10090 - cost=14.512236\n",
      "Iteration 10100 - cost=12.855391\n",
      "Iteration 10110 - cost=12.547463\n",
      "Iteration 10120 - cost=11.584393\n",
      "Iteration 10130 - cost=11.787267\n",
      "Iteration 10140 - cost=13.686469\n",
      "Iteration 10150 - cost=11.946243\n",
      "Iteration 10160 - cost=13.075235\n",
      "Iteration 10170 - cost=12.508951\n",
      "Iteration 10180 - cost=13.223965\n",
      "Iteration 10190 - cost=11.949940\n",
      "Iteration 10200 - cost=14.142924\n",
      "Iteration 10210 - cost=12.985538\n",
      "Iteration 10220 - cost=12.864323\n",
      "Iteration 10230 - cost=15.333785\n",
      "Iteration 10240 - cost=12.155698\n",
      "Iteration 10250 - cost=13.700147\n",
      "Iteration 10260 - cost=11.697861\n",
      "Iteration 10270 - cost=12.137555\n",
      "Iteration 10280 - cost=13.893447\n",
      "Iteration 10290 - cost=14.648631\n",
      "Iteration 10300 - cost=13.515562\n",
      "Iteration 10310 - cost=11.449889\n",
      "Iteration 10320 - cost=14.629538\n",
      "Iteration 10330 - cost=11.383549\n",
      "Iteration 10340 - cost=12.251451\n",
      "Iteration 10350 - cost=10.453107\n",
      "Iteration 10360 - cost=13.905515\n",
      "Iteration 10370 - cost=13.575101\n",
      "Iteration 10380 - cost=11.917863\n",
      "Iteration 10390 - cost=14.429584\n",
      "Iteration 10400 - cost=11.929998\n",
      "Iteration 10410 - cost=11.533983\n",
      "Iteration 10420 - cost=12.727543\n",
      "Iteration 10430 - cost=11.989674\n",
      "Iteration 10440 - cost=10.857668\n",
      "Iteration 10450 - cost=11.974647\n",
      "Iteration 10460 - cost=14.783065\n",
      "Iteration 10470 - cost=12.117942\n",
      "Iteration 10480 - cost=13.175641\n",
      "Iteration 10490 - cost=11.456426\n",
      "Iteration 10500 - cost=13.611644\n",
      "Iteration 10510 - cost=11.912751\n",
      "Iteration 10520 - cost=11.787080\n",
      "Iteration 10530 - cost=12.818119\n",
      "Iteration 10540 - cost=12.792223\n",
      "Iteration 10550 - cost=11.746452\n",
      "Iteration 10560 - cost=12.594484\n",
      "Iteration 10570 - cost=12.297974\n",
      "Iteration 10580 - cost=10.211621\n",
      "Iteration 10590 - cost=11.185122\n",
      "Iteration 10600 - cost=12.668093\n",
      "Iteration 10610 - cost=12.293710\n",
      "Iteration 10620 - cost=11.687172\n",
      "Iteration 10630 - cost=13.133599\n",
      "Iteration 10640 - cost=13.931032\n",
      "Iteration 10650 - cost=14.357610\n",
      "Iteration 10660 - cost=13.043567\n",
      "Iteration 10670 - cost=12.434378\n",
      "Iteration 10680 - cost=13.270703\n",
      "Iteration 10690 - cost=11.084658\n",
      "Iteration 10700 - cost=12.783989\n",
      "Iteration 10710 - cost=13.291798\n",
      "Iteration 10720 - cost=11.582527\n",
      "Iteration 10730 - cost=11.679543\n",
      "Iteration 10740 - cost=11.661905\n",
      "Iteration 10750 - cost=13.284111\n",
      "Iteration 10760 - cost=13.143493\n",
      "Iteration 10770 - cost=13.187093\n",
      "Iteration 10780 - cost=12.398939\n",
      "Iteration 10790 - cost=13.358497\n",
      "Iteration 10800 - cost=12.456795\n",
      "Iteration 10810 - cost=11.559239\n",
      "Iteration 10820 - cost=11.730260\n",
      "Iteration 10830 - cost=11.136914\n",
      "Iteration 10840 - cost=12.539208\n",
      "Iteration 10850 - cost=12.541722\n",
      "Iteration 10860 - cost=13.067088\n",
      "Iteration 10870 - cost=9.169152\n",
      "Iteration 10880 - cost=10.850759\n",
      "Iteration 10890 - cost=12.383428\n",
      "Iteration 10900 - cost=13.584076\n",
      "Iteration 10910 - cost=9.859792\n",
      "Iteration 10920 - cost=11.713281\n",
      "Iteration 10930 - cost=10.496931\n",
      "Iteration 10940 - cost=11.163710\n",
      "Iteration 10950 - cost=10.289620\n",
      "Iteration 10960 - cost=11.547292\n",
      "Iteration 10970 - cost=12.033797\n",
      "Iteration 10980 - cost=12.735937\n",
      "Iteration 10990 - cost=13.152680\n",
      "Iteration 11000 - cost=12.091663\n",
      "Iteration 11010 - cost=14.462150\n",
      "Iteration 11020 - cost=11.741128\n",
      "Iteration 11030 - cost=13.918379\n",
      "Iteration 11040 - cost=14.587780\n",
      "Iteration 11050 - cost=11.384552\n",
      "Iteration 11060 - cost=13.832946\n",
      "Iteration 11070 - cost=11.289789\n",
      "Iteration 11080 - cost=12.255744\n",
      "Iteration 11090 - cost=12.144934\n",
      "Iteration 11100 - cost=12.386926\n",
      "Iteration 11110 - cost=10.480546\n",
      "Iteration 11120 - cost=11.801865\n",
      "Iteration 11130 - cost=13.935133\n",
      "Iteration 11140 - cost=11.602134\n",
      "Iteration 11150 - cost=12.211838\n",
      "Iteration 11160 - cost=12.039339\n",
      "Iteration 11170 - cost=13.055886\n",
      "Iteration 11180 - cost=11.933753\n",
      "Iteration 11190 - cost=12.145999\n",
      "Iteration 11200 - cost=12.424706\n",
      "Iteration 11210 - cost=12.317690\n",
      "Iteration 11220 - cost=11.997877\n",
      "Iteration 11230 - cost=11.570820\n",
      "Iteration 11240 - cost=11.955535\n",
      "Iteration 11250 - cost=10.648795\n",
      "Iteration 11260 - cost=12.960842\n",
      "Iteration 11270 - cost=12.793420\n",
      "Iteration 11280 - cost=10.671883\n",
      "Iteration 11290 - cost=12.271888\n",
      "Iteration 11300 - cost=12.354868\n",
      "Iteration 11310 - cost=13.603667\n",
      "Iteration 11320 - cost=11.291317\n",
      "Iteration 11330 - cost=12.819739\n",
      "Iteration 11340 - cost=9.643070\n",
      "Iteration 11350 - cost=11.544066\n",
      "Iteration 11360 - cost=13.458631\n",
      "Iteration 11370 - cost=12.458685\n",
      "Iteration 11380 - cost=11.849170\n",
      "Iteration 11390 - cost=12.393543\n",
      "Iteration 11400 - cost=11.374401\n",
      "Iteration 11410 - cost=12.235862\n",
      "Iteration 11420 - cost=10.459434\n",
      "Iteration 11430 - cost=13.887009\n",
      "Iteration 11440 - cost=10.673989\n",
      "Iteration 11450 - cost=13.556058\n",
      "Iteration 11460 - cost=12.649042\n",
      "Iteration 11470 - cost=11.060008\n",
      "Iteration 11480 - cost=12.079568\n",
      "Iteration 11490 - cost=12.131654\n",
      "Iteration 11500 - cost=12.203593\n",
      "Iteration 11510 - cost=12.067060\n",
      "Iteration 11520 - cost=11.142731\n",
      "Iteration 11530 - cost=11.951626\n",
      "Iteration 11540 - cost=11.525604\n",
      "Iteration 11550 - cost=12.089481\n",
      "Iteration 11560 - cost=10.700907\n",
      "Iteration 11570 - cost=10.534091\n",
      "Iteration 11580 - cost=10.565707\n",
      "Iteration 11590 - cost=11.724403\n",
      "Iteration 11600 - cost=11.338033\n",
      "Iteration 11610 - cost=11.419996\n",
      "Iteration 11620 - cost=11.936782\n",
      "Iteration 11630 - cost=10.929587\n",
      "Iteration 11640 - cost=11.091980\n",
      "Iteration 11650 - cost=13.887230\n",
      "Iteration 11660 - cost=11.281144\n",
      "Iteration 11670 - cost=13.519952\n",
      "Iteration 11680 - cost=10.277940\n",
      "Iteration 11690 - cost=11.221676\n",
      "Iteration 11700 - cost=12.266554\n",
      "Iteration 11710 - cost=12.534275\n",
      "Iteration 11720 - cost=11.749752\n",
      "Iteration 11730 - cost=11.064670\n",
      "Iteration 11740 - cost=12.835211\n",
      "Iteration 11750 - cost=12.582007\n",
      "Iteration 11760 - cost=10.698497\n",
      "Iteration 11770 - cost=11.941269\n",
      "Iteration 11780 - cost=12.772313\n",
      "Iteration 11790 - cost=12.206767\n",
      "Iteration 11800 - cost=12.524136\n",
      "Iteration 11810 - cost=12.883317\n",
      "Iteration 11820 - cost=12.620045\n",
      "Iteration 11830 - cost=11.405001\n",
      "Iteration 11840 - cost=12.373256\n",
      "Iteration 11850 - cost=11.481693\n",
      "Iteration 11860 - cost=11.657237\n",
      "Iteration 11870 - cost=11.595686\n",
      "Iteration 11880 - cost=14.180586\n",
      "Iteration 11890 - cost=13.074945\n",
      "Iteration 11900 - cost=11.113512\n",
      "Iteration 11910 - cost=12.598236\n",
      "Iteration 11920 - cost=13.470274\n",
      "Iteration 11930 - cost=12.624900\n",
      "Iteration 11940 - cost=12.387165\n",
      "Iteration 11950 - cost=12.389879\n",
      "Iteration 11960 - cost=12.165344\n",
      "Iteration 11970 - cost=12.481094\n",
      "Iteration 11980 - cost=12.682412\n",
      "Iteration 11990 - cost=13.851132\n",
      "Iteration 12000 - cost=11.207103\n",
      "Iteration 12010 - cost=11.954648\n",
      "Iteration 12020 - cost=10.748433\n",
      "Iteration 12030 - cost=10.740448\n",
      "Iteration 12040 - cost=11.056647\n",
      "Iteration 12050 - cost=11.332480\n",
      "Iteration 12060 - cost=13.327111\n",
      "Iteration 12070 - cost=11.108812\n",
      "Iteration 12080 - cost=12.298950\n",
      "Iteration 12090 - cost=11.581879\n",
      "Iteration 12100 - cost=11.504294\n",
      "Iteration 12110 - cost=12.184622\n",
      "Iteration 12120 - cost=13.575804\n",
      "Iteration 12130 - cost=12.432005\n",
      "Iteration 12140 - cost=10.768711\n",
      "Iteration 12150 - cost=12.719784\n",
      "Iteration 12160 - cost=12.291034\n",
      "Iteration 12170 - cost=11.737238\n",
      "Iteration 12180 - cost=11.255006\n",
      "Iteration 12190 - cost=12.487875\n",
      "Iteration 12200 - cost=10.460448\n",
      "Iteration 12210 - cost=11.650921\n",
      "Iteration 12220 - cost=11.919678\n",
      "Iteration 12230 - cost=12.175055\n",
      "Iteration 12240 - cost=12.624122\n",
      "Iteration 12250 - cost=13.662584\n",
      "Iteration 12260 - cost=12.157279\n",
      "Iteration 12270 - cost=11.001051\n",
      "Iteration 12280 - cost=10.991813\n",
      "Iteration 12290 - cost=11.095659\n",
      "Iteration 12300 - cost=12.370044\n",
      "Iteration 12310 - cost=12.146062\n",
      "Iteration 12320 - cost=12.172070\n",
      "Iteration 12330 - cost=12.354577\n",
      "Iteration 12340 - cost=10.463203\n",
      "Iteration 12350 - cost=11.858672\n",
      "Iteration 12360 - cost=10.783064\n",
      "Iteration 12370 - cost=10.733031\n",
      "Iteration 12380 - cost=11.589738\n",
      "Iteration 12390 - cost=13.777420\n",
      "Iteration 12400 - cost=11.435664\n",
      "Iteration 12410 - cost=10.520958\n",
      "Iteration 12420 - cost=11.878029\n",
      "Iteration 12430 - cost=11.534603\n",
      "Iteration 12440 - cost=11.480610\n",
      "Iteration 12450 - cost=11.817907\n",
      "Iteration 12460 - cost=10.425839\n",
      "Iteration 12470 - cost=12.034795\n",
      "Iteration 12480 - cost=11.338636\n",
      "Iteration 12490 - cost=11.182960\n",
      "Iteration 12500 - cost=11.222352\n",
      "Iteration 12510 - cost=11.550501\n",
      "Iteration 12520 - cost=12.506576\n",
      "Iteration 12530 - cost=13.865161\n",
      "Iteration 12540 - cost=10.510753\n",
      "Iteration 12550 - cost=11.254267\n",
      "Iteration 12560 - cost=11.924869\n",
      "Iteration 12570 - cost=13.343567\n",
      "Iteration 12580 - cost=11.013239\n",
      "Iteration 12590 - cost=8.493025\n",
      "Iteration 12600 - cost=12.007335\n",
      "Iteration 12610 - cost=13.321443\n",
      "Iteration 12620 - cost=11.760359\n",
      "Iteration 12630 - cost=12.781792\n",
      "Iteration 12640 - cost=11.631459\n",
      "Iteration 12650 - cost=12.027909\n",
      "Iteration 12660 - cost=10.728362\n",
      "Iteration 12670 - cost=10.940795\n",
      "Iteration 12680 - cost=11.914316\n",
      "Iteration 12690 - cost=11.738614\n",
      "Iteration 12700 - cost=11.953839\n",
      "Iteration 12710 - cost=11.910793\n",
      "Iteration 12720 - cost=10.613200\n",
      "Iteration 12730 - cost=11.890437\n",
      "Iteration 12740 - cost=12.008683\n",
      "Iteration 12750 - cost=11.216268\n",
      "Iteration 12760 - cost=10.920649\n",
      "Iteration 12770 - cost=13.747763\n",
      "Iteration 12780 - cost=11.573804\n",
      "Iteration 12790 - cost=11.643808\n",
      "Iteration 12800 - cost=11.414363\n",
      "Iteration 12810 - cost=11.975404\n",
      "Iteration 12820 - cost=12.574469\n",
      "Iteration 12830 - cost=11.638016\n",
      "Iteration 12840 - cost=12.649276\n",
      "Iteration 12850 - cost=11.915268\n",
      "Iteration 12860 - cost=10.339116\n",
      "Iteration 12870 - cost=12.074032\n",
      "Iteration 12880 - cost=10.959404\n",
      "Iteration 12890 - cost=11.771937\n",
      "Iteration 12900 - cost=11.710504\n",
      "Iteration 12910 - cost=10.104308\n",
      "Iteration 12920 - cost=12.647197\n",
      "Iteration 12930 - cost=11.639343\n",
      "Iteration 12940 - cost=11.875626\n",
      "Iteration 12950 - cost=11.048892\n",
      "Iteration 12960 - cost=12.499580\n",
      "Iteration 12970 - cost=10.713670\n",
      "Iteration 12980 - cost=12.248653\n",
      "Iteration 12990 - cost=10.594332\n",
      "Iteration 13000 - cost=11.111280\n",
      "Iteration 13010 - cost=10.538076\n",
      "Iteration 13020 - cost=10.241123\n",
      "Iteration 13030 - cost=12.018037\n",
      "Iteration 13040 - cost=10.666170\n",
      "Iteration 13050 - cost=9.931320\n",
      "Iteration 13060 - cost=13.999305\n",
      "Iteration 13070 - cost=12.296731\n",
      "Iteration 13080 - cost=10.591918\n",
      "Iteration 13090 - cost=13.190623\n",
      "Iteration 13100 - cost=9.962036\n",
      "Iteration 13110 - cost=10.323942\n",
      "Iteration 13120 - cost=10.569008\n",
      "Iteration 13130 - cost=11.980554\n",
      "Iteration 13140 - cost=13.009198\n",
      "Iteration 13150 - cost=10.793907\n",
      "Iteration 13160 - cost=9.998651\n",
      "Iteration 13170 - cost=11.014361\n",
      "Iteration 13180 - cost=12.075470\n",
      "Iteration 13190 - cost=11.830372\n",
      "Iteration 13200 - cost=11.684896\n",
      "Iteration 13210 - cost=14.199860\n",
      "Iteration 13220 - cost=10.762813\n",
      "Iteration 13230 - cost=9.279385\n",
      "Iteration 13240 - cost=11.406716\n",
      "Iteration 13250 - cost=9.901323\n",
      "Iteration 13260 - cost=10.589098\n",
      "Iteration 13270 - cost=12.191107\n",
      "Iteration 13280 - cost=11.281986\n",
      "Iteration 13290 - cost=11.132139\n",
      "Iteration 13300 - cost=10.643885\n",
      "Iteration 13310 - cost=12.029395\n",
      "Iteration 13320 - cost=12.017626\n",
      "Iteration 13330 - cost=11.892535\n",
      "Iteration 13340 - cost=10.029245\n",
      "Iteration 13350 - cost=11.912567\n",
      "Iteration 13360 - cost=11.092598\n",
      "Iteration 13370 - cost=10.312548\n",
      "Iteration 13380 - cost=10.985713\n",
      "Iteration 13390 - cost=12.600193\n",
      "Iteration 13400 - cost=11.725697\n",
      "Iteration 13410 - cost=10.605883\n",
      "Iteration 13420 - cost=9.223588\n",
      "Iteration 13430 - cost=10.203705\n",
      "Iteration 13440 - cost=11.978117\n",
      "Iteration 13450 - cost=10.988729\n",
      "Iteration 13460 - cost=10.605790\n",
      "Iteration 13470 - cost=11.564991\n",
      "Iteration 13480 - cost=11.931560\n",
      "Iteration 13490 - cost=11.191949\n",
      "Iteration 13500 - cost=10.170973\n",
      "Iteration 13510 - cost=11.286273\n",
      "Iteration 13520 - cost=11.451454\n",
      "Iteration 13530 - cost=10.655214\n",
      "Iteration 13540 - cost=11.511463\n",
      "Iteration 13550 - cost=11.762829\n",
      "Iteration 13560 - cost=10.759583\n",
      "Iteration 13570 - cost=9.168908\n",
      "Iteration 13580 - cost=13.324682\n",
      "Iteration 13590 - cost=10.521875\n",
      "Iteration 13600 - cost=11.132718\n",
      "Iteration 13610 - cost=13.103401\n",
      "Iteration 13620 - cost=12.240897\n",
      "Iteration 13630 - cost=10.876532\n",
      "Iteration 13640 - cost=11.006039\n",
      "Iteration 13650 - cost=10.339250\n",
      "Iteration 13660 - cost=11.484043\n",
      "Iteration 13670 - cost=12.535685\n",
      "Iteration 13680 - cost=10.744114\n",
      "Iteration 13690 - cost=10.681805\n",
      "Iteration 13700 - cost=10.096688\n",
      "Iteration 13710 - cost=11.008854\n",
      "Iteration 13720 - cost=10.612221\n",
      "Iteration 13730 - cost=11.559535\n",
      "Iteration 13740 - cost=12.901149\n",
      "Iteration 13750 - cost=11.218166\n",
      "Iteration 13760 - cost=11.812865\n",
      "Iteration 13770 - cost=11.655687\n",
      "Iteration 13780 - cost=9.472289\n",
      "Iteration 13790 - cost=10.525971\n",
      "Iteration 13800 - cost=10.592002\n",
      "Iteration 13810 - cost=11.821109\n",
      "Iteration 13820 - cost=12.382435\n",
      "Iteration 13830 - cost=10.886359\n",
      "Iteration 13840 - cost=12.245590\n",
      "Iteration 13850 - cost=11.858273\n",
      "Iteration 13860 - cost=12.808168\n",
      "Iteration 13870 - cost=11.138095\n",
      "Iteration 13880 - cost=10.031459\n",
      "Iteration 13890 - cost=11.930503\n",
      "Iteration 13900 - cost=10.555196\n",
      "Iteration 13910 - cost=9.883024\n",
      "Iteration 13920 - cost=11.146670\n",
      "Iteration 13930 - cost=10.450269\n",
      "Iteration 13940 - cost=11.861911\n",
      "Iteration 13950 - cost=11.514236\n",
      "Iteration 13960 - cost=11.005096\n",
      "Iteration 13970 - cost=12.530561\n",
      "Iteration 13980 - cost=11.976721\n",
      "Iteration 13990 - cost=9.801501\n",
      "Iteration 14000 - cost=10.899213\n",
      "Iteration 14010 - cost=11.924839\n",
      "Iteration 14020 - cost=11.388590\n",
      "Iteration 14030 - cost=10.303591\n",
      "Iteration 14040 - cost=12.259341\n",
      "Iteration 14050 - cost=10.948737\n",
      "Iteration 14060 - cost=10.199259\n",
      "Iteration 14070 - cost=11.107261\n",
      "Iteration 14080 - cost=11.165771\n",
      "Iteration 14090 - cost=10.950170\n",
      "Iteration 14100 - cost=9.905655\n",
      "Iteration 14110 - cost=10.925127\n",
      "Iteration 14120 - cost=8.953040\n",
      "Iteration 14130 - cost=12.367488\n",
      "Iteration 14140 - cost=11.380497\n",
      "Iteration 14150 - cost=12.443676\n",
      "Iteration 14160 - cost=12.968243\n",
      "Iteration 14170 - cost=11.078996\n",
      "Iteration 14180 - cost=10.164830\n",
      "Iteration 14190 - cost=12.451805\n",
      "Iteration 14200 - cost=12.409469\n",
      "Iteration 14210 - cost=13.199379\n",
      "Iteration 14220 - cost=12.719605\n",
      "Iteration 14230 - cost=10.770075\n",
      "Iteration 14240 - cost=10.149848\n",
      "Iteration 14250 - cost=10.416778\n",
      "Iteration 14260 - cost=9.808134\n",
      "Iteration 14270 - cost=11.267282\n",
      "Iteration 14280 - cost=10.354410\n",
      "Iteration 14290 - cost=10.488056\n",
      "Iteration 14300 - cost=12.174084\n",
      "Iteration 14310 - cost=11.514321\n",
      "Iteration 14320 - cost=10.867150\n",
      "Iteration 14330 - cost=11.900662\n",
      "Iteration 14340 - cost=12.142908\n",
      "Iteration 14350 - cost=10.785794\n",
      "Iteration 14360 - cost=10.669920\n",
      "Iteration 14370 - cost=10.624162\n",
      "Iteration 14380 - cost=12.424727\n",
      "Iteration 14390 - cost=10.772899\n",
      "Iteration 14400 - cost=11.189097\n",
      "Iteration 14410 - cost=10.161639\n",
      "Iteration 14420 - cost=11.233092\n",
      "Iteration 14430 - cost=11.838274\n",
      "Iteration 14440 - cost=9.850078\n",
      "Iteration 14450 - cost=12.934948\n",
      "Iteration 14460 - cost=10.331358\n",
      "Iteration 14470 - cost=11.491277\n",
      "Iteration 14480 - cost=11.495913\n",
      "Iteration 14490 - cost=10.077002\n",
      "Iteration 14500 - cost=10.928672\n",
      "Iteration 14510 - cost=11.283069\n",
      "Iteration 14520 - cost=10.686432\n",
      "Iteration 14530 - cost=11.560871\n",
      "Iteration 14540 - cost=9.542961\n",
      "Iteration 14550 - cost=10.382707\n",
      "Iteration 14560 - cost=11.384443\n",
      "Iteration 14570 - cost=10.899513\n",
      "Iteration 14580 - cost=11.053967\n",
      "Iteration 14590 - cost=13.227019\n",
      "Iteration 14600 - cost=10.918247\n",
      "Iteration 14610 - cost=11.618796\n",
      "Iteration 14620 - cost=10.932811\n",
      "Iteration 14630 - cost=9.243765\n",
      "Iteration 14640 - cost=10.968238\n",
      "Iteration 14650 - cost=10.131037\n",
      "Iteration 14660 - cost=11.148907\n",
      "Iteration 14670 - cost=10.014643\n",
      "Iteration 14680 - cost=9.355498\n",
      "Iteration 14690 - cost=11.205375\n",
      "Iteration 14700 - cost=11.533567\n",
      "Iteration 14710 - cost=11.459178\n",
      "Iteration 14720 - cost=10.495435\n",
      "Iteration 14730 - cost=9.690273\n",
      "Iteration 14740 - cost=11.127833\n",
      "Iteration 14750 - cost=12.354978\n",
      "Iteration 14760 - cost=11.454752\n",
      "Iteration 14770 - cost=11.198914\n",
      "Iteration 14780 - cost=11.526008\n",
      "Iteration 14790 - cost=10.565493\n",
      "Iteration 14800 - cost=11.658051\n",
      "Iteration 14810 - cost=11.187915\n",
      "Iteration 14820 - cost=10.367414\n",
      "Iteration 14830 - cost=11.178917\n",
      "Iteration 14840 - cost=10.811241\n",
      "Iteration 14850 - cost=9.398540\n",
      "Iteration 14860 - cost=9.611626\n",
      "Iteration 14870 - cost=12.621597\n",
      "Iteration 14880 - cost=10.291203\n",
      "Iteration 14890 - cost=10.993462\n",
      "Iteration 14900 - cost=10.356791\n",
      "Iteration 14910 - cost=10.028075\n",
      "Iteration 14920 - cost=10.240290\n",
      "Iteration 14930 - cost=13.112711\n",
      "Iteration 14940 - cost=11.329646\n",
      "Iteration 14950 - cost=10.009029\n",
      "Iteration 14960 - cost=12.977687\n",
      "Iteration 14970 - cost=9.946927\n",
      "Iteration 14980 - cost=11.459187\n",
      "Iteration 14990 - cost=10.538109\n",
      "Iteration 15000 - cost=9.773481\n",
      "Iteration 15010 - cost=11.925149\n",
      "Iteration 15020 - cost=10.081253\n",
      "Iteration 15030 - cost=10.496145\n",
      "Iteration 15040 - cost=10.429466\n",
      "Iteration 15050 - cost=10.772945\n",
      "Iteration 15060 - cost=10.567095\n",
      "Iteration 15070 - cost=11.373313\n",
      "Iteration 15080 - cost=9.289110\n",
      "Iteration 15090 - cost=12.066052\n",
      "Iteration 15100 - cost=11.817331\n",
      "Iteration 15110 - cost=12.296448\n",
      "Iteration 15120 - cost=12.110784\n",
      "Iteration 15130 - cost=9.608855\n",
      "Iteration 15140 - cost=11.311847\n",
      "Iteration 15150 - cost=13.134927\n",
      "Iteration 15160 - cost=11.831248\n",
      "Iteration 15170 - cost=9.342849\n",
      "Iteration 15180 - cost=9.329646\n",
      "Iteration 15190 - cost=10.510335\n",
      "Iteration 15200 - cost=10.488418\n",
      "Iteration 15210 - cost=10.163067\n",
      "Iteration 15220 - cost=11.108322\n",
      "Iteration 15230 - cost=10.048279\n",
      "Iteration 15240 - cost=10.793929\n",
      "Iteration 15250 - cost=11.086054\n",
      "Iteration 15260 - cost=9.623040\n",
      "Iteration 15270 - cost=10.477288\n",
      "Iteration 15280 - cost=11.242599\n",
      "Iteration 15290 - cost=10.764761\n",
      "Iteration 15300 - cost=10.295816\n",
      "Iteration 15310 - cost=11.814021\n",
      "Iteration 15320 - cost=10.018142\n",
      "Iteration 15330 - cost=11.958736\n",
      "Iteration 15340 - cost=11.136093\n",
      "Iteration 15350 - cost=11.470313\n",
      "Iteration 15360 - cost=12.122205\n",
      "Iteration 15370 - cost=9.551143\n",
      "Iteration 15380 - cost=10.891071\n",
      "Iteration 15390 - cost=11.856749\n",
      "Iteration 15400 - cost=11.621720\n",
      "Iteration 15410 - cost=11.896060\n",
      "Iteration 15420 - cost=10.263363\n",
      "Iteration 15430 - cost=10.223189\n",
      "Iteration 15440 - cost=10.155931\n",
      "Iteration 15450 - cost=11.568458\n",
      "Iteration 15460 - cost=10.273220\n",
      "Iteration 15470 - cost=11.677224\n",
      "Iteration 15480 - cost=9.671510\n",
      "Iteration 15490 - cost=8.950386\n",
      "Iteration 15500 - cost=10.567923\n",
      "Iteration 15510 - cost=10.277416\n",
      "Iteration 15520 - cost=10.845233\n",
      "Iteration 15530 - cost=11.987791\n",
      "Iteration 15540 - cost=13.692714\n",
      "Iteration 15550 - cost=10.057917\n",
      "Iteration 15560 - cost=9.688416\n",
      "Iteration 15570 - cost=12.369470\n",
      "Iteration 15580 - cost=10.234841\n",
      "Iteration 15590 - cost=10.215551\n",
      "Iteration 15600 - cost=11.639544\n",
      "Iteration 15610 - cost=10.936878\n",
      "Iteration 15620 - cost=10.399618\n",
      "Iteration 15630 - cost=10.661608\n",
      "Iteration 15640 - cost=12.182579\n",
      "Iteration 15650 - cost=11.463636\n",
      "Iteration 15660 - cost=10.176603\n",
      "Iteration 15670 - cost=10.914318\n",
      "Iteration 15680 - cost=9.844873\n",
      "Iteration 15690 - cost=10.820985\n",
      "Iteration 15700 - cost=11.466229\n",
      "Iteration 15710 - cost=10.484208\n",
      "Iteration 15720 - cost=12.045823\n",
      "Iteration 15730 - cost=10.157283\n",
      "Iteration 15740 - cost=11.096582\n",
      "Iteration 15750 - cost=10.348885\n",
      "Iteration 15760 - cost=10.115322\n",
      "Iteration 15770 - cost=10.799639\n",
      "Iteration 15780 - cost=10.391878\n",
      "Iteration 15790 - cost=10.490841\n",
      "Iteration 15800 - cost=11.552187\n",
      "Iteration 15810 - cost=11.061753\n",
      "Iteration 15820 - cost=12.026398\n",
      "Iteration 15830 - cost=9.247210\n",
      "Iteration 15840 - cost=11.493783\n",
      "Iteration 15850 - cost=10.755745\n",
      "Iteration 15860 - cost=12.758665\n",
      "Iteration 15870 - cost=9.420160\n",
      "Iteration 15880 - cost=11.825461\n",
      "Iteration 15890 - cost=12.053994\n",
      "Iteration 15900 - cost=9.207970\n",
      "Iteration 15910 - cost=10.427289\n",
      "Iteration 15920 - cost=10.439434\n",
      "Iteration 15930 - cost=11.085540\n",
      "Iteration 15940 - cost=13.203461\n",
      "Iteration 15950 - cost=11.093379\n",
      "Iteration 15960 - cost=10.104400\n",
      "Iteration 15970 - cost=10.019266\n",
      "Iteration 15980 - cost=11.284807\n",
      "Iteration 15990 - cost=11.164543\n",
      "Iteration 16000 - cost=10.885492\n",
      "Iteration 16010 - cost=12.106026\n",
      "Iteration 16020 - cost=10.888880\n",
      "Iteration 16030 - cost=10.044745\n",
      "Iteration 16040 - cost=9.517584\n",
      "Iteration 16050 - cost=10.387820\n",
      "Iteration 16060 - cost=12.035393\n",
      "Iteration 16070 - cost=10.977281\n",
      "Iteration 16080 - cost=11.671683\n",
      "Iteration 16090 - cost=9.213427\n",
      "Iteration 16100 - cost=11.568915\n",
      "Iteration 16110 - cost=9.556437\n",
      "Iteration 16120 - cost=10.544473\n",
      "Iteration 16130 - cost=11.242265\n",
      "Iteration 16140 - cost=9.641559\n",
      "Iteration 16150 - cost=11.751631\n",
      "Iteration 16160 - cost=9.995998\n",
      "Iteration 16170 - cost=11.825875\n",
      "Iteration 16180 - cost=10.830897\n",
      "Iteration 16190 - cost=10.941433\n",
      "Iteration 16200 - cost=11.829507\n",
      "Iteration 16210 - cost=9.371292\n",
      "Iteration 16220 - cost=12.566897\n",
      "Iteration 16230 - cost=11.730256\n",
      "Iteration 16240 - cost=10.861969\n",
      "Iteration 16250 - cost=9.678773\n",
      "Iteration 16260 - cost=10.371639\n",
      "Iteration 16270 - cost=8.795633\n",
      "Iteration 16280 - cost=11.845091\n",
      "Iteration 16290 - cost=9.280161\n",
      "Iteration 16300 - cost=10.920610\n",
      "Iteration 16310 - cost=8.701779\n",
      "Iteration 16320 - cost=10.702117\n",
      "Iteration 16330 - cost=10.945337\n",
      "Iteration 16340 - cost=11.839226\n",
      "Iteration 16350 - cost=10.254412\n",
      "Iteration 16360 - cost=10.405168\n",
      "Iteration 16370 - cost=11.629792\n",
      "Iteration 16380 - cost=9.677393\n",
      "Iteration 16390 - cost=10.472488\n",
      "Iteration 16400 - cost=9.722377\n",
      "Iteration 16410 - cost=11.354211\n",
      "Iteration 16420 - cost=11.302516\n",
      "Iteration 16430 - cost=11.099424\n",
      "Iteration 16440 - cost=10.183953\n",
      "Iteration 16450 - cost=11.220679\n",
      "Iteration 16460 - cost=9.579717\n",
      "Iteration 16470 - cost=9.934388\n",
      "Iteration 16480 - cost=11.508522\n",
      "Iteration 16490 - cost=9.777154\n",
      "Iteration 16500 - cost=10.066976\n",
      "Iteration 16510 - cost=10.094800\n",
      "Iteration 16520 - cost=10.230992\n",
      "Iteration 16530 - cost=10.462869\n",
      "Iteration 16540 - cost=10.178980\n",
      "Iteration 16550 - cost=9.317842\n",
      "Iteration 16560 - cost=10.672678\n",
      "Iteration 16570 - cost=10.011716\n",
      "Iteration 16580 - cost=11.416238\n",
      "Iteration 16590 - cost=12.129268\n",
      "Iteration 16600 - cost=10.729257\n",
      "Iteration 16610 - cost=10.126445\n",
      "Iteration 16620 - cost=9.959449\n",
      "Iteration 16630 - cost=10.866773\n",
      "Iteration 16640 - cost=10.857974\n",
      "Iteration 16650 - cost=10.471641\n",
      "Iteration 16660 - cost=10.406204\n",
      "Iteration 16670 - cost=11.631145\n",
      "Iteration 16680 - cost=10.345100\n",
      "Iteration 16690 - cost=11.862112\n",
      "Iteration 16700 - cost=11.082034\n",
      "Iteration 16710 - cost=12.826020\n",
      "Iteration 16720 - cost=10.529995\n",
      "Iteration 16730 - cost=10.418366\n",
      "Iteration 16740 - cost=10.870548\n",
      "Iteration 16750 - cost=11.502155\n",
      "Iteration 16760 - cost=9.576235\n",
      "Iteration 16770 - cost=11.546134\n",
      "Iteration 16780 - cost=9.156601\n",
      "Iteration 16790 - cost=9.398886\n",
      "Iteration 16800 - cost=11.115999\n",
      "Iteration 16810 - cost=11.656594\n",
      "Iteration 16820 - cost=9.542458\n",
      "Iteration 16830 - cost=10.990844\n",
      "Iteration 16840 - cost=9.389170\n",
      "Iteration 16850 - cost=10.591196\n",
      "Iteration 16860 - cost=10.933069\n",
      "Iteration 16870 - cost=10.322301\n",
      "Iteration 16880 - cost=9.572121\n",
      "Iteration 16890 - cost=10.948391\n",
      "Iteration 16900 - cost=12.559747\n",
      "Iteration 16910 - cost=10.327508\n",
      "Iteration 16920 - cost=11.181240\n",
      "Iteration 16930 - cost=9.757845\n",
      "Iteration 16940 - cost=12.128108\n",
      "Iteration 16950 - cost=10.751571\n",
      "Iteration 16960 - cost=9.629847\n",
      "Iteration 16970 - cost=10.665055\n",
      "Iteration 16980 - cost=9.386535\n",
      "Iteration 16990 - cost=11.458805\n",
      "Iteration 17000 - cost=10.270663\n",
      "Iteration 17010 - cost=11.750610\n",
      "Iteration 17020 - cost=10.115777\n",
      "Iteration 17030 - cost=10.156287\n",
      "Iteration 17040 - cost=9.099825\n",
      "Iteration 17050 - cost=10.274747\n",
      "Iteration 17060 - cost=12.470608\n",
      "Iteration 17070 - cost=10.018418\n",
      "Iteration 17080 - cost=9.985927\n",
      "Iteration 17090 - cost=11.203213\n",
      "Iteration 17100 - cost=9.712306\n",
      "Iteration 17110 - cost=11.946038\n",
      "Iteration 17120 - cost=10.215165\n",
      "Iteration 17130 - cost=10.106243\n",
      "Iteration 17140 - cost=9.884998\n",
      "Iteration 17150 - cost=11.476664\n",
      "Iteration 17160 - cost=9.424051\n",
      "Iteration 17170 - cost=10.877169\n",
      "Iteration 17180 - cost=9.436370\n",
      "Iteration 17190 - cost=11.126291\n",
      "Iteration 17200 - cost=10.045573\n",
      "Iteration 17210 - cost=9.607013\n",
      "Iteration 17220 - cost=9.062221\n",
      "Iteration 17230 - cost=9.764704\n",
      "Iteration 17240 - cost=10.573157\n",
      "Iteration 17250 - cost=11.155766\n",
      "Iteration 17260 - cost=9.745098\n",
      "Iteration 17270 - cost=10.755780\n",
      "Iteration 17280 - cost=10.563674\n",
      "Iteration 17290 - cost=9.608832\n",
      "Iteration 17300 - cost=10.064926\n",
      "Iteration 17310 - cost=9.486787\n",
      "Iteration 17320 - cost=11.942531\n",
      "Iteration 17330 - cost=10.573868\n",
      "Iteration 17340 - cost=10.299125\n",
      "Iteration 17350 - cost=10.288003\n",
      "Iteration 17360 - cost=11.223745\n",
      "Iteration 17370 - cost=8.941367\n",
      "Iteration 17380 - cost=10.209077\n",
      "Iteration 17390 - cost=11.171202\n",
      "Iteration 17400 - cost=10.374263\n",
      "Iteration 17410 - cost=9.866334\n",
      "Iteration 17420 - cost=9.725536\n",
      "Iteration 17430 - cost=9.110049\n",
      "Iteration 17440 - cost=10.388111\n",
      "Iteration 17450 - cost=10.517121\n",
      "Iteration 17460 - cost=10.382654\n",
      "Iteration 17470 - cost=9.515572\n",
      "Iteration 17480 - cost=9.436522\n",
      "Iteration 17490 - cost=9.892027\n",
      "Iteration 17500 - cost=10.888559\n",
      "Iteration 17510 - cost=11.334887\n",
      "Iteration 17520 - cost=10.419795\n",
      "Iteration 17530 - cost=10.286314\n",
      "Iteration 17540 - cost=11.330965\n",
      "Iteration 17550 - cost=11.308214\n",
      "Iteration 17560 - cost=10.509619\n",
      "Iteration 17570 - cost=11.136834\n",
      "Iteration 17580 - cost=9.200059\n",
      "Iteration 17590 - cost=11.008030\n",
      "Iteration 17600 - cost=10.041538\n",
      "Iteration 17610 - cost=8.964047\n",
      "Iteration 17620 - cost=9.230336\n",
      "Iteration 17630 - cost=11.606598\n",
      "Iteration 17640 - cost=10.914108\n",
      "Iteration 17650 - cost=10.772847\n",
      "Iteration 17660 - cost=10.068785\n",
      "Iteration 17670 - cost=11.222820\n",
      "Iteration 17680 - cost=11.593102\n",
      "Iteration 17690 - cost=11.147470\n",
      "Iteration 17700 - cost=9.968401\n",
      "Iteration 17710 - cost=11.520024\n",
      "Iteration 17720 - cost=10.165416\n",
      "Iteration 17730 - cost=10.401464\n",
      "Iteration 17740 - cost=11.271972\n",
      "Iteration 17750 - cost=9.869707\n",
      "Iteration 17760 - cost=10.612872\n",
      "Iteration 17770 - cost=10.053998\n",
      "Iteration 17780 - cost=12.261316\n",
      "Iteration 17790 - cost=10.157949\n",
      "Iteration 17800 - cost=9.379251\n",
      "Iteration 17810 - cost=10.491841\n",
      "Iteration 17820 - cost=9.811244\n",
      "Iteration 17830 - cost=10.463203\n",
      "Iteration 17840 - cost=10.950063\n",
      "Iteration 17850 - cost=9.657345\n",
      "Iteration 17860 - cost=10.062880\n",
      "Iteration 17870 - cost=7.240097\n",
      "Iteration 17880 - cost=10.680729\n",
      "Iteration 17890 - cost=10.468907\n",
      "Iteration 17900 - cost=10.509035\n",
      "Iteration 17910 - cost=10.268297\n",
      "Iteration 17920 - cost=9.812081\n",
      "Iteration 17930 - cost=11.179370\n",
      "Iteration 17940 - cost=10.444464\n",
      "Iteration 17950 - cost=11.487036\n",
      "Iteration 17960 - cost=10.076729\n",
      "Iteration 17970 - cost=9.545344\n",
      "Iteration 17980 - cost=10.453682\n",
      "Iteration 17990 - cost=9.670044\n",
      "Iteration 18000 - cost=9.986023\n",
      "Iteration 18010 - cost=10.643175\n",
      "Iteration 18020 - cost=9.488961\n",
      "Iteration 18030 - cost=11.761486\n",
      "Iteration 18040 - cost=11.234837\n",
      "Iteration 18050 - cost=10.287311\n",
      "Iteration 18060 - cost=9.236821\n",
      "Iteration 18070 - cost=10.976193\n",
      "Iteration 18080 - cost=10.971371\n",
      "Iteration 18090 - cost=10.983164\n",
      "Iteration 18100 - cost=11.026374\n",
      "Iteration 18110 - cost=7.767313\n",
      "Iteration 18120 - cost=9.785229\n",
      "Iteration 18130 - cost=10.719205\n",
      "Iteration 18140 - cost=9.908740\n",
      "Iteration 18150 - cost=9.882549\n",
      "Iteration 18160 - cost=10.098293\n",
      "Iteration 18170 - cost=9.892962\n",
      "Iteration 18180 - cost=9.604094\n",
      "Iteration 18190 - cost=11.350759\n",
      "Iteration 18200 - cost=9.396975\n",
      "Iteration 18210 - cost=9.642299\n",
      "Iteration 18220 - cost=9.868134\n",
      "Iteration 18230 - cost=10.420058\n",
      "Iteration 18240 - cost=9.677153\n",
      "Iteration 18250 - cost=11.773984\n",
      "Iteration 18260 - cost=9.476690\n",
      "Iteration 18270 - cost=9.708910\n",
      "Iteration 18280 - cost=9.983669\n",
      "Iteration 18290 - cost=12.290106\n",
      "Iteration 18300 - cost=10.077962\n",
      "Iteration 18310 - cost=11.364344\n",
      "Iteration 18320 - cost=11.982048\n",
      "Iteration 18330 - cost=9.884190\n",
      "Iteration 18340 - cost=10.531506\n",
      "Iteration 18350 - cost=10.641876\n",
      "Iteration 18360 - cost=10.198549\n",
      "Iteration 18370 - cost=8.411689\n",
      "Iteration 18380 - cost=11.186963\n",
      "Iteration 18390 - cost=11.417496\n",
      "Iteration 18400 - cost=10.460667\n",
      "Iteration 18410 - cost=8.781409\n",
      "Iteration 18420 - cost=10.342363\n",
      "Iteration 18430 - cost=9.565441\n",
      "Iteration 18440 - cost=10.073642\n",
      "Iteration 18450 - cost=10.831831\n",
      "Iteration 18460 - cost=10.080982\n",
      "Iteration 18470 - cost=11.069290\n",
      "Iteration 18480 - cost=10.272634\n",
      "Iteration 18490 - cost=10.133184\n",
      "Iteration 18500 - cost=10.946528\n",
      "Iteration 18510 - cost=10.186804\n",
      "Iteration 18520 - cost=9.319091\n",
      "Iteration 18530 - cost=9.583665\n",
      "Iteration 18540 - cost=11.705340\n",
      "Iteration 18550 - cost=9.696818\n",
      "Iteration 18560 - cost=11.071702\n",
      "Iteration 18570 - cost=9.642215\n",
      "Iteration 18580 - cost=10.212344\n",
      "Iteration 18590 - cost=10.215007\n",
      "Iteration 18600 - cost=9.896093\n",
      "Iteration 18610 - cost=10.501220\n",
      "Iteration 18620 - cost=8.920986\n",
      "Iteration 18630 - cost=10.954624\n",
      "Iteration 18640 - cost=10.006047\n",
      "Iteration 18650 - cost=10.328624\n",
      "Iteration 18660 - cost=10.595756\n",
      "Iteration 18670 - cost=10.218090\n",
      "Iteration 18680 - cost=9.647384\n",
      "Iteration 18690 - cost=10.189782\n",
      "Iteration 18700 - cost=9.648164\n",
      "Iteration 18710 - cost=10.029451\n",
      "Iteration 18720 - cost=9.825279\n",
      "Iteration 18730 - cost=10.441850\n",
      "Iteration 18740 - cost=10.273813\n",
      "Iteration 18750 - cost=9.769224\n",
      "Iteration 18760 - cost=8.576345\n",
      "Iteration 18770 - cost=10.724969\n",
      "Iteration 18780 - cost=9.619928\n",
      "Iteration 18790 - cost=8.612843\n",
      "Iteration 18800 - cost=9.796726\n",
      "Iteration 18810 - cost=10.978326\n",
      "Iteration 18820 - cost=10.626402\n",
      "Iteration 18830 - cost=10.354451\n",
      "Iteration 18840 - cost=9.651437\n",
      "Iteration 18850 - cost=10.774389\n",
      "Iteration 18860 - cost=11.233346\n",
      "Iteration 18870 - cost=9.663264\n",
      "Iteration 18880 - cost=9.853519\n",
      "Iteration 18890 - cost=9.736233\n",
      "Iteration 18900 - cost=11.415508\n",
      "Iteration 18910 - cost=8.346559\n",
      "Iteration 18920 - cost=10.203901\n",
      "Iteration 18930 - cost=9.797703\n",
      "Iteration 18940 - cost=10.567754\n",
      "Iteration 18950 - cost=10.024643\n",
      "Iteration 18960 - cost=12.053124\n",
      "Iteration 18970 - cost=11.841615\n",
      "Iteration 18980 - cost=10.783376\n",
      "Iteration 18990 - cost=9.669098\n",
      "Iteration 19000 - cost=8.567154\n",
      "Iteration 19010 - cost=11.461052\n",
      "Iteration 19020 - cost=9.641654\n",
      "Iteration 19030 - cost=11.605289\n",
      "Iteration 19040 - cost=10.176291\n",
      "Iteration 19050 - cost=9.773896\n",
      "Iteration 19060 - cost=10.235821\n",
      "Iteration 19070 - cost=10.690782\n",
      "Iteration 19080 - cost=10.695237\n",
      "Iteration 19090 - cost=10.109521\n",
      "Iteration 19100 - cost=10.514416\n",
      "Iteration 19110 - cost=9.553769\n",
      "Iteration 19120 - cost=10.563994\n",
      "Iteration 19130 - cost=11.672205\n",
      "Iteration 19140 - cost=10.250555\n",
      "Iteration 19150 - cost=10.673606\n",
      "Iteration 19160 - cost=10.621048\n",
      "Iteration 19170 - cost=10.659567\n",
      "Iteration 19180 - cost=9.000926\n",
      "Iteration 19190 - cost=12.093315\n",
      "Iteration 19200 - cost=8.936815\n",
      "Iteration 19210 - cost=10.753841\n",
      "Iteration 19220 - cost=9.464375\n",
      "Iteration 19230 - cost=9.632170\n",
      "Iteration 19240 - cost=9.831281\n",
      "Iteration 19250 - cost=10.704439\n",
      "Iteration 19260 - cost=10.587601\n",
      "Iteration 19270 - cost=9.523472\n",
      "Iteration 19280 - cost=10.748635\n",
      "Iteration 19290 - cost=10.395462\n",
      "Iteration 19300 - cost=9.107885\n",
      "Iteration 19310 - cost=9.440687\n",
      "Iteration 19320 - cost=11.163632\n",
      "Iteration 19330 - cost=11.626207\n",
      "Iteration 19340 - cost=11.442042\n",
      "Iteration 19350 - cost=9.952207\n",
      "Iteration 19360 - cost=9.903370\n",
      "Iteration 19370 - cost=11.174724\n",
      "Iteration 19380 - cost=10.945537\n",
      "Iteration 19390 - cost=9.958672\n",
      "Iteration 19400 - cost=10.089633\n",
      "Iteration 19410 - cost=9.988018\n",
      "Iteration 19420 - cost=10.658971\n",
      "Iteration 19430 - cost=8.671502\n",
      "Iteration 19440 - cost=9.058220\n",
      "Iteration 19450 - cost=10.066102\n",
      "Iteration 19460 - cost=10.500539\n",
      "Iteration 19470 - cost=11.058591\n",
      "Iteration 19480 - cost=9.398578\n",
      "Iteration 19490 - cost=11.091373\n",
      "Iteration 19500 - cost=8.655300\n",
      "Iteration 19510 - cost=10.306460\n",
      "Iteration 19520 - cost=10.902018\n",
      "Iteration 19530 - cost=9.361066\n",
      "Iteration 19540 - cost=11.006145\n",
      "Iteration 19550 - cost=10.323694\n",
      "Iteration 19560 - cost=9.904917\n",
      "Iteration 19570 - cost=7.902727\n",
      "Iteration 19580 - cost=11.259425\n",
      "Iteration 19590 - cost=10.878646\n",
      "Iteration 19600 - cost=10.762833\n",
      "Iteration 19610 - cost=9.348417\n",
      "Iteration 19620 - cost=11.503886\n",
      "Iteration 19630 - cost=10.222781\n",
      "Iteration 19640 - cost=9.576869\n",
      "Iteration 19650 - cost=11.079575\n",
      "Iteration 19660 - cost=10.991074\n",
      "Iteration 19670 - cost=10.945323\n",
      "Iteration 19680 - cost=10.622332\n",
      "Iteration 19690 - cost=9.689689\n",
      "Iteration 19700 - cost=9.288307\n",
      "Iteration 19710 - cost=11.165487\n",
      "Iteration 19720 - cost=11.191605\n",
      "Iteration 19730 - cost=9.629619\n",
      "Iteration 19740 - cost=9.578144\n",
      "Iteration 19750 - cost=9.864671\n",
      "Iteration 19760 - cost=9.534314\n",
      "Iteration 19770 - cost=9.626459\n",
      "Iteration 19780 - cost=10.078169\n",
      "Iteration 19790 - cost=11.347527\n",
      "Iteration 19800 - cost=9.530467\n",
      "Iteration 19810 - cost=9.151950\n",
      "Iteration 19820 - cost=9.296891\n",
      "Iteration 19830 - cost=9.794401\n",
      "Iteration 19840 - cost=11.982033\n",
      "Iteration 19850 - cost=9.681589\n",
      "Iteration 19860 - cost=9.243016\n",
      "Iteration 19870 - cost=10.563393\n",
      "Iteration 19880 - cost=11.796011\n",
      "Iteration 19890 - cost=9.742201\n",
      "Iteration 19900 - cost=9.187426\n",
      "Iteration 19910 - cost=10.905050\n",
      "Iteration 19920 - cost=10.800226\n",
      "Iteration 19930 - cost=10.927104\n",
      "Iteration 19940 - cost=8.524328\n",
      "Iteration 19950 - cost=11.274495\n",
      "Iteration 19960 - cost=10.519375\n",
      "Iteration 19970 - cost=7.876171\n",
      "Iteration 19980 - cost=9.522775\n",
      "Iteration 19990 - cost=10.560787\n",
      "Iteration 20000 - cost=9.734645\n",
      "Iteration 20010 - cost=10.520032\n",
      "Iteration 20020 - cost=10.796842\n",
      "Iteration 20030 - cost=10.363762\n",
      "Iteration 20040 - cost=10.293598\n",
      "Iteration 20050 - cost=9.261811\n",
      "Iteration 20060 - cost=12.566568\n",
      "Iteration 20070 - cost=9.666310\n",
      "Iteration 20080 - cost=10.508004\n",
      "Iteration 20090 - cost=10.946114\n",
      "Iteration 20100 - cost=10.993163\n",
      "Iteration 20110 - cost=10.531363\n",
      "Iteration 20120 - cost=10.193403\n",
      "Iteration 20130 - cost=9.462920\n",
      "Iteration 20140 - cost=8.334337\n",
      "Iteration 20150 - cost=10.136752\n",
      "Iteration 20160 - cost=9.613704\n",
      "Iteration 20170 - cost=9.512510\n",
      "Iteration 20180 - cost=9.942713\n",
      "Iteration 20190 - cost=9.299607\n",
      "Iteration 20200 - cost=10.983047\n",
      "Iteration 20210 - cost=10.341162\n",
      "Iteration 20220 - cost=10.744332\n",
      "Iteration 20230 - cost=9.790237\n",
      "Iteration 20240 - cost=8.958850\n",
      "Iteration 20250 - cost=9.602834\n",
      "Iteration 20260 - cost=9.223319\n",
      "Iteration 20270 - cost=9.912830\n",
      "Iteration 20280 - cost=11.267995\n",
      "Iteration 20290 - cost=9.218212\n",
      "Iteration 20300 - cost=9.550222\n",
      "Iteration 20310 - cost=11.390803\n",
      "Iteration 20320 - cost=10.988589\n",
      "Iteration 20330 - cost=9.080679\n",
      "Iteration 20340 - cost=11.050020\n",
      "Iteration 20350 - cost=11.354171\n",
      "Iteration 20360 - cost=10.477383\n",
      "Iteration 20370 - cost=10.016824\n",
      "Iteration 20380 - cost=8.499202\n",
      "Iteration 20390 - cost=8.660933\n",
      "Iteration 20400 - cost=9.489196\n",
      "Iteration 20410 - cost=10.665455\n",
      "Iteration 20420 - cost=10.416331\n",
      "Iteration 20430 - cost=9.342270\n",
      "Iteration 20440 - cost=9.811316\n",
      "Iteration 20450 - cost=9.863173\n",
      "Iteration 20460 - cost=10.994725\n",
      "Iteration 20470 - cost=9.164732\n",
      "Iteration 20480 - cost=10.541234\n",
      "Iteration 20490 - cost=10.369389\n",
      "Iteration 20500 - cost=10.355738\n",
      "Iteration 20510 - cost=10.924991\n",
      "Iteration 20520 - cost=10.097792\n",
      "Iteration 20530 - cost=9.579927\n",
      "Iteration 20540 - cost=9.366661\n",
      "Iteration 20550 - cost=8.692132\n",
      "Iteration 20560 - cost=10.079194\n",
      "Iteration 20570 - cost=10.090881\n",
      "Iteration 20580 - cost=11.233351\n",
      "Iteration 20590 - cost=9.983755\n",
      "Iteration 20600 - cost=8.394198\n",
      "Iteration 20610 - cost=10.166341\n",
      "Iteration 20620 - cost=9.611851\n",
      "Iteration 20630 - cost=9.793140\n",
      "Iteration 20640 - cost=10.123194\n",
      "Iteration 20650 - cost=9.763443\n",
      "Iteration 20660 - cost=9.737479\n",
      "Iteration 20670 - cost=10.636690\n",
      "Iteration 20680 - cost=11.691678\n",
      "Iteration 20690 - cost=10.663045\n",
      "Iteration 20700 - cost=10.113172\n",
      "Iteration 20710 - cost=10.597410\n",
      "Iteration 20720 - cost=10.757548\n",
      "Iteration 20730 - cost=9.025471\n",
      "Iteration 20740 - cost=9.326223\n",
      "Iteration 20750 - cost=8.998207\n",
      "Iteration 20760 - cost=9.630497\n",
      "Iteration 20770 - cost=10.532503\n",
      "Iteration 20780 - cost=10.113782\n",
      "Iteration 20790 - cost=10.691494\n",
      "Iteration 20800 - cost=8.940493\n",
      "Iteration 20810 - cost=10.712917\n",
      "Iteration 20820 - cost=10.995285\n",
      "Iteration 20830 - cost=10.828956\n",
      "Iteration 20840 - cost=9.805418\n",
      "Iteration 20850 - cost=9.161780\n",
      "Iteration 20860 - cost=8.640758\n",
      "Iteration 20870 - cost=10.288504\n",
      "Iteration 20880 - cost=10.499747\n",
      "Iteration 20890 - cost=9.930980\n",
      "Iteration 20900 - cost=8.930256\n",
      "Iteration 20910 - cost=10.320966\n",
      "Iteration 20920 - cost=10.239581\n",
      "Iteration 20930 - cost=9.042216\n",
      "Iteration 20940 - cost=9.668675\n",
      "Iteration 20950 - cost=10.149291\n",
      "Iteration 20960 - cost=9.043357\n",
      "Iteration 20970 - cost=10.361640\n",
      "Iteration 20980 - cost=9.844885\n",
      "Iteration 20990 - cost=10.057288\n",
      "Iteration 21000 - cost=11.015238\n",
      "Iteration 21010 - cost=8.446623\n",
      "Iteration 21020 - cost=10.451482\n",
      "Iteration 21030 - cost=9.365116\n",
      "Iteration 21040 - cost=10.104210\n",
      "Iteration 21050 - cost=10.746867\n",
      "Iteration 21060 - cost=9.058136\n",
      "Iteration 21070 - cost=10.250875\n",
      "Iteration 21080 - cost=10.330579\n",
      "Iteration 21090 - cost=9.935921\n",
      "Iteration 21100 - cost=10.043670\n",
      "Iteration 21110 - cost=10.202439\n",
      "Iteration 21120 - cost=8.913281\n",
      "Iteration 21130 - cost=10.298400\n",
      "Iteration 21140 - cost=10.709894\n",
      "Iteration 21150 - cost=10.306834\n",
      "Iteration 21160 - cost=9.886571\n",
      "Iteration 21170 - cost=8.986916\n",
      "Iteration 21180 - cost=10.543367\n",
      "Iteration 21190 - cost=9.641297\n",
      "Iteration 21200 - cost=10.660915\n",
      "Iteration 21210 - cost=9.277607\n",
      "Iteration 21220 - cost=10.503475\n",
      "Iteration 21230 - cost=10.959671\n",
      "Iteration 21240 - cost=9.904769\n",
      "Iteration 21250 - cost=10.025679\n",
      "Iteration 21260 - cost=11.230823\n",
      "Iteration 21270 - cost=10.650554\n",
      "Iteration 21280 - cost=8.794989\n",
      "Iteration 21290 - cost=9.486768\n",
      "Iteration 21300 - cost=10.170604\n",
      "Iteration 21310 - cost=11.842401\n",
      "Iteration 21320 - cost=9.872053\n",
      "Iteration 21330 - cost=10.493946\n",
      "Iteration 21340 - cost=9.010283\n",
      "Iteration 21350 - cost=10.894687\n",
      "Iteration 21360 - cost=9.175142\n",
      "Iteration 21370 - cost=10.426588\n",
      "Iteration 21380 - cost=8.155585\n",
      "Iteration 21390 - cost=8.287896\n",
      "Iteration 21400 - cost=11.754400\n",
      "Iteration 21410 - cost=9.469591\n",
      "Iteration 21420 - cost=11.459496\n",
      "Iteration 21430 - cost=10.442999\n",
      "Iteration 21440 - cost=9.532580\n",
      "Iteration 21450 - cost=11.691755\n",
      "Iteration 21460 - cost=8.367902\n",
      "Iteration 21470 - cost=9.756588\n",
      "Iteration 21480 - cost=10.201493\n",
      "Iteration 21490 - cost=10.646122\n",
      "Iteration 21500 - cost=10.069704\n",
      "Iteration 21510 - cost=10.063402\n",
      "Iteration 21520 - cost=9.685778\n",
      "Iteration 21530 - cost=9.089949\n",
      "Iteration 21540 - cost=9.125068\n",
      "Iteration 21550 - cost=9.969516\n",
      "Iteration 21560 - cost=10.603243\n",
      "Iteration 21570 - cost=9.487884\n",
      "Iteration 21580 - cost=9.268101\n",
      "Iteration 21590 - cost=10.009976\n",
      "Iteration 21600 - cost=10.401858\n",
      "Iteration 21610 - cost=10.669006\n",
      "Iteration 21620 - cost=9.856481\n",
      "Iteration 21630 - cost=8.403215\n",
      "Iteration 21640 - cost=10.043366\n",
      "Iteration 21650 - cost=9.739868\n",
      "Iteration 21660 - cost=9.526637\n",
      "Iteration 21670 - cost=10.624788\n",
      "Iteration 21680 - cost=10.230054\n",
      "Iteration 21690 - cost=10.603069\n",
      "Iteration 21700 - cost=9.009416\n",
      "Iteration 21710 - cost=9.943586\n",
      "Iteration 21720 - cost=8.766215\n",
      "Iteration 21730 - cost=10.792793\n",
      "Iteration 21740 - cost=9.667644\n",
      "Iteration 21750 - cost=9.967803\n",
      "Iteration 21760 - cost=11.413604\n",
      "Iteration 21770 - cost=10.454785\n",
      "Iteration 21780 - cost=11.071300\n",
      "Iteration 21790 - cost=10.912326\n",
      "Iteration 21800 - cost=9.019121\n",
      "Iteration 21810 - cost=9.151290\n",
      "Iteration 21820 - cost=10.446472\n",
      "Iteration 21830 - cost=10.320856\n",
      "Iteration 21840 - cost=8.470942\n",
      "Iteration 21850 - cost=10.565412\n",
      "Iteration 21860 - cost=9.774489\n",
      "Iteration 21870 - cost=9.667972\n",
      "Iteration 21880 - cost=9.818958\n",
      "Iteration 21890 - cost=9.308034\n",
      "Iteration 21900 - cost=11.357057\n",
      "Iteration 21910 - cost=12.433166\n",
      "Iteration 21920 - cost=10.204718\n",
      "Iteration 21930 - cost=11.341841\n",
      "Iteration 21940 - cost=11.553694\n",
      "Iteration 21950 - cost=9.929959\n",
      "Iteration 21960 - cost=10.161555\n",
      "Iteration 21970 - cost=9.062883\n",
      "Iteration 21980 - cost=10.169886\n",
      "Iteration 21990 - cost=10.584788\n",
      "Iteration 22000 - cost=11.034657\n",
      "Iteration 22010 - cost=10.006739\n",
      "Iteration 22020 - cost=9.933388\n",
      "Iteration 22030 - cost=11.293335\n",
      "Iteration 22040 - cost=9.368069\n",
      "Iteration 22050 - cost=9.046397\n",
      "Iteration 22060 - cost=9.429463\n",
      "Iteration 22070 - cost=8.801141\n",
      "Iteration 22080 - cost=10.970506\n",
      "Iteration 22090 - cost=9.918602\n",
      "Iteration 22100 - cost=11.269906\n",
      "Iteration 22110 - cost=11.115650\n",
      "Iteration 22120 - cost=10.274970\n",
      "Iteration 22130 - cost=10.168028\n",
      "Iteration 22140 - cost=11.461034\n",
      "Iteration 22150 - cost=9.411768\n",
      "Iteration 22160 - cost=10.258123\n",
      "Iteration 22170 - cost=9.219763\n",
      "Iteration 22180 - cost=10.776798\n",
      "Iteration 22190 - cost=10.331320\n",
      "Iteration 22200 - cost=9.753737\n",
      "Iteration 22210 - cost=9.204801\n",
      "Iteration 22220 - cost=9.337939\n",
      "Iteration 22230 - cost=8.423890\n",
      "Iteration 22240 - cost=9.174551\n",
      "Iteration 22250 - cost=9.509341\n",
      "Iteration 22260 - cost=10.266092\n",
      "Iteration 22270 - cost=10.170731\n",
      "Iteration 22280 - cost=9.628302\n",
      "Iteration 22290 - cost=8.932142\n",
      "Iteration 22300 - cost=10.979726\n",
      "Iteration 22310 - cost=8.575911\n",
      "Iteration 22320 - cost=10.723921\n",
      "Iteration 22330 - cost=9.712757\n",
      "Iteration 22340 - cost=10.255068\n",
      "Iteration 22350 - cost=10.719633\n",
      "Iteration 22360 - cost=9.597838\n",
      "Iteration 22370 - cost=9.084848\n",
      "Iteration 22380 - cost=9.778151\n",
      "Iteration 22390 - cost=9.294086\n",
      "Iteration 22400 - cost=9.601573\n",
      "Iteration 22410 - cost=9.889146\n",
      "Iteration 22420 - cost=10.760443\n",
      "Iteration 22430 - cost=7.477474\n",
      "Iteration 22440 - cost=11.076800\n",
      "Iteration 22450 - cost=9.403583\n",
      "Iteration 22460 - cost=10.117758\n",
      "Iteration 22470 - cost=10.241002\n",
      "Iteration 22480 - cost=8.228744\n",
      "Iteration 22490 - cost=9.643497\n",
      "Iteration 22500 - cost=10.598619\n",
      "Iteration 22510 - cost=9.209373\n",
      "Iteration 22520 - cost=10.820182\n",
      "Iteration 22530 - cost=10.871870\n",
      "Iteration 22540 - cost=10.496128\n",
      "Iteration 22550 - cost=9.663471\n",
      "Iteration 22560 - cost=9.920307\n",
      "Iteration 22570 - cost=10.370323\n",
      "Iteration 22580 - cost=8.058380\n",
      "Iteration 22590 - cost=10.650233\n",
      "Iteration 22600 - cost=10.522361\n",
      "Iteration 22610 - cost=11.438291\n",
      "Iteration 22620 - cost=10.078556\n",
      "Iteration 22630 - cost=8.829052\n",
      "Iteration 22640 - cost=11.239721\n",
      "Iteration 22650 - cost=9.850876\n",
      "Iteration 22660 - cost=9.266469\n",
      "Iteration 22670 - cost=10.170471\n",
      "Iteration 22680 - cost=8.575312\n",
      "Iteration 22690 - cost=10.189436\n",
      "Iteration 22700 - cost=10.116933\n",
      "Iteration 22710 - cost=10.600792\n",
      "Iteration 22720 - cost=8.713124\n",
      "Iteration 22730 - cost=9.827075\n",
      "Iteration 22740 - cost=10.073086\n",
      "Iteration 22750 - cost=10.068443\n",
      "Iteration 22760 - cost=9.490549\n",
      "Iteration 22770 - cost=10.713994\n",
      "Iteration 22780 - cost=10.466754\n",
      "Iteration 22790 - cost=10.044661\n",
      "Iteration 22800 - cost=10.501558\n",
      "Iteration 22810 - cost=9.173012\n",
      "Iteration 22820 - cost=11.728724\n",
      "Iteration 22830 - cost=10.802276\n",
      "Iteration 22840 - cost=9.766643\n",
      "Iteration 22850 - cost=9.313272\n",
      "Iteration 22860 - cost=10.132246\n",
      "Iteration 22870 - cost=10.839144\n",
      "Iteration 22880 - cost=10.570142\n",
      "Iteration 22890 - cost=9.900160\n",
      "Iteration 22900 - cost=9.337920\n",
      "Iteration 22910 - cost=9.670684\n",
      "Iteration 22920 - cost=10.265804\n",
      "Iteration 22930 - cost=10.487808\n",
      "Iteration 22940 - cost=8.757142\n",
      "Iteration 22950 - cost=10.424760\n",
      "Iteration 22960 - cost=10.235686\n",
      "Iteration 22970 - cost=10.168707\n",
      "Iteration 22980 - cost=9.697230\n",
      "Iteration 22990 - cost=10.803573\n",
      "Iteration 23000 - cost=9.236504\n",
      "Iteration 23010 - cost=10.681555\n",
      "Iteration 23020 - cost=10.009781\n",
      "Iteration 23030 - cost=10.430317\n",
      "Iteration 23040 - cost=9.912481\n",
      "Iteration 23050 - cost=11.594650\n",
      "Iteration 23060 - cost=9.467515\n",
      "Iteration 23070 - cost=10.054200\n",
      "Iteration 23080 - cost=10.629152\n",
      "Iteration 23090 - cost=8.653108\n",
      "Iteration 23100 - cost=8.376130\n",
      "Iteration 23110 - cost=7.628706\n",
      "Iteration 23120 - cost=9.690986\n",
      "Iteration 23130 - cost=10.816042\n",
      "Iteration 23140 - cost=9.830960\n",
      "Iteration 23150 - cost=10.263462\n",
      "Iteration 23160 - cost=9.847201\n",
      "Iteration 23170 - cost=10.309491\n",
      "Iteration 23180 - cost=10.243084\n",
      "Iteration 23190 - cost=9.114235\n",
      "Iteration 23200 - cost=11.818333\n",
      "Iteration 23210 - cost=10.230834\n",
      "Iteration 23220 - cost=9.932774\n",
      "Iteration 23230 - cost=10.489443\n",
      "Iteration 23240 - cost=9.671975\n",
      "Iteration 23250 - cost=10.325740\n",
      "Iteration 23260 - cost=8.839449\n",
      "Iteration 23270 - cost=8.533295\n",
      "Iteration 23280 - cost=8.537820\n",
      "Iteration 23290 - cost=8.615797\n",
      "Iteration 23300 - cost=9.930856\n",
      "Iteration 23310 - cost=10.523991\n",
      "Iteration 23320 - cost=12.141807\n",
      "Iteration 23330 - cost=8.979154\n",
      "Iteration 23340 - cost=9.937913\n",
      "Iteration 23350 - cost=10.675271\n",
      "Iteration 23360 - cost=9.843796\n",
      "Iteration 23370 - cost=10.745062\n",
      "Iteration 23380 - cost=11.343898\n",
      "Iteration 23390 - cost=10.920091\n",
      "Iteration 23400 - cost=8.712118\n",
      "Iteration 23410 - cost=10.991475\n",
      "Iteration 23420 - cost=9.968970\n",
      "Iteration 23430 - cost=8.261785\n",
      "Iteration 23440 - cost=11.353639\n",
      "Iteration 23450 - cost=11.200207\n",
      "Iteration 23460 - cost=10.464205\n",
      "Iteration 23470 - cost=9.406002\n",
      "Iteration 23480 - cost=9.003010\n",
      "Iteration 23490 - cost=9.972896\n",
      "Iteration 23500 - cost=11.070813\n",
      "Iteration 23510 - cost=9.251575\n",
      "Iteration 23520 - cost=10.896560\n",
      "Iteration 23530 - cost=9.519903\n",
      "Iteration 23540 - cost=10.671170\n",
      "Iteration 23550 - cost=9.126621\n",
      "Iteration 23560 - cost=9.513775\n",
      "Iteration 23570 - cost=9.989131\n",
      "Iteration 23580 - cost=9.477838\n",
      "Iteration 23590 - cost=8.921544\n",
      "Iteration 23600 - cost=11.489139\n",
      "Iteration 23610 - cost=10.643614\n",
      "Iteration 23620 - cost=9.370612\n",
      "Iteration 23630 - cost=9.305707\n",
      "Iteration 23640 - cost=10.793810\n",
      "Iteration 23650 - cost=9.955747\n",
      "Iteration 23660 - cost=9.996763\n",
      "Iteration 23670 - cost=10.739923\n",
      "Iteration 23680 - cost=9.272809\n",
      "Iteration 23690 - cost=10.800267\n",
      "Iteration 23700 - cost=10.123087\n",
      "Iteration 23710 - cost=9.162649\n",
      "Iteration 23720 - cost=8.800199\n",
      "Iteration 23730 - cost=10.578318\n",
      "Iteration 23740 - cost=10.037962\n",
      "Iteration 23750 - cost=9.241234\n",
      "Iteration 23760 - cost=9.218492\n",
      "Iteration 23770 - cost=9.578808\n",
      "Iteration 23780 - cost=10.731208\n",
      "Iteration 23790 - cost=9.052230\n",
      "Iteration 23800 - cost=9.589152\n",
      "Iteration 23810 - cost=10.350826\n",
      "Iteration 23820 - cost=9.106781\n",
      "Iteration 23830 - cost=10.881135\n",
      "Iteration 23840 - cost=10.031150\n",
      "Iteration 23850 - cost=8.970114\n",
      "Iteration 23860 - cost=9.724435\n",
      "Iteration 23870 - cost=11.426241\n",
      "Iteration 23880 - cost=9.344307\n",
      "Iteration 23890 - cost=10.302774\n",
      "Iteration 23900 - cost=9.849486\n",
      "Iteration 23910 - cost=11.467749\n",
      "Iteration 23920 - cost=10.863228\n",
      "Iteration 23930 - cost=9.614358\n",
      "Iteration 23940 - cost=10.134643\n",
      "Iteration 23950 - cost=10.383103\n",
      "Iteration 23960 - cost=11.292417\n",
      "Iteration 23970 - cost=9.915981\n",
      "Iteration 23980 - cost=10.088741\n",
      "Iteration 23990 - cost=9.522373\n",
      "Iteration 24000 - cost=11.369341\n",
      "Iteration 24010 - cost=10.412515\n",
      "Iteration 24020 - cost=9.498587\n",
      "Iteration 24030 - cost=10.284844\n",
      "Iteration 24040 - cost=9.835660\n",
      "Iteration 24050 - cost=10.277320\n",
      "Iteration 24060 - cost=10.412668\n",
      "Iteration 24070 - cost=10.630099\n",
      "Iteration 24080 - cost=9.269389\n",
      "Iteration 24090 - cost=9.800972\n",
      "Iteration 24100 - cost=10.024534\n",
      "Iteration 24110 - cost=9.809301\n",
      "Iteration 24120 - cost=10.859221\n",
      "Iteration 24130 - cost=9.304118\n",
      "Iteration 24140 - cost=9.391393\n",
      "Iteration 24150 - cost=9.889871\n",
      "Iteration 24160 - cost=8.958537\n",
      "Iteration 24170 - cost=10.249728\n",
      "Iteration 24180 - cost=9.172182\n",
      "Iteration 24190 - cost=9.988848\n",
      "Iteration 24200 - cost=9.863463\n",
      "Iteration 24210 - cost=9.625714\n",
      "Iteration 24220 - cost=11.187041\n",
      "Iteration 24230 - cost=9.627992\n",
      "Iteration 24240 - cost=9.472322\n",
      "Iteration 24250 - cost=9.127409\n",
      "Iteration 24260 - cost=8.800702\n",
      "Iteration 24270 - cost=10.667362\n",
      "Iteration 24280 - cost=9.279344\n",
      "Iteration 24290 - cost=9.466883\n",
      "Iteration 24300 - cost=10.453576\n",
      "Iteration 24310 - cost=9.626879\n",
      "Iteration 24320 - cost=10.071405\n",
      "Iteration 24330 - cost=10.285118\n",
      "Iteration 24340 - cost=8.854498\n",
      "Iteration 24350 - cost=8.480526\n",
      "Iteration 24360 - cost=11.044276\n",
      "Iteration 24370 - cost=9.907988\n",
      "Iteration 24380 - cost=11.393871\n",
      "Iteration 24390 - cost=10.554835\n",
      "Iteration 24400 - cost=7.859514\n",
      "Iteration 24410 - cost=10.115190\n",
      "Iteration 24420 - cost=9.215239\n",
      "Iteration 24430 - cost=10.910691\n",
      "Iteration 24440 - cost=11.225147\n",
      "Iteration 24450 - cost=10.623697\n",
      "Iteration 24460 - cost=8.170271\n",
      "Iteration 24470 - cost=10.469006\n",
      "Iteration 24480 - cost=9.082717\n",
      "Iteration 24490 - cost=10.996461\n",
      "Iteration 24500 - cost=9.671599\n",
      "Iteration 24510 - cost=8.970010\n",
      "Iteration 24520 - cost=9.284415\n",
      "Iteration 24530 - cost=10.182222\n",
      "Iteration 24540 - cost=9.905238\n",
      "Iteration 24550 - cost=9.679877\n",
      "Iteration 24560 - cost=9.017624\n",
      "Iteration 24570 - cost=10.636088\n",
      "Iteration 24580 - cost=9.481087\n",
      "Iteration 24590 - cost=11.066180\n",
      "Iteration 24600 - cost=9.764932\n",
      "Iteration 24610 - cost=9.518251\n",
      "Iteration 24620 - cost=9.114777\n",
      "Iteration 24630 - cost=9.818428\n",
      "Iteration 24640 - cost=10.538080\n",
      "Iteration 24650 - cost=11.372080\n",
      "Iteration 24660 - cost=10.811679\n",
      "Iteration 24670 - cost=10.170870\n",
      "Iteration 24680 - cost=11.629600\n",
      "Iteration 24690 - cost=9.257049\n",
      "Iteration 24700 - cost=10.366994\n",
      "Iteration 24710 - cost=10.537302\n",
      "Iteration 24720 - cost=8.172116\n",
      "Iteration 24730 - cost=10.955870\n",
      "Iteration 24740 - cost=9.418179\n",
      "Iteration 24750 - cost=9.376811\n",
      "Iteration 24760 - cost=9.738403\n",
      "Iteration 24770 - cost=10.957664\n",
      "Iteration 24780 - cost=10.457292\n",
      "Iteration 24790 - cost=10.474953\n",
      "Iteration 24800 - cost=12.214429\n",
      "Iteration 24810 - cost=9.241045\n",
      "Iteration 24820 - cost=9.283244\n",
      "Iteration 24830 - cost=9.319077\n",
      "Iteration 24840 - cost=9.141830\n",
      "Iteration 24850 - cost=8.538371\n",
      "Iteration 24860 - cost=10.170976\n",
      "Iteration 24870 - cost=10.751387\n",
      "Iteration 24880 - cost=9.323147\n",
      "Iteration 24890 - cost=8.852394\n",
      "Iteration 24900 - cost=9.764507\n",
      "Iteration 24910 - cost=10.154441\n",
      "Iteration 24920 - cost=9.178543\n",
      "Iteration 24930 - cost=9.863095\n",
      "Iteration 24940 - cost=8.656737\n",
      "Iteration 24950 - cost=9.395250\n",
      "Iteration 24960 - cost=10.565482\n",
      "Iteration 24970 - cost=9.600022\n",
      "Iteration 24980 - cost=8.673423\n",
      "Iteration 24990 - cost=10.822851\n",
      "Iteration 25000 - cost=10.052795\n",
      "Iteration 25010 - cost=10.328891\n",
      "Iteration 25020 - cost=9.988478\n",
      "Iteration 25030 - cost=8.194003\n",
      "Iteration 25040 - cost=10.447743\n",
      "Iteration 25050 - cost=10.550893\n",
      "Iteration 25060 - cost=8.601518\n",
      "Iteration 25070 - cost=9.004966\n",
      "Iteration 25080 - cost=10.811594\n",
      "Iteration 25090 - cost=9.657300\n",
      "Iteration 25100 - cost=10.698203\n",
      "Iteration 25110 - cost=9.207627\n",
      "Iteration 25120 - cost=10.451638\n",
      "Iteration 25130 - cost=10.384223\n",
      "Iteration 25140 - cost=10.213783\n",
      "Iteration 25150 - cost=12.062247\n",
      "Iteration 25160 - cost=11.529179\n",
      "Iteration 25170 - cost=9.303149\n",
      "Iteration 25180 - cost=8.906085\n",
      "Iteration 25190 - cost=10.370904\n",
      "Iteration 25200 - cost=9.116810\n",
      "Iteration 25210 - cost=8.583196\n",
      "Iteration 25220 - cost=9.764358\n",
      "Iteration 25230 - cost=8.564700\n",
      "Iteration 25240 - cost=10.938061\n",
      "Iteration 25250 - cost=10.185214\n",
      "Iteration 25260 - cost=9.696391\n",
      "Iteration 25270 - cost=8.013484\n",
      "Iteration 25280 - cost=11.340212\n",
      "Iteration 25290 - cost=9.861933\n",
      "Iteration 25300 - cost=9.210179\n",
      "Iteration 25310 - cost=9.626293\n",
      "Iteration 25320 - cost=12.050385\n",
      "Iteration 25330 - cost=10.264664\n",
      "Iteration 25340 - cost=10.693794\n",
      "Iteration 25350 - cost=11.938952\n",
      "Iteration 25360 - cost=10.328559\n",
      "Iteration 25370 - cost=9.668699\n",
      "Iteration 25380 - cost=9.634173\n",
      "Iteration 25390 - cost=10.019089\n",
      "Iteration 25400 - cost=11.078629\n",
      "Iteration 25410 - cost=9.096894\n",
      "Iteration 25420 - cost=10.453979\n",
      "Iteration 25430 - cost=10.005477\n",
      "Iteration 25440 - cost=11.253350\n",
      "Iteration 25450 - cost=9.671937\n",
      "Iteration 25460 - cost=10.147206\n",
      "Iteration 25470 - cost=11.266132\n",
      "Iteration 25480 - cost=9.801599\n",
      "Iteration 25490 - cost=10.358036\n",
      "Iteration 25500 - cost=10.223812\n",
      "Iteration 25510 - cost=9.572763\n",
      "Iteration 25520 - cost=9.213562\n",
      "Iteration 25530 - cost=10.170612\n",
      "Iteration 25540 - cost=9.680801\n",
      "Iteration 25550 - cost=9.218126\n",
      "Iteration 25560 - cost=9.560028\n",
      "Iteration 25570 - cost=9.823247\n",
      "Iteration 25580 - cost=9.890111\n",
      "Iteration 25590 - cost=11.005505\n",
      "Iteration 25600 - cost=9.805983\n",
      "Iteration 25610 - cost=10.104286\n",
      "Iteration 25620 - cost=8.484122\n",
      "Iteration 25630 - cost=10.363294\n",
      "Iteration 25640 - cost=9.559355\n",
      "Iteration 25650 - cost=8.559661\n",
      "Iteration 25660 - cost=8.272694\n",
      "Iteration 25670 - cost=9.821854\n",
      "Iteration 25680 - cost=10.193412\n",
      "Iteration 25690 - cost=10.441184\n",
      "Iteration 25700 - cost=9.679252\n",
      "Iteration 25710 - cost=9.526098\n",
      "Iteration 25720 - cost=10.250257\n",
      "Iteration 25730 - cost=10.080506\n",
      "Iteration 25740 - cost=9.629945\n",
      "Iteration 25750 - cost=9.782512\n",
      "Iteration 25760 - cost=10.699676\n",
      "Iteration 25770 - cost=10.138551\n",
      "Iteration 25780 - cost=9.155406\n",
      "Iteration 25790 - cost=10.742151\n",
      "Iteration 25800 - cost=10.095334\n",
      "Iteration 25810 - cost=10.427631\n",
      "Iteration 25820 - cost=9.466022\n",
      "Iteration 25830 - cost=10.103277\n",
      "Iteration 25840 - cost=10.065845\n",
      "Iteration 25850 - cost=10.298598\n",
      "Iteration 25860 - cost=9.069467\n",
      "Iteration 25870 - cost=9.842784\n",
      "Iteration 25880 - cost=12.117958\n",
      "Iteration 25890 - cost=9.464216\n",
      "Iteration 25900 - cost=8.789472\n",
      "Iteration 25910 - cost=9.943496\n",
      "Iteration 25920 - cost=9.356101\n",
      "Iteration 25930 - cost=9.786560\n",
      "Iteration 25940 - cost=9.580417\n",
      "Iteration 25950 - cost=11.304041\n",
      "Iteration 25960 - cost=9.137825\n",
      "Iteration 25970 - cost=11.190813\n",
      "Iteration 25980 - cost=9.320648\n",
      "Iteration 25990 - cost=8.236393\n",
      "Iteration 26000 - cost=9.888562\n",
      "Iteration 26010 - cost=8.470481\n",
      "Iteration 26020 - cost=10.216052\n",
      "Iteration 26030 - cost=10.689251\n",
      "Iteration 26040 - cost=10.264147\n",
      "Iteration 26050 - cost=10.860352\n",
      "Iteration 26060 - cost=9.148264\n",
      "Iteration 26070 - cost=10.558664\n",
      "Iteration 26080 - cost=10.735304\n",
      "Iteration 26090 - cost=9.823742\n",
      "Iteration 26100 - cost=10.709646\n",
      "Iteration 26110 - cost=11.422612\n",
      "Iteration 26120 - cost=7.985639\n",
      "Iteration 26130 - cost=10.160211\n",
      "Iteration 26140 - cost=9.781306\n",
      "Iteration 26150 - cost=8.793842\n",
      "Iteration 26160 - cost=11.101474\n",
      "Iteration 26170 - cost=9.690804\n",
      "Iteration 26180 - cost=8.742881\n",
      "Iteration 26190 - cost=10.066151\n",
      "Iteration 26200 - cost=10.048097\n",
      "Iteration 26210 - cost=10.182763\n",
      "Iteration 26220 - cost=9.055559\n",
      "Iteration 26230 - cost=8.928099\n",
      "Iteration 26240 - cost=10.006218\n",
      "Iteration 26250 - cost=9.152593\n",
      "Iteration 26260 - cost=10.321243\n",
      "Iteration 26270 - cost=10.721031\n",
      "Iteration 26280 - cost=8.118907\n",
      "Iteration 26290 - cost=9.438082\n",
      "Iteration 26300 - cost=8.611014\n",
      "Iteration 26310 - cost=10.256201\n",
      "Iteration 26320 - cost=9.875605\n",
      "Iteration 26330 - cost=9.912226\n",
      "Iteration 26340 - cost=10.636061\n",
      "Iteration 26350 - cost=10.523395\n",
      "Iteration 26360 - cost=9.905995\n",
      "Iteration 26370 - cost=10.209631\n",
      "Iteration 26380 - cost=9.602120\n",
      "Iteration 26390 - cost=10.273390\n",
      "Iteration 26400 - cost=9.864426\n",
      "Iteration 26410 - cost=9.737045\n",
      "Iteration 26420 - cost=8.889978\n",
      "Iteration 26430 - cost=9.758279\n",
      "Iteration 26440 - cost=10.239057\n",
      "Iteration 26450 - cost=8.896823\n",
      "Iteration 26460 - cost=10.443040\n",
      "Iteration 26470 - cost=8.703258\n",
      "Iteration 26480 - cost=11.436756\n",
      "Iteration 26490 - cost=8.470020\n",
      "Iteration 26500 - cost=9.662599\n",
      "Iteration 26510 - cost=9.653157\n",
      "Iteration 26520 - cost=11.564295\n",
      "Iteration 26530 - cost=9.210777\n",
      "Iteration 26540 - cost=10.433549\n",
      "Iteration 26550 - cost=9.425267\n",
      "Iteration 26560 - cost=10.308824\n",
      "Iteration 26570 - cost=9.763691\n",
      "Iteration 26580 - cost=9.429686\n",
      "Iteration 26590 - cost=9.215340\n",
      "Iteration 26600 - cost=9.949473\n",
      "Iteration 26610 - cost=12.088915\n",
      "Iteration 26620 - cost=11.170267\n",
      "Iteration 26630 - cost=9.083109\n",
      "Iteration 26640 - cost=9.683108\n",
      "Iteration 26650 - cost=10.347115\n",
      "Iteration 26660 - cost=10.786020\n",
      "Iteration 26670 - cost=10.462479\n",
      "Iteration 26680 - cost=9.312469\n",
      "Iteration 26690 - cost=8.569828\n",
      "Iteration 26700 - cost=9.485972\n",
      "Iteration 26710 - cost=8.244944\n",
      "Iteration 26720 - cost=9.628757\n",
      "Iteration 26730 - cost=10.040623\n",
      "Iteration 26740 - cost=9.041951\n",
      "Iteration 26750 - cost=10.544384\n",
      "Iteration 26760 - cost=9.608368\n",
      "Iteration 26770 - cost=10.316129\n",
      "Iteration 26780 - cost=10.050032\n",
      "Iteration 26790 - cost=11.249984\n",
      "Iteration 26800 - cost=10.098491\n",
      "Iteration 26810 - cost=8.373809\n",
      "Iteration 26820 - cost=9.793956\n",
      "Iteration 26830 - cost=10.181176\n",
      "Iteration 26840 - cost=9.792786\n",
      "Iteration 26850 - cost=8.831112\n",
      "Iteration 26860 - cost=9.752802\n",
      "Iteration 26870 - cost=10.783727\n",
      "Iteration 26880 - cost=9.287551\n",
      "Iteration 26890 - cost=9.906827\n",
      "Iteration 26900 - cost=9.804123\n",
      "Iteration 26910 - cost=10.205045\n",
      "Iteration 26920 - cost=10.850008\n",
      "Iteration 26930 - cost=9.479656\n",
      "Iteration 26940 - cost=8.426518\n",
      "Iteration 26950 - cost=10.021037\n",
      "Iteration 26960 - cost=10.746608\n",
      "Iteration 26970 - cost=9.922818\n",
      "Iteration 26980 - cost=9.491771\n",
      "Iteration 26990 - cost=10.753281\n",
      "Iteration 27000 - cost=8.784199\n",
      "Iteration 27010 - cost=9.933934\n",
      "Iteration 27020 - cost=10.285020\n",
      "Iteration 27030 - cost=9.834239\n",
      "Iteration 27040 - cost=10.107734\n",
      "Iteration 27050 - cost=8.897387\n",
      "Iteration 27060 - cost=9.080629\n",
      "Iteration 27070 - cost=9.945179\n",
      "Iteration 27080 - cost=10.100935\n",
      "Iteration 27090 - cost=9.938965\n",
      "Iteration 27100 - cost=10.372607\n",
      "Iteration 27110 - cost=10.392143\n",
      "Iteration 27120 - cost=11.313426\n",
      "Iteration 27130 - cost=10.309498\n",
      "Iteration 27140 - cost=9.118434\n",
      "Iteration 27150 - cost=9.622087\n",
      "Iteration 27160 - cost=9.120138\n",
      "Iteration 27170 - cost=9.249773\n",
      "Iteration 27180 - cost=9.761617\n",
      "Iteration 27190 - cost=10.510278\n",
      "Iteration 27200 - cost=9.266436\n",
      "Iteration 27210 - cost=9.519072\n",
      "Iteration 27220 - cost=7.556587\n",
      "Iteration 27230 - cost=9.855441\n",
      "Iteration 27240 - cost=9.779060\n",
      "Iteration 27250 - cost=9.615346\n",
      "Iteration 27260 - cost=10.151925\n",
      "Iteration 27270 - cost=9.488797\n",
      "Iteration 27280 - cost=8.955980\n",
      "Iteration 27290 - cost=10.365093\n",
      "Iteration 27300 - cost=10.020918\n",
      "Iteration 27310 - cost=9.309732\n",
      "Iteration 27320 - cost=8.388618\n",
      "Iteration 27330 - cost=7.177089\n",
      "Iteration 27340 - cost=9.085675\n",
      "Iteration 27350 - cost=9.549943\n",
      "Iteration 27360 - cost=9.837463\n",
      "Iteration 27370 - cost=12.484475\n",
      "Iteration 27380 - cost=9.112279\n",
      "Iteration 27390 - cost=9.770504\n",
      "Iteration 27400 - cost=9.043742\n",
      "Iteration 27410 - cost=10.111628\n",
      "Iteration 27420 - cost=8.757144\n",
      "Iteration 27430 - cost=9.957314\n",
      "Iteration 27440 - cost=9.893092\n",
      "Iteration 27450 - cost=9.328165\n",
      "Iteration 27460 - cost=8.803376\n",
      "Iteration 27470 - cost=8.624365\n",
      "Iteration 27480 - cost=10.939604\n",
      "Iteration 27490 - cost=11.555306\n",
      "Iteration 27500 - cost=8.968595\n",
      "Iteration 27510 - cost=10.865833\n",
      "Iteration 27520 - cost=9.299199\n",
      "Iteration 27530 - cost=10.126785\n",
      "Iteration 27540 - cost=8.137541\n",
      "Iteration 27550 - cost=11.670959\n",
      "Iteration 27560 - cost=11.155004\n",
      "Iteration 27570 - cost=9.372578\n",
      "Iteration 27580 - cost=11.067597\n",
      "Iteration 27590 - cost=9.193793\n",
      "Iteration 27600 - cost=11.755402\n",
      "Iteration 27610 - cost=10.369914\n",
      "Iteration 27620 - cost=9.042982\n",
      "Iteration 27630 - cost=9.699009\n",
      "Iteration 27640 - cost=9.024354\n",
      "Iteration 27650 - cost=9.589102\n",
      "Iteration 27660 - cost=9.812953\n",
      "Iteration 27670 - cost=10.925311\n",
      "Iteration 27680 - cost=11.287746\n",
      "Iteration 27690 - cost=9.856281\n",
      "Iteration 27700 - cost=9.134750\n",
      "Iteration 27710 - cost=9.910959\n",
      "Iteration 27720 - cost=8.741468\n",
      "Iteration 27730 - cost=9.528731\n",
      "Iteration 27740 - cost=11.534672\n",
      "Iteration 27750 - cost=9.688248\n",
      "Iteration 27760 - cost=8.696571\n",
      "Iteration 27770 - cost=9.179986\n",
      "Iteration 27780 - cost=9.669311\n",
      "Iteration 27790 - cost=10.008648\n",
      "Iteration 27800 - cost=8.955097\n",
      "Iteration 27810 - cost=9.426261\n",
      "Iteration 27820 - cost=10.341577\n",
      "Iteration 27830 - cost=10.209908\n",
      "Iteration 27840 - cost=9.352638\n",
      "Iteration 27850 - cost=9.586377\n",
      "Iteration 27860 - cost=8.456619\n",
      "Iteration 27870 - cost=9.430214\n",
      "Iteration 27880 - cost=9.491154\n",
      "Iteration 27890 - cost=9.494919\n",
      "Iteration 27900 - cost=9.716874\n",
      "Iteration 27910 - cost=10.017756\n",
      "Iteration 27920 - cost=10.209537\n",
      "Iteration 27930 - cost=9.965824\n",
      "Iteration 27940 - cost=9.929645\n",
      "Iteration 27950 - cost=10.181884\n",
      "Iteration 27960 - cost=11.139558\n",
      "Iteration 27970 - cost=10.399276\n",
      "Iteration 27980 - cost=9.194519\n",
      "Iteration 27990 - cost=9.770346\n",
      "Iteration 28000 - cost=9.768656\n",
      "Iteration 28010 - cost=10.686737\n",
      "Iteration 28020 - cost=9.579486\n",
      "Iteration 28030 - cost=8.837393\n",
      "Iteration 28040 - cost=10.522286\n",
      "Iteration 28050 - cost=8.555692\n",
      "Iteration 28060 - cost=8.158393\n",
      "Iteration 28070 - cost=10.703403\n",
      "Iteration 28080 - cost=9.144078\n",
      "Iteration 28090 - cost=8.152759\n",
      "Iteration 28100 - cost=10.660340\n",
      "Iteration 28110 - cost=10.030875\n",
      "Iteration 28120 - cost=9.355860\n",
      "Iteration 28130 - cost=10.356447\n",
      "Iteration 28140 - cost=9.898230\n",
      "Iteration 28150 - cost=8.937366\n",
      "Iteration 28160 - cost=9.706907\n",
      "Iteration 28170 - cost=10.131039\n",
      "Iteration 28180 - cost=10.537583\n",
      "Iteration 28190 - cost=9.280243\n",
      "Iteration 28200 - cost=10.217615\n",
      "Iteration 28210 - cost=10.331734\n",
      "Iteration 28220 - cost=9.793380\n",
      "Iteration 28230 - cost=8.431938\n",
      "Iteration 28240 - cost=9.862460\n",
      "Iteration 28250 - cost=9.444155\n",
      "Iteration 28260 - cost=10.819362\n",
      "Iteration 28270 - cost=9.850174\n",
      "Iteration 28280 - cost=10.948329\n",
      "Iteration 28290 - cost=10.444899\n",
      "Iteration 28300 - cost=9.662594\n",
      "Iteration 28310 - cost=10.110195\n",
      "Iteration 28320 - cost=9.603584\n",
      "Iteration 28330 - cost=10.043937\n",
      "Iteration 28340 - cost=9.358298\n",
      "Iteration 28350 - cost=8.773448\n",
      "Iteration 28360 - cost=8.892436\n",
      "Iteration 28370 - cost=9.830754\n",
      "Iteration 28380 - cost=9.720821\n",
      "Iteration 28390 - cost=10.029073\n",
      "Iteration 28400 - cost=8.653731\n",
      "Iteration 28410 - cost=10.106773\n",
      "Iteration 28420 - cost=9.236127\n",
      "Iteration 28430 - cost=9.539170\n",
      "Iteration 28440 - cost=9.552068\n",
      "Iteration 28450 - cost=9.359797\n",
      "Iteration 28460 - cost=10.328468\n",
      "Iteration 28470 - cost=11.597217\n",
      "Iteration 28480 - cost=9.640212\n",
      "Iteration 28490 - cost=8.578066\n",
      "Iteration 28500 - cost=9.427765\n",
      "Iteration 28510 - cost=10.089988\n",
      "Iteration 28520 - cost=9.565811\n",
      "Iteration 28530 - cost=8.966355\n",
      "Iteration 28540 - cost=9.751169\n",
      "Iteration 28550 - cost=9.264517\n",
      "Iteration 28560 - cost=9.484452\n",
      "Iteration 28570 - cost=10.028348\n",
      "Iteration 28580 - cost=9.774502\n",
      "Iteration 28590 - cost=9.755347\n",
      "Iteration 28600 - cost=11.002649\n",
      "Iteration 28610 - cost=10.767854\n",
      "Iteration 28620 - cost=8.846217\n",
      "Iteration 28630 - cost=9.953604\n",
      "Iteration 28640 - cost=9.026693\n",
      "Iteration 28650 - cost=9.025247\n",
      "Iteration 28660 - cost=8.229310\n",
      "Iteration 28670 - cost=7.022656\n",
      "Iteration 28680 - cost=9.719208\n",
      "Iteration 28690 - cost=9.500617\n",
      "Iteration 28700 - cost=10.254191\n",
      "Iteration 28710 - cost=9.022572\n",
      "Iteration 28720 - cost=8.388584\n",
      "Iteration 28730 - cost=9.899088\n",
      "Iteration 28740 - cost=9.474025\n",
      "Iteration 28750 - cost=11.361270\n",
      "Iteration 28760 - cost=9.818570\n",
      "Iteration 28770 - cost=8.513090\n",
      "Iteration 28780 - cost=10.780328\n",
      "Iteration 28790 - cost=9.677339\n",
      "Iteration 28800 - cost=10.562456\n",
      "Iteration 28810 - cost=11.493382\n",
      "Iteration 28820 - cost=9.739952\n",
      "Iteration 28830 - cost=10.099783\n",
      "Iteration 28840 - cost=10.085983\n",
      "Iteration 28850 - cost=9.959444\n",
      "Iteration 28860 - cost=9.626021\n",
      "Iteration 28870 - cost=11.545676\n",
      "Iteration 28880 - cost=10.371850\n",
      "Iteration 28890 - cost=8.596930\n",
      "Iteration 28900 - cost=10.958322\n",
      "Iteration 28910 - cost=9.004747\n",
      "Iteration 28920 - cost=10.379831\n",
      "Iteration 28930 - cost=8.276045\n",
      "Iteration 28940 - cost=9.408882\n",
      "Iteration 28950 - cost=9.858884\n",
      "Iteration 28960 - cost=9.731669\n",
      "Iteration 28970 - cost=10.661645\n",
      "Iteration 28980 - cost=10.962256\n",
      "Iteration 28990 - cost=10.595393\n",
      "Iteration 29000 - cost=10.065664\n",
      "Iteration 29010 - cost=9.906595\n",
      "Iteration 29020 - cost=10.590012\n",
      "Iteration 29030 - cost=11.419272\n",
      "Iteration 29040 - cost=8.984101\n",
      "Iteration 29050 - cost=9.606520\n",
      "Iteration 29060 - cost=9.235837\n",
      "Iteration 29070 - cost=10.096531\n",
      "Iteration 29080 - cost=10.720569\n",
      "Iteration 29090 - cost=11.569929\n",
      "Iteration 29100 - cost=10.075791\n",
      "Iteration 29110 - cost=11.405153\n",
      "Iteration 29120 - cost=10.668597\n",
      "Iteration 29130 - cost=10.671720\n",
      "Iteration 29140 - cost=10.790838\n",
      "Iteration 29150 - cost=9.569634\n",
      "Iteration 29160 - cost=11.223947\n",
      "Iteration 29170 - cost=9.232301\n",
      "Iteration 29180 - cost=9.771833\n",
      "Iteration 29190 - cost=9.436951\n",
      "Iteration 29200 - cost=9.829666\n",
      "Iteration 29210 - cost=9.819750\n",
      "Iteration 29220 - cost=9.307204\n",
      "Iteration 29230 - cost=9.954115\n",
      "Iteration 29240 - cost=9.262600\n",
      "Iteration 29250 - cost=9.625998\n",
      "Iteration 29260 - cost=10.962834\n",
      "Iteration 29270 - cost=8.515159\n",
      "Iteration 29280 - cost=9.521737\n",
      "Iteration 29290 - cost=9.747345\n",
      "Iteration 29300 - cost=11.120911\n",
      "Iteration 29310 - cost=9.294749\n",
      "Iteration 29320 - cost=9.133727\n",
      "Iteration 29330 - cost=9.384205\n",
      "Iteration 29340 - cost=11.019869\n",
      "Iteration 29350 - cost=9.415500\n",
      "Iteration 29360 - cost=9.945030\n",
      "Iteration 29370 - cost=10.231431\n",
      "Iteration 29380 - cost=8.692493\n",
      "Iteration 29390 - cost=9.549884\n",
      "Iteration 29400 - cost=8.714175\n",
      "Iteration 29410 - cost=9.156157\n",
      "Iteration 29420 - cost=9.003851\n",
      "Iteration 29430 - cost=8.415919\n",
      "Iteration 29440 - cost=9.534479\n",
      "Iteration 29450 - cost=9.764338\n",
      "Iteration 29460 - cost=9.700115\n",
      "Iteration 29470 - cost=9.990238\n",
      "Iteration 29480 - cost=8.895428\n",
      "Iteration 29490 - cost=10.794052\n",
      "Iteration 29500 - cost=11.066657\n",
      "Iteration 29510 - cost=9.541449\n",
      "Iteration 29520 - cost=9.524903\n",
      "Iteration 29530 - cost=10.894340\n",
      "Iteration 29540 - cost=10.554104\n",
      "Iteration 29550 - cost=12.371567\n",
      "Iteration 29560 - cost=9.537610\n",
      "Iteration 29570 - cost=8.204675\n",
      "Iteration 29580 - cost=10.772230\n",
      "Iteration 29590 - cost=10.290908\n",
      "Iteration 29600 - cost=9.636736\n",
      "Iteration 29610 - cost=9.196922\n",
      "Iteration 29620 - cost=9.115303\n",
      "Iteration 29630 - cost=9.054732\n",
      "Iteration 29640 - cost=10.180620\n",
      "Iteration 29650 - cost=9.573640\n",
      "Iteration 29660 - cost=8.371229\n",
      "Iteration 29670 - cost=10.414665\n",
      "Iteration 29680 - cost=11.255842\n",
      "Iteration 29690 - cost=9.913852\n",
      "Iteration 29700 - cost=10.121721\n",
      "Iteration 29710 - cost=10.108981\n",
      "Iteration 29720 - cost=8.529812\n",
      "Iteration 29730 - cost=9.187128\n",
      "Iteration 29740 - cost=10.957818\n",
      "Iteration 29750 - cost=9.243366\n",
      "Iteration 29760 - cost=10.144915\n",
      "Iteration 29770 - cost=10.079970\n",
      "Iteration 29780 - cost=7.819377\n",
      "Iteration 29790 - cost=8.494777\n",
      "Iteration 29800 - cost=9.295411\n",
      "Iteration 29810 - cost=8.402731\n",
      "Iteration 29820 - cost=8.648962\n",
      "Iteration 29830 - cost=8.732351\n",
      "Iteration 29840 - cost=9.520209\n",
      "Iteration 29850 - cost=10.373247\n",
      "Iteration 29860 - cost=10.041256\n",
      "Iteration 29870 - cost=9.515584\n",
      "Iteration 29880 - cost=9.285702\n",
      "Iteration 29890 - cost=9.311949\n",
      "Iteration 29900 - cost=9.049095\n",
      "Iteration 29910 - cost=8.967513\n",
      "Iteration 29920 - cost=9.349782\n",
      "Iteration 29930 - cost=10.005992\n",
      "Iteration 29940 - cost=10.342476\n",
      "Iteration 29950 - cost=8.474476\n",
      "Iteration 29960 - cost=10.247453\n",
      "Iteration 29970 - cost=9.952071\n",
      "Iteration 29980 - cost=10.104119\n",
      "Iteration 29990 - cost=10.674689\n",
      "Iteration 30000 - cost=8.888303\n",
      "Iteration 30010 - cost=11.903326\n",
      "Iteration 30020 - cost=10.802134\n",
      "Iteration 30030 - cost=10.253569\n",
      "Iteration 30040 - cost=10.652676\n",
      "Iteration 30050 - cost=10.190793\n",
      "Iteration 30060 - cost=9.181553\n",
      "Iteration 30070 - cost=10.645453\n",
      "Iteration 30080 - cost=9.695955\n",
      "Iteration 30090 - cost=10.401406\n",
      "Iteration 30100 - cost=9.255807\n",
      "Iteration 30110 - cost=9.822881\n",
      "Iteration 30120 - cost=9.567200\n",
      "Iteration 30130 - cost=9.282830\n",
      "Iteration 30140 - cost=9.665868\n",
      "Iteration 30150 - cost=11.682405\n",
      "Iteration 30160 - cost=8.826089\n",
      "Iteration 30170 - cost=10.162780\n",
      "Iteration 30180 - cost=10.270526\n",
      "Iteration 30190 - cost=9.802553\n",
      "Iteration 30200 - cost=10.027677\n",
      "Iteration 30210 - cost=10.400336\n",
      "Iteration 30220 - cost=9.236421\n",
      "Iteration 30230 - cost=9.395105\n",
      "Iteration 30240 - cost=10.645625\n",
      "Iteration 30250 - cost=9.954783\n",
      "Iteration 30260 - cost=10.543223\n",
      "Iteration 30270 - cost=9.136300\n",
      "Iteration 30280 - cost=10.996352\n",
      "Iteration 30290 - cost=9.590067\n",
      "Iteration 30300 - cost=10.086594\n",
      "Iteration 30310 - cost=10.410727\n",
      "Iteration 30320 - cost=10.219592\n",
      "Iteration 30330 - cost=10.019841\n",
      "Iteration 30340 - cost=11.051847\n",
      "Iteration 30350 - cost=10.974962\n",
      "Iteration 30360 - cost=9.881116\n",
      "Iteration 30370 - cost=9.549390\n",
      "Iteration 30380 - cost=9.536094\n",
      "Iteration 30390 - cost=8.876038\n",
      "Iteration 30400 - cost=8.849048\n",
      "Iteration 30410 - cost=8.751954\n",
      "Iteration 30420 - cost=8.656036\n",
      "Iteration 30430 - cost=11.057426\n",
      "Iteration 30440 - cost=9.416395\n",
      "Iteration 30450 - cost=9.896678\n",
      "Iteration 30460 - cost=10.056172\n",
      "Iteration 30470 - cost=10.217921\n",
      "Iteration 30480 - cost=8.961912\n",
      "Iteration 30490 - cost=10.480374\n",
      "Iteration 30500 - cost=8.590775\n",
      "Iteration 30510 - cost=10.185324\n",
      "Iteration 30520 - cost=8.524741\n",
      "Iteration 30530 - cost=9.995919\n",
      "Iteration 30540 - cost=9.346483\n",
      "Iteration 30550 - cost=9.035820\n",
      "Iteration 30560 - cost=10.463595\n",
      "Iteration 30570 - cost=9.923665\n",
      "Iteration 30580 - cost=9.376282\n",
      "Iteration 30590 - cost=10.483496\n",
      "Iteration 30600 - cost=10.368361\n",
      "Iteration 30610 - cost=8.311888\n",
      "Iteration 30620 - cost=7.847886\n",
      "Iteration 30630 - cost=10.042286\n",
      "Iteration 30640 - cost=9.969022\n",
      "Iteration 30650 - cost=9.851083\n",
      "Iteration 30660 - cost=9.135474\n",
      "Iteration 30670 - cost=9.909728\n",
      "Iteration 30680 - cost=10.281898\n",
      "Iteration 30690 - cost=11.284940\n",
      "Iteration 30700 - cost=9.512039\n",
      "Iteration 30710 - cost=10.211455\n",
      "Iteration 30720 - cost=10.266828\n",
      "Iteration 30730 - cost=9.067486\n",
      "Iteration 30740 - cost=9.611756\n",
      "Iteration 30750 - cost=11.298775\n",
      "Iteration 30760 - cost=10.694862\n",
      "Iteration 30770 - cost=10.091524\n",
      "Iteration 30780 - cost=10.373635\n",
      "Iteration 30790 - cost=9.209008\n",
      "Iteration 30800 - cost=10.096021\n",
      "Iteration 30810 - cost=9.570387\n",
      "Iteration 30820 - cost=10.872810\n",
      "Iteration 30830 - cost=10.389247\n",
      "Iteration 30840 - cost=10.339740\n",
      "Iteration 30850 - cost=10.138255\n",
      "Iteration 30860 - cost=9.078538\n",
      "Iteration 30870 - cost=10.152807\n",
      "Iteration 30880 - cost=8.059351\n",
      "Iteration 30890 - cost=10.861127\n",
      "Iteration 30900 - cost=10.454684\n",
      "Iteration 30910 - cost=10.860653\n",
      "Iteration 30920 - cost=10.198348\n",
      "Iteration 30930 - cost=10.954104\n",
      "Iteration 30940 - cost=10.616946\n",
      "Iteration 30950 - cost=10.239427\n",
      "Iteration 30960 - cost=9.153443\n",
      "Iteration 30970 - cost=8.716620\n",
      "Iteration 30980 - cost=9.446237\n",
      "Iteration 30990 - cost=10.707686\n",
      "Iteration 31000 - cost=9.352873\n",
      "Iteration 31010 - cost=9.968872\n",
      "Iteration 31020 - cost=10.492533\n",
      "Iteration 31030 - cost=9.183756\n",
      "Iteration 31040 - cost=9.611399\n",
      "Iteration 31050 - cost=9.903203\n",
      "Iteration 31060 - cost=9.293467\n",
      "Iteration 31070 - cost=10.976196\n",
      "Iteration 31080 - cost=9.399065\n",
      "Iteration 31090 - cost=11.239618\n",
      "Iteration 31100 - cost=8.875356\n",
      "Iteration 31110 - cost=8.795904\n",
      "Iteration 31120 - cost=10.545190\n",
      "Iteration 31130 - cost=9.875422\n",
      "Iteration 31140 - cost=10.488830\n",
      "Iteration 31150 - cost=11.355202\n",
      "Iteration 31160 - cost=10.827266\n",
      "Iteration 31170 - cost=9.074817\n",
      "Iteration 31180 - cost=9.055333\n",
      "Iteration 31190 - cost=10.791991\n",
      "Iteration 31200 - cost=10.273887\n",
      "Iteration 31210 - cost=10.531626\n",
      "Iteration 31220 - cost=10.285563\n",
      "Iteration 31230 - cost=9.218596\n",
      "Iteration 31240 - cost=9.297764\n",
      "Iteration 31250 - cost=9.490090\n",
      "Iteration 31260 - cost=10.229651\n",
      "Iteration 31270 - cost=9.766941\n",
      "Iteration 31280 - cost=10.686049\n",
      "Iteration 31290 - cost=9.018903\n",
      "Iteration 31300 - cost=8.267896\n",
      "Iteration 31310 - cost=9.944829\n",
      "Iteration 31320 - cost=9.379911\n",
      "Iteration 31330 - cost=10.244128\n",
      "Iteration 31340 - cost=9.931246\n",
      "Iteration 31350 - cost=10.138115\n",
      "Iteration 31360 - cost=10.161096\n",
      "Iteration 31370 - cost=10.415575\n",
      "Iteration 31380 - cost=10.037864\n",
      "Iteration 31390 - cost=9.972466\n",
      "Iteration 31400 - cost=10.876624\n",
      "Iteration 31410 - cost=10.441507\n",
      "Iteration 31420 - cost=9.206030\n",
      "Iteration 31430 - cost=9.151935\n",
      "Iteration 31440 - cost=9.466320\n",
      "Iteration 31450 - cost=8.958370\n",
      "Iteration 31460 - cost=8.747383\n",
      "Iteration 31470 - cost=8.786514\n",
      "Iteration 31480 - cost=10.029241\n",
      "Iteration 31490 - cost=9.407689\n",
      "Iteration 31500 - cost=10.839028\n",
      "Iteration 31510 - cost=9.325329\n",
      "Iteration 31520 - cost=9.966502\n",
      "Iteration 31530 - cost=8.359184\n",
      "Iteration 31540 - cost=10.243375\n",
      "Iteration 31550 - cost=11.211641\n",
      "Iteration 31560 - cost=10.303318\n",
      "Iteration 31570 - cost=11.654518\n",
      "Iteration 31580 - cost=9.237364\n",
      "Iteration 31590 - cost=9.539556\n",
      "Iteration 31600 - cost=8.398799\n",
      "Iteration 31610 - cost=11.356981\n",
      "Iteration 31620 - cost=9.145802\n",
      "Iteration 31630 - cost=10.268366\n",
      "Iteration 31640 - cost=8.331888\n",
      "Iteration 31650 - cost=9.946458\n",
      "Iteration 31660 - cost=8.943814\n",
      "Iteration 31670 - cost=9.683604\n",
      "Iteration 31680 - cost=9.170285\n",
      "Iteration 31690 - cost=9.033554\n",
      "Iteration 31700 - cost=7.937672\n",
      "Iteration 31710 - cost=9.087738\n",
      "Iteration 31720 - cost=8.889209\n",
      "Iteration 31730 - cost=8.907069\n",
      "Iteration 31740 - cost=10.241782\n",
      "Iteration 31750 - cost=10.189743\n",
      "Iteration 31760 - cost=9.814419\n",
      "Iteration 31770 - cost=10.672932\n",
      "Iteration 31780 - cost=9.390587\n",
      "Iteration 31790 - cost=10.603155\n",
      "Iteration 31800 - cost=10.255668\n",
      "Iteration 31810 - cost=9.260473\n",
      "Iteration 31820 - cost=10.794898\n",
      "Iteration 31830 - cost=9.348541\n",
      "Iteration 31840 - cost=8.813644\n",
      "Iteration 31850 - cost=8.752057\n",
      "Iteration 31860 - cost=8.421119\n",
      "Iteration 31870 - cost=9.917592\n",
      "Iteration 31880 - cost=10.509197\n",
      "Iteration 31890 - cost=7.980694\n",
      "Iteration 31900 - cost=9.736425\n",
      "Iteration 31910 - cost=8.864127\n",
      "Iteration 31920 - cost=9.001448\n",
      "Iteration 31930 - cost=11.261481\n",
      "Iteration 31940 - cost=10.387126\n",
      "Iteration 31950 - cost=9.268673\n",
      "Iteration 31960 - cost=10.393298\n",
      "Iteration 31970 - cost=10.184617\n",
      "Iteration 31980 - cost=10.488391\n",
      "Iteration 31990 - cost=10.411032\n",
      "Iteration 32000 - cost=9.581274\n",
      "Iteration 32010 - cost=10.534115\n",
      "Iteration 32020 - cost=9.493884\n",
      "Iteration 32030 - cost=9.302106\n",
      "Iteration 32040 - cost=8.918000\n",
      "Iteration 32050 - cost=10.187688\n",
      "Iteration 32060 - cost=9.644457\n",
      "Iteration 32070 - cost=8.871023\n",
      "Iteration 32080 - cost=8.329968\n",
      "Iteration 32090 - cost=9.699238\n",
      "Iteration 32100 - cost=9.820655\n",
      "Iteration 32110 - cost=9.747797\n",
      "Iteration 32120 - cost=10.061329\n",
      "Iteration 32130 - cost=8.649109\n",
      "Iteration 32140 - cost=9.098357\n",
      "Iteration 32150 - cost=8.427773\n",
      "Iteration 32160 - cost=9.702685\n",
      "Iteration 32170 - cost=10.781329\n",
      "Iteration 32180 - cost=9.364993\n",
      "Iteration 32190 - cost=9.975923\n",
      "Iteration 32200 - cost=9.255476\n",
      "Iteration 32210 - cost=9.807970\n",
      "Iteration 32220 - cost=9.501670\n",
      "Iteration 32230 - cost=9.906386\n",
      "Iteration 32240 - cost=9.860273\n",
      "Iteration 32250 - cost=7.664299\n",
      "Iteration 32260 - cost=9.010011\n",
      "Iteration 32270 - cost=10.421917\n",
      "Iteration 32280 - cost=9.216207\n",
      "Iteration 32290 - cost=9.986789\n",
      "Iteration 32300 - cost=9.465370\n",
      "Iteration 32310 - cost=10.291343\n",
      "Iteration 32320 - cost=10.088984\n",
      "Iteration 32330 - cost=10.380801\n",
      "Iteration 32340 - cost=9.588818\n",
      "Iteration 32350 - cost=10.934070\n",
      "Iteration 32360 - cost=9.515692\n",
      "Iteration 32370 - cost=10.323321\n",
      "Iteration 32380 - cost=9.031802\n",
      "Iteration 32390 - cost=8.070590\n",
      "Iteration 32400 - cost=11.322000\n",
      "Iteration 32410 - cost=10.454393\n",
      "Iteration 32420 - cost=9.969813\n",
      "Iteration 32430 - cost=10.381914\n",
      "Iteration 32440 - cost=10.716702\n",
      "Iteration 32450 - cost=10.098799\n",
      "Iteration 32460 - cost=9.669169\n",
      "Iteration 32470 - cost=10.069960\n",
      "Iteration 32480 - cost=9.985364\n",
      "Iteration 32490 - cost=9.993416\n",
      "Iteration 32500 - cost=8.651809\n",
      "Iteration 32510 - cost=9.588838\n",
      "Iteration 32520 - cost=8.235774\n",
      "Iteration 32530 - cost=9.467615\n",
      "Iteration 32540 - cost=8.844978\n",
      "Iteration 32550 - cost=11.235035\n",
      "Iteration 32560 - cost=8.603567\n",
      "Iteration 32570 - cost=11.009198\n",
      "Iteration 32580 - cost=9.563712\n",
      "Iteration 32590 - cost=9.001193\n",
      "Iteration 32600 - cost=9.350429\n",
      "Iteration 32610 - cost=9.854716\n",
      "Iteration 32620 - cost=10.404270\n",
      "Iteration 32630 - cost=9.703084\n",
      "Iteration 32640 - cost=9.544352\n",
      "Iteration 32650 - cost=11.329836\n",
      "Iteration 32660 - cost=9.411118\n",
      "Iteration 32670 - cost=9.662815\n",
      "Iteration 32680 - cost=9.335689\n",
      "Iteration 32690 - cost=8.829562\n",
      "Iteration 32700 - cost=10.558602\n",
      "Iteration 32710 - cost=9.163893\n",
      "Iteration 32720 - cost=9.348062\n",
      "Iteration 32730 - cost=10.807157\n",
      "Iteration 32740 - cost=9.598940\n",
      "Iteration 32750 - cost=8.010904\n",
      "Iteration 32760 - cost=7.813092\n",
      "Iteration 32770 - cost=10.422830\n",
      "Iteration 32780 - cost=8.440471\n",
      "Iteration 32790 - cost=10.364867\n",
      "Iteration 32800 - cost=9.663140\n",
      "Iteration 32810 - cost=9.788930\n",
      "Iteration 32820 - cost=9.746892\n",
      "Iteration 32830 - cost=9.512066\n",
      "Iteration 32840 - cost=10.153200\n",
      "Iteration 32850 - cost=11.078227\n",
      "Iteration 32860 - cost=9.736512\n",
      "Iteration 32870 - cost=10.280395\n",
      "Iteration 32880 - cost=9.432664\n",
      "Iteration 32890 - cost=10.042835\n",
      "Iteration 32900 - cost=9.546217\n",
      "Iteration 32910 - cost=8.473309\n",
      "Iteration 32920 - cost=10.999843\n",
      "Iteration 32930 - cost=10.366358\n",
      "Iteration 32940 - cost=9.221957\n",
      "Iteration 32950 - cost=10.442142\n",
      "Iteration 32960 - cost=9.875146\n",
      "Iteration 32970 - cost=8.521957\n",
      "Iteration 32980 - cost=9.745724\n",
      "Iteration 32990 - cost=8.754155\n",
      "Iteration 33000 - cost=9.085258\n",
      "Iteration 33010 - cost=10.550357\n",
      "Iteration 33020 - cost=10.031853\n",
      "Iteration 33030 - cost=9.728390\n",
      "Iteration 33040 - cost=9.398752\n",
      "Iteration 33050 - cost=9.176345\n",
      "Iteration 33060 - cost=9.317294\n",
      "Iteration 33070 - cost=9.042178\n",
      "Iteration 33080 - cost=10.069046\n",
      "Iteration 33090 - cost=9.047724\n",
      "Iteration 33100 - cost=9.454668\n",
      "Iteration 33110 - cost=10.118341\n",
      "Iteration 33120 - cost=10.465378\n",
      "Iteration 33130 - cost=9.899738\n",
      "Iteration 33140 - cost=9.027266\n",
      "Iteration 33150 - cost=9.414614\n",
      "Iteration 33160 - cost=9.999803\n",
      "Iteration 33170 - cost=8.837974\n",
      "Iteration 33180 - cost=9.788645\n",
      "Iteration 33190 - cost=9.927436\n",
      "Iteration 33200 - cost=10.386954\n",
      "Iteration 33210 - cost=10.281530\n",
      "Iteration 33220 - cost=8.895897\n",
      "Iteration 33230 - cost=9.856026\n",
      "Iteration 33240 - cost=9.611381\n",
      "Iteration 33250 - cost=9.488938\n",
      "Iteration 33260 - cost=7.837430\n",
      "Iteration 33270 - cost=9.704882\n",
      "Iteration 33280 - cost=10.467514\n",
      "Iteration 33290 - cost=9.542268\n",
      "Iteration 33300 - cost=9.760555\n",
      "Iteration 33310 - cost=9.001702\n",
      "Iteration 33320 - cost=10.392623\n",
      "Iteration 33330 - cost=9.029891\n",
      "Iteration 33340 - cost=9.552833\n",
      "Iteration 33350 - cost=9.754219\n",
      "Iteration 33360 - cost=11.312859\n",
      "Iteration 33370 - cost=10.589644\n",
      "Iteration 33380 - cost=10.095865\n",
      "Iteration 33390 - cost=10.512210\n",
      "Iteration 33400 - cost=9.116046\n",
      "Iteration 33410 - cost=10.205381\n",
      "Iteration 33420 - cost=8.295110\n",
      "Iteration 33430 - cost=10.446429\n",
      "Iteration 33440 - cost=10.595046\n",
      "Iteration 33450 - cost=8.644991\n",
      "Iteration 33460 - cost=8.514311\n",
      "Iteration 33470 - cost=9.294395\n",
      "Iteration 33480 - cost=10.078371\n",
      "Iteration 33490 - cost=9.938909\n",
      "Iteration 33500 - cost=10.495980\n",
      "Iteration 33510 - cost=9.170159\n",
      "Iteration 33520 - cost=10.247035\n",
      "Iteration 33530 - cost=10.172780\n",
      "Iteration 33540 - cost=10.277832\n",
      "Iteration 33550 - cost=9.614877\n",
      "Iteration 33560 - cost=8.514175\n",
      "Iteration 33570 - cost=9.447445\n",
      "Iteration 33580 - cost=9.965672\n",
      "Iteration 33590 - cost=9.819456\n",
      "Iteration 33600 - cost=9.874053\n",
      "Iteration 33610 - cost=10.701998\n",
      "Iteration 33620 - cost=8.533720\n",
      "Iteration 33630 - cost=10.280016\n",
      "Iteration 33640 - cost=10.299886\n",
      "Iteration 33650 - cost=10.412563\n",
      "Iteration 33660 - cost=8.348682\n",
      "Iteration 33670 - cost=8.787441\n",
      "Iteration 33680 - cost=8.227228\n",
      "Iteration 33690 - cost=10.899018\n",
      "Iteration 33700 - cost=9.053215\n",
      "Iteration 33710 - cost=10.096584\n",
      "Iteration 33720 - cost=9.978694\n",
      "Iteration 33730 - cost=9.405185\n",
      "Iteration 33740 - cost=8.177869\n",
      "Iteration 33750 - cost=9.613015\n",
      "Iteration 33760 - cost=11.222424\n",
      "Iteration 33770 - cost=9.712424\n",
      "Iteration 33780 - cost=8.397161\n",
      "Iteration 33790 - cost=10.328193\n",
      "Iteration 33800 - cost=8.978219\n",
      "Iteration 33810 - cost=10.113874\n",
      "Iteration 33820 - cost=10.037967\n",
      "Iteration 33830 - cost=9.813259\n",
      "Iteration 33840 - cost=9.545795\n",
      "Iteration 33850 - cost=9.324878\n",
      "Iteration 33860 - cost=9.432678\n",
      "Iteration 33870 - cost=10.476978\n",
      "Iteration 33880 - cost=9.605971\n",
      "Iteration 33890 - cost=8.002245\n",
      "Iteration 33900 - cost=8.890355\n",
      "Iteration 33910 - cost=10.791638\n",
      "Iteration 33920 - cost=11.731601\n",
      "Iteration 33930 - cost=8.958803\n",
      "Iteration 33940 - cost=9.077784\n",
      "Iteration 33950 - cost=8.905919\n",
      "Iteration 33960 - cost=10.358028\n",
      "Iteration 33970 - cost=10.622704\n",
      "Iteration 33980 - cost=8.742573\n",
      "Iteration 33990 - cost=9.408748\n",
      "Iteration 34000 - cost=9.452282\n",
      "Iteration 34010 - cost=8.908554\n",
      "Iteration 34020 - cost=8.770002\n",
      "Iteration 34030 - cost=9.651623\n",
      "Iteration 34040 - cost=9.362711\n",
      "Iteration 34050 - cost=9.873315\n",
      "Iteration 34060 - cost=8.745673\n",
      "Iteration 34070 - cost=10.213952\n",
      "Iteration 34080 - cost=9.075996\n",
      "Iteration 34090 - cost=8.643357\n",
      "Iteration 34100 - cost=8.777441\n",
      "Iteration 34110 - cost=8.322217\n",
      "Iteration 34120 - cost=10.988231\n",
      "Iteration 34130 - cost=9.954767\n",
      "Iteration 34140 - cost=11.464985\n",
      "Iteration 34150 - cost=9.393540\n",
      "Iteration 34160 - cost=9.016431\n",
      "Iteration 34170 - cost=9.987475\n",
      "Iteration 34180 - cost=10.219141\n",
      "Iteration 34190 - cost=9.955686\n",
      "Iteration 34200 - cost=9.597873\n",
      "Iteration 34210 - cost=11.572683\n",
      "Iteration 34220 - cost=10.262212\n",
      "Iteration 34230 - cost=9.282901\n",
      "Iteration 34240 - cost=9.075270\n",
      "Iteration 34250 - cost=9.577798\n",
      "Iteration 34260 - cost=9.677504\n",
      "Iteration 34270 - cost=9.672165\n",
      "Iteration 34280 - cost=10.371698\n",
      "Iteration 34290 - cost=10.560870\n",
      "Iteration 34300 - cost=8.762209\n",
      "Iteration 34310 - cost=10.253592\n",
      "Iteration 34320 - cost=10.691762\n",
      "Iteration 34330 - cost=10.314092\n",
      "Iteration 34340 - cost=9.622553\n",
      "Iteration 34350 - cost=9.252965\n",
      "Iteration 34360 - cost=11.001141\n",
      "Iteration 34370 - cost=9.571980\n",
      "Iteration 34380 - cost=10.677331\n",
      "Iteration 34390 - cost=8.920870\n",
      "Iteration 34400 - cost=10.105527\n",
      "Iteration 34410 - cost=9.387940\n",
      "Iteration 34420 - cost=8.435180\n",
      "Iteration 34430 - cost=8.674187\n",
      "Iteration 34440 - cost=10.255135\n",
      "Iteration 34450 - cost=9.433674\n",
      "Iteration 34460 - cost=10.175606\n",
      "Iteration 34470 - cost=9.903581\n",
      "Iteration 34480 - cost=11.229620\n",
      "Iteration 34490 - cost=9.035020\n",
      "Iteration 34500 - cost=9.384716\n",
      "Iteration 34510 - cost=8.807886\n",
      "Iteration 34520 - cost=11.179992\n",
      "Iteration 34530 - cost=11.583460\n",
      "Iteration 34540 - cost=12.547462\n",
      "Iteration 34550 - cost=9.442597\n",
      "Iteration 34560 - cost=10.432563\n",
      "Iteration 34570 - cost=10.779511\n",
      "Iteration 34580 - cost=9.465237\n",
      "Iteration 34590 - cost=12.278560\n",
      "Iteration 34600 - cost=10.917057\n",
      "Iteration 34610 - cost=11.117791\n",
      "Iteration 34620 - cost=9.560568\n",
      "Iteration 34630 - cost=9.538032\n",
      "Iteration 34640 - cost=8.663077\n",
      "Iteration 34650 - cost=9.964881\n",
      "Iteration 34660 - cost=10.490151\n",
      "Iteration 34670 - cost=9.226356\n",
      "Iteration 34680 - cost=10.386030\n",
      "Iteration 34690 - cost=9.071070\n",
      "Iteration 34700 - cost=8.791966\n",
      "Iteration 34710 - cost=9.692414\n",
      "Iteration 34720 - cost=9.442783\n",
      "Iteration 34730 - cost=8.088524\n",
      "Iteration 34740 - cost=9.216662\n",
      "Iteration 34750 - cost=11.130383\n",
      "Iteration 34760 - cost=9.276568\n",
      "Iteration 34770 - cost=10.184754\n",
      "Iteration 34780 - cost=9.362078\n",
      "Iteration 34790 - cost=9.521869\n",
      "Iteration 34800 - cost=11.573557\n",
      "Iteration 34810 - cost=9.647198\n",
      "Iteration 34820 - cost=10.292650\n",
      "Iteration 34830 - cost=10.686719\n",
      "Iteration 34840 - cost=11.062624\n",
      "Iteration 34850 - cost=10.852487\n",
      "Iteration 34860 - cost=10.031149\n",
      "Iteration 34870 - cost=9.569779\n",
      "Iteration 34880 - cost=10.515202\n",
      "Iteration 34890 - cost=9.078340\n",
      "Iteration 34900 - cost=9.061917\n",
      "Iteration 34910 - cost=8.409236\n",
      "Iteration 34920 - cost=10.131696\n",
      "Iteration 34930 - cost=9.824052\n",
      "Iteration 34940 - cost=10.155107\n",
      "Iteration 34950 - cost=9.942973\n",
      "Iteration 34960 - cost=10.092785\n",
      "Iteration 34970 - cost=11.754539\n",
      "Iteration 34980 - cost=8.843741\n",
      "Iteration 34990 - cost=8.459001\n",
      "Iteration 35000 - cost=9.620194\n",
      "Iteration 35010 - cost=9.077589\n",
      "Iteration 35020 - cost=10.818394\n",
      "Iteration 35030 - cost=8.680402\n",
      "Iteration 35040 - cost=9.526664\n",
      "Iteration 35050 - cost=9.509427\n",
      "Iteration 35060 - cost=10.382997\n",
      "Iteration 35070 - cost=8.984474\n",
      "Iteration 35080 - cost=11.271440\n",
      "Iteration 35090 - cost=9.038221\n",
      "Iteration 35100 - cost=7.862422\n",
      "Iteration 35110 - cost=9.510885\n",
      "Iteration 35120 - cost=10.436765\n",
      "Iteration 35130 - cost=9.409768\n",
      "Iteration 35140 - cost=9.060693\n",
      "Iteration 35150 - cost=9.546428\n",
      "Iteration 35160 - cost=8.405757\n",
      "Iteration 35170 - cost=8.350662\n",
      "Iteration 35180 - cost=9.056897\n",
      "Iteration 35190 - cost=8.539920\n",
      "Iteration 35200 - cost=9.600623\n",
      "Iteration 35210 - cost=10.835825\n",
      "Iteration 35220 - cost=8.612425\n",
      "Iteration 35230 - cost=9.130368\n",
      "Iteration 35240 - cost=8.373311\n",
      "Iteration 35250 - cost=8.351148\n",
      "Iteration 35260 - cost=10.202927\n",
      "Iteration 35270 - cost=9.342777\n",
      "Iteration 35280 - cost=8.151131\n",
      "Iteration 35290 - cost=10.561299\n",
      "Iteration 35300 - cost=9.634053\n",
      "Iteration 35310 - cost=9.933895\n",
      "Iteration 35320 - cost=11.094303\n",
      "Iteration 35330 - cost=9.815777\n",
      "Iteration 35340 - cost=10.405352\n",
      "Iteration 35350 - cost=11.359302\n",
      "Iteration 35360 - cost=8.803420\n",
      "Iteration 35370 - cost=8.494354\n",
      "Iteration 35380 - cost=10.031591\n",
      "Iteration 35390 - cost=10.162094\n",
      "Iteration 35400 - cost=10.991449\n",
      "Iteration 35410 - cost=8.990906\n",
      "Iteration 35420 - cost=10.055942\n",
      "Iteration 35430 - cost=9.234267\n",
      "Iteration 35440 - cost=10.334359\n",
      "Iteration 35450 - cost=9.675027\n",
      "Iteration 35460 - cost=9.998063\n",
      "Iteration 35470 - cost=9.871427\n",
      "Iteration 35480 - cost=9.085746\n",
      "Iteration 35490 - cost=10.010457\n",
      "Iteration 35500 - cost=9.389459\n",
      "Iteration 35510 - cost=9.442670\n",
      "Iteration 35520 - cost=10.549503\n",
      "Iteration 35530 - cost=10.361069\n",
      "Iteration 35540 - cost=10.901952\n",
      "Iteration 35550 - cost=8.983796\n",
      "Iteration 35560 - cost=9.912339\n",
      "Iteration 35570 - cost=9.190049\n",
      "Iteration 35580 - cost=9.832480\n",
      "Iteration 35590 - cost=10.313712\n",
      "Iteration 35600 - cost=9.424697\n",
      "Iteration 35610 - cost=9.532412\n",
      "Iteration 35620 - cost=9.998302\n",
      "Iteration 35630 - cost=9.526289\n",
      "Iteration 35640 - cost=9.147901\n",
      "Iteration 35650 - cost=8.869456\n",
      "Iteration 35660 - cost=8.658883\n",
      "Iteration 35670 - cost=8.750452\n",
      "Iteration 35680 - cost=9.516038\n",
      "Iteration 35690 - cost=9.993708\n",
      "Iteration 35700 - cost=9.842087\n",
      "Iteration 35710 - cost=8.834033\n",
      "Iteration 35720 - cost=9.937737\n",
      "Iteration 35730 - cost=9.140234\n",
      "Iteration 35740 - cost=11.074907\n",
      "Iteration 35750 - cost=8.213162\n",
      "Iteration 35760 - cost=9.381092\n",
      "Iteration 35770 - cost=8.991277\n",
      "Iteration 35780 - cost=10.884355\n",
      "Iteration 35790 - cost=9.635324\n",
      "Iteration 35800 - cost=10.164570\n",
      "Iteration 35810 - cost=12.034749\n",
      "Iteration 35820 - cost=9.295260\n",
      "Iteration 35830 - cost=8.381381\n",
      "Iteration 35840 - cost=11.286647\n",
      "Iteration 35850 - cost=9.680351\n",
      "Iteration 35860 - cost=9.776162\n",
      "Iteration 35870 - cost=8.632771\n",
      "Iteration 35880 - cost=8.305933\n",
      "Iteration 35890 - cost=11.449788\n",
      "Iteration 35900 - cost=10.042871\n",
      "Iteration 35910 - cost=9.774558\n",
      "Iteration 35920 - cost=8.993078\n",
      "Iteration 35930 - cost=9.155905\n",
      "Iteration 35940 - cost=9.281404\n",
      "Iteration 35950 - cost=9.016056\n",
      "Iteration 35960 - cost=11.367734\n",
      "Iteration 35970 - cost=9.256800\n",
      "Iteration 35980 - cost=11.416869\n",
      "Iteration 35990 - cost=8.566408\n",
      "Iteration 36000 - cost=10.039340\n",
      "Iteration 36010 - cost=9.029069\n",
      "Iteration 36020 - cost=9.747720\n",
      "Iteration 36030 - cost=8.417195\n",
      "Iteration 36040 - cost=8.839629\n",
      "Iteration 36050 - cost=9.153267\n",
      "Iteration 36060 - cost=9.712055\n",
      "Iteration 36070 - cost=10.345466\n",
      "Iteration 36080 - cost=9.554816\n",
      "Iteration 36090 - cost=9.499510\n",
      "Iteration 36100 - cost=9.725940\n",
      "Iteration 36110 - cost=10.559432\n",
      "Iteration 36120 - cost=8.654122\n",
      "Iteration 36130 - cost=8.332375\n",
      "Iteration 36140 - cost=7.611922\n",
      "Iteration 36150 - cost=10.953747\n",
      "Iteration 36160 - cost=10.727644\n",
      "Iteration 36170 - cost=8.999337\n",
      "Iteration 36180 - cost=9.670605\n",
      "Iteration 36190 - cost=9.119749\n",
      "Iteration 36200 - cost=8.119968\n",
      "Iteration 36210 - cost=10.820953\n",
      "Iteration 36220 - cost=9.081631\n",
      "Iteration 36230 - cost=10.121742\n",
      "Iteration 36240 - cost=8.844184\n",
      "Iteration 36250 - cost=10.478465\n",
      "Iteration 36260 - cost=8.782141\n",
      "Iteration 36270 - cost=9.155477\n",
      "Iteration 36280 - cost=11.135361\n",
      "Iteration 36290 - cost=9.887580\n",
      "Iteration 36300 - cost=10.337694\n",
      "Iteration 36310 - cost=8.889992\n",
      "Iteration 36320 - cost=9.123204\n",
      "Iteration 36330 - cost=9.867791\n",
      "Iteration 36340 - cost=9.633717\n",
      "Iteration 36350 - cost=9.019389\n",
      "Iteration 36360 - cost=9.883829\n",
      "Iteration 36370 - cost=10.272291\n",
      "Iteration 36380 - cost=9.478701\n",
      "Iteration 36390 - cost=10.041877\n",
      "Iteration 36400 - cost=10.844146\n",
      "Iteration 36410 - cost=9.858590\n",
      "Iteration 36420 - cost=9.635268\n",
      "Iteration 36430 - cost=9.542294\n",
      "Iteration 36440 - cost=10.136936\n",
      "Iteration 36450 - cost=10.112588\n",
      "Iteration 36460 - cost=10.863250\n",
      "Iteration 36470 - cost=10.393476\n",
      "Iteration 36480 - cost=8.004917\n",
      "Iteration 36490 - cost=8.862689\n",
      "Iteration 36500 - cost=9.092374\n",
      "Iteration 36510 - cost=10.381461\n",
      "Iteration 36520 - cost=8.922288\n",
      "Iteration 36530 - cost=9.614931\n",
      "Iteration 36540 - cost=9.051200\n",
      "Iteration 36550 - cost=9.856587\n",
      "Iteration 36560 - cost=9.519735\n",
      "Iteration 36570 - cost=9.583513\n",
      "Iteration 36580 - cost=11.101647\n",
      "Iteration 36590 - cost=11.086387\n",
      "Iteration 36600 - cost=10.050297\n",
      "Iteration 36610 - cost=7.102230\n",
      "Iteration 36620 - cost=11.073032\n",
      "Iteration 36630 - cost=8.988829\n",
      "Iteration 36640 - cost=9.434071\n",
      "Iteration 36650 - cost=10.270816\n",
      "Iteration 36660 - cost=8.933081\n",
      "Iteration 36670 - cost=9.369494\n",
      "Iteration 36680 - cost=10.889645\n",
      "Iteration 36690 - cost=9.614379\n",
      "Iteration 36700 - cost=9.139010\n",
      "Iteration 36710 - cost=10.441671\n",
      "Iteration 36720 - cost=9.169800\n",
      "Iteration 36730 - cost=9.196597\n",
      "Iteration 36740 - cost=10.411078\n",
      "Iteration 36750 - cost=8.713691\n",
      "Iteration 36760 - cost=11.066289\n",
      "Iteration 36770 - cost=10.118937\n",
      "Iteration 36780 - cost=8.975390\n",
      "Iteration 36790 - cost=10.032535\n",
      "Iteration 36800 - cost=10.914408\n",
      "Iteration 36810 - cost=9.465846\n",
      "Iteration 36820 - cost=8.792624\n",
      "Iteration 36830 - cost=9.819238\n",
      "Iteration 36840 - cost=9.477123\n",
      "Iteration 36850 - cost=10.347389\n",
      "Iteration 36860 - cost=10.077795\n",
      "Iteration 36870 - cost=8.428167\n",
      "Iteration 36880 - cost=9.133361\n",
      "Iteration 36890 - cost=9.351699\n",
      "Iteration 36900 - cost=8.530530\n",
      "Iteration 36910 - cost=11.655106\n",
      "Iteration 36920 - cost=8.361172\n",
      "Iteration 36930 - cost=9.253536\n",
      "Iteration 36940 - cost=9.656491\n",
      "Iteration 36950 - cost=7.426087\n",
      "Iteration 36960 - cost=9.381730\n",
      "Iteration 36970 - cost=10.373952\n",
      "Iteration 36980 - cost=10.629057\n",
      "Iteration 36990 - cost=10.126075\n",
      "Iteration 37000 - cost=10.647984\n",
      "Iteration 37010 - cost=9.401667\n",
      "Iteration 37020 - cost=8.887913\n",
      "Iteration 37030 - cost=10.889519\n",
      "Iteration 37040 - cost=10.447055\n",
      "Iteration 37050 - cost=12.164355\n",
      "Iteration 37060 - cost=9.930969\n",
      "Iteration 37070 - cost=9.231642\n",
      "Iteration 37080 - cost=9.240472\n",
      "Iteration 37090 - cost=10.412815\n",
      "Iteration 37100 - cost=9.645784\n",
      "Iteration 37110 - cost=10.604228\n",
      "Iteration 37120 - cost=9.728567\n",
      "Iteration 37130 - cost=8.035862\n",
      "Iteration 37140 - cost=9.924534\n",
      "Iteration 37150 - cost=9.596897\n",
      "Iteration 37160 - cost=10.709914\n",
      "Iteration 37170 - cost=9.262740\n",
      "Iteration 37180 - cost=9.237581\n",
      "Iteration 37190 - cost=8.625442\n",
      "Iteration 37200 - cost=10.447410\n",
      "Iteration 37210 - cost=10.347924\n",
      "Iteration 37220 - cost=8.975615\n",
      "Iteration 37230 - cost=11.907330\n",
      "Iteration 37240 - cost=7.776055\n",
      "Iteration 37250 - cost=8.852717\n",
      "Iteration 37260 - cost=10.124252\n",
      "Iteration 37270 - cost=10.449522\n",
      "Iteration 37280 - cost=9.970904\n",
      "Iteration 37290 - cost=8.873520\n",
      "Iteration 37300 - cost=9.908159\n",
      "Iteration 37310 - cost=9.040003\n",
      "Iteration 37320 - cost=9.504830\n",
      "Iteration 37330 - cost=10.440103\n",
      "Iteration 37340 - cost=7.687915\n",
      "Iteration 37350 - cost=10.035449\n",
      "Iteration 37360 - cost=11.320037\n",
      "Iteration 37370 - cost=8.518202\n",
      "Iteration 37380 - cost=10.356562\n",
      "Iteration 37390 - cost=10.464559\n",
      "Iteration 37400 - cost=9.030374\n",
      "Iteration 37410 - cost=10.127537\n",
      "Iteration 37420 - cost=10.187385\n",
      "Iteration 37430 - cost=8.774733\n",
      "Iteration 37440 - cost=9.915690\n",
      "Iteration 37450 - cost=8.593145\n",
      "Iteration 37460 - cost=9.924534\n",
      "Iteration 37470 - cost=10.307232\n",
      "Iteration 37480 - cost=10.104539\n",
      "Iteration 37490 - cost=11.456058\n",
      "Iteration 37500 - cost=10.115817\n",
      "Iteration 37510 - cost=10.466004\n",
      "Iteration 37520 - cost=8.324094\n",
      "Iteration 37530 - cost=7.435779\n",
      "Iteration 37540 - cost=11.176508\n",
      "Iteration 37550 - cost=9.567924\n",
      "Iteration 37560 - cost=11.040338\n",
      "Iteration 37570 - cost=8.516487\n",
      "Iteration 37580 - cost=8.855136\n",
      "Iteration 37590 - cost=10.271511\n",
      "Iteration 37600 - cost=8.644232\n",
      "Iteration 37610 - cost=10.352309\n",
      "Iteration 37620 - cost=8.658438\n",
      "Iteration 37630 - cost=9.979931\n",
      "Iteration 37640 - cost=9.566114\n",
      "Iteration 37650 - cost=9.976088\n",
      "Iteration 37660 - cost=9.247757\n",
      "Iteration 37670 - cost=8.641738\n",
      "Iteration 37680 - cost=9.411461\n",
      "Iteration 37690 - cost=9.904736\n",
      "Iteration 37700 - cost=9.223840\n",
      "Iteration 37710 - cost=9.464384\n",
      "Iteration 37720 - cost=10.601909\n",
      "Iteration 37730 - cost=8.870718\n",
      "Iteration 37740 - cost=9.069155\n",
      "Iteration 37750 - cost=10.161931\n",
      "Iteration 37760 - cost=9.807900\n",
      "Iteration 37770 - cost=11.062407\n",
      "Iteration 37780 - cost=10.039007\n",
      "Iteration 37790 - cost=9.324941\n",
      "Iteration 37800 - cost=8.713355\n",
      "Iteration 37810 - cost=8.742713\n",
      "Iteration 37820 - cost=10.065033\n",
      "Iteration 37830 - cost=9.502228\n",
      "Iteration 37840 - cost=8.387705\n",
      "Iteration 37850 - cost=8.592284\n",
      "Iteration 37860 - cost=10.766066\n",
      "Iteration 37870 - cost=9.172481\n",
      "Iteration 37880 - cost=8.759525\n",
      "Iteration 37890 - cost=10.265562\n",
      "Iteration 37900 - cost=10.717466\n",
      "Iteration 37910 - cost=8.358378\n",
      "Iteration 37920 - cost=10.695703\n",
      "Iteration 37930 - cost=8.620987\n",
      "Iteration 37940 - cost=8.687092\n",
      "Iteration 37950 - cost=8.604703\n",
      "Iteration 37960 - cost=10.405435\n",
      "Iteration 37970 - cost=9.192937\n",
      "Iteration 37980 - cost=9.607687\n",
      "Iteration 37990 - cost=9.851746\n",
      "Iteration 38000 - cost=10.150451\n",
      "Iteration 38010 - cost=10.448272\n",
      "Iteration 38020 - cost=8.819437\n",
      "Iteration 38030 - cost=11.249336\n",
      "Iteration 38040 - cost=10.424341\n",
      "Iteration 38050 - cost=9.263337\n",
      "Iteration 38060 - cost=9.489558\n",
      "Iteration 38070 - cost=9.990096\n",
      "Iteration 38080 - cost=9.059942\n",
      "Iteration 38090 - cost=11.319105\n",
      "Iteration 38100 - cost=10.961207\n",
      "Iteration 38110 - cost=10.482990\n",
      "Iteration 38120 - cost=9.953578\n",
      "Iteration 38130 - cost=9.234713\n",
      "Iteration 38140 - cost=11.028516\n",
      "Iteration 38150 - cost=10.030881\n",
      "Iteration 38160 - cost=9.511719\n",
      "Iteration 38170 - cost=10.685449\n",
      "Iteration 38180 - cost=9.223813\n",
      "Iteration 38190 - cost=9.229135\n",
      "Iteration 38200 - cost=9.853552\n",
      "Iteration 38210 - cost=10.002608\n",
      "Iteration 38220 - cost=9.980313\n",
      "Iteration 38230 - cost=9.000098\n",
      "Iteration 38240 - cost=10.930837\n",
      "Iteration 38250 - cost=8.872893\n",
      "Iteration 38260 - cost=9.077726\n",
      "Iteration 38270 - cost=10.872026\n",
      "Iteration 38280 - cost=8.641403\n",
      "Iteration 38290 - cost=10.257064\n",
      "Iteration 38300 - cost=10.172731\n",
      "Iteration 38310 - cost=10.849080\n",
      "Iteration 38320 - cost=9.399858\n",
      "Iteration 38330 - cost=10.014440\n",
      "Iteration 38340 - cost=9.553118\n",
      "Iteration 38350 - cost=9.072561\n",
      "Iteration 38360 - cost=9.031645\n",
      "Iteration 38370 - cost=9.328184\n",
      "Iteration 38380 - cost=11.446847\n",
      "Iteration 38390 - cost=9.520487\n",
      "Iteration 38400 - cost=9.621291\n",
      "Iteration 38410 - cost=9.625516\n",
      "Iteration 38420 - cost=9.824523\n",
      "Iteration 38430 - cost=8.927678\n",
      "Iteration 38440 - cost=8.672267\n",
      "Iteration 38450 - cost=9.039973\n",
      "Iteration 38460 - cost=8.317379\n",
      "Iteration 38470 - cost=10.013034\n",
      "Iteration 38480 - cost=10.042889\n",
      "Iteration 38490 - cost=9.343444\n",
      "Iteration 38500 - cost=11.135961\n",
      "Iteration 38510 - cost=9.246640\n",
      "Iteration 38520 - cost=9.470005\n",
      "Iteration 38530 - cost=10.465461\n",
      "Iteration 38540 - cost=11.140251\n",
      "Iteration 38550 - cost=11.183165\n",
      "Iteration 38560 - cost=9.364743\n",
      "Iteration 38570 - cost=9.116420\n",
      "Iteration 38580 - cost=10.448858\n",
      "Iteration 38590 - cost=7.747920\n",
      "Iteration 38600 - cost=9.508725\n",
      "Iteration 38610 - cost=8.931740\n",
      "Iteration 38620 - cost=10.907650\n",
      "Iteration 38630 - cost=9.504955\n",
      "Iteration 38640 - cost=9.664230\n",
      "Iteration 38650 - cost=8.920708\n",
      "Iteration 38660 - cost=9.292189\n",
      "Iteration 38670 - cost=9.195943\n",
      "Iteration 38680 - cost=10.398090\n",
      "Iteration 38690 - cost=10.049753\n",
      "Iteration 38700 - cost=7.743269\n",
      "Iteration 38710 - cost=9.204882\n",
      "Iteration 38720 - cost=9.235312\n",
      "Iteration 38730 - cost=10.293173\n",
      "Iteration 38740 - cost=8.726734\n",
      "Iteration 38750 - cost=9.804810\n",
      "Iteration 38760 - cost=8.977195\n",
      "Iteration 38770 - cost=10.709549\n",
      "Iteration 38780 - cost=11.546511\n",
      "Iteration 38790 - cost=9.635358\n",
      "Iteration 38800 - cost=9.935147\n",
      "Iteration 38810 - cost=8.869340\n",
      "Iteration 38820 - cost=9.389567\n",
      "Iteration 38830 - cost=9.340834\n",
      "Iteration 38840 - cost=7.942508\n",
      "Iteration 38850 - cost=10.862992\n",
      "Iteration 38860 - cost=9.025710\n",
      "Iteration 38870 - cost=8.635300\n",
      "Iteration 38880 - cost=8.982403\n",
      "Iteration 38890 - cost=10.033524\n",
      "Iteration 38900 - cost=9.245208\n",
      "Iteration 38910 - cost=8.389566\n",
      "Iteration 38920 - cost=9.288239\n",
      "Iteration 38930 - cost=10.804753\n",
      "Iteration 38940 - cost=9.539329\n",
      "Iteration 38950 - cost=8.530258\n",
      "Iteration 38960 - cost=10.287416\n",
      "Iteration 38970 - cost=11.390207\n",
      "Iteration 38980 - cost=8.736205\n",
      "Iteration 38990 - cost=10.565003\n",
      "Iteration 39000 - cost=9.294268\n",
      "Iteration 39010 - cost=9.138047\n",
      "Iteration 39020 - cost=8.175886\n",
      "Iteration 39030 - cost=9.131763\n",
      "Iteration 39040 - cost=9.526391\n",
      "Iteration 39050 - cost=10.687989\n",
      "Iteration 39060 - cost=9.644195\n",
      "Iteration 39070 - cost=8.962388\n",
      "Iteration 39080 - cost=9.484589\n",
      "Iteration 39090 - cost=8.107853\n",
      "Iteration 39100 - cost=8.832251\n",
      "Iteration 39110 - cost=9.405943\n",
      "Iteration 39120 - cost=11.407398\n",
      "Iteration 39130 - cost=9.589763\n",
      "Iteration 39140 - cost=9.834780\n",
      "Iteration 39150 - cost=10.034118\n",
      "Iteration 39160 - cost=10.155086\n",
      "Iteration 39170 - cost=10.321111\n",
      "Iteration 39180 - cost=8.536456\n",
      "Iteration 39190 - cost=10.314585\n",
      "Iteration 39200 - cost=8.776217\n",
      "Iteration 39210 - cost=10.434212\n",
      "Iteration 39220 - cost=9.058813\n",
      "Iteration 39230 - cost=10.546668\n",
      "Iteration 39240 - cost=10.992067\n",
      "Iteration 39250 - cost=9.654117\n",
      "Iteration 39260 - cost=9.347299\n",
      "Iteration 39270 - cost=9.610204\n",
      "Iteration 39280 - cost=10.740433\n",
      "Iteration 39290 - cost=8.581883\n",
      "Iteration 39300 - cost=8.448435\n",
      "Iteration 39310 - cost=8.473446\n",
      "Iteration 39320 - cost=9.971489\n",
      "Iteration 39330 - cost=9.135132\n",
      "Iteration 39340 - cost=9.520379\n",
      "Iteration 39350 - cost=8.924711\n",
      "Iteration 39360 - cost=8.100554\n",
      "Iteration 39370 - cost=11.427533\n",
      "Iteration 39380 - cost=8.945348\n",
      "Iteration 39390 - cost=10.022445\n",
      "Iteration 39400 - cost=9.840361\n",
      "Iteration 39410 - cost=9.168403\n",
      "Iteration 39420 - cost=9.024651\n",
      "Iteration 39430 - cost=9.860498\n",
      "Iteration 39440 - cost=8.941981\n",
      "Iteration 39450 - cost=8.235066\n",
      "Iteration 39460 - cost=10.769561\n",
      "Iteration 39470 - cost=8.870533\n",
      "Iteration 39480 - cost=9.924422\n",
      "Iteration 39490 - cost=7.843372\n",
      "Iteration 39500 - cost=9.235361\n",
      "Iteration 39510 - cost=9.071530\n",
      "Iteration 39520 - cost=9.953745\n",
      "Iteration 39530 - cost=10.084836\n",
      "Iteration 39540 - cost=9.466351\n",
      "Iteration 39550 - cost=9.720430\n",
      "Iteration 39560 - cost=10.161583\n",
      "Iteration 39570 - cost=8.927365\n",
      "Iteration 39580 - cost=8.786552\n",
      "Iteration 39590 - cost=9.518486\n",
      "Iteration 39600 - cost=9.949913\n",
      "Iteration 39610 - cost=10.074936\n",
      "Iteration 39620 - cost=10.369965\n",
      "Iteration 39630 - cost=9.952782\n",
      "Iteration 39640 - cost=10.070291\n",
      "Iteration 39650 - cost=8.810320\n",
      "Iteration 39660 - cost=10.882244\n",
      "Iteration 39670 - cost=9.442060\n",
      "Iteration 39680 - cost=11.275881\n",
      "Iteration 39690 - cost=8.424206\n",
      "Iteration 39700 - cost=8.895798\n",
      "Iteration 39710 - cost=9.065605\n",
      "Iteration 39720 - cost=8.605288\n",
      "Iteration 39730 - cost=10.541846\n",
      "Iteration 39740 - cost=8.840427\n",
      "Iteration 39750 - cost=8.937290\n",
      "Iteration 39760 - cost=9.178550\n",
      "Iteration 39770 - cost=10.883129\n",
      "Iteration 39780 - cost=8.832140\n",
      "Iteration 39790 - cost=8.712058\n",
      "Iteration 39800 - cost=9.443215\n",
      "Iteration 39810 - cost=8.996545\n",
      "Iteration 39820 - cost=10.237100\n",
      "Iteration 39830 - cost=9.051902\n",
      "Iteration 39840 - cost=9.147391\n",
      "Iteration 39850 - cost=8.620262\n",
      "Iteration 39860 - cost=10.085855\n",
      "Iteration 39870 - cost=9.629161\n",
      "Iteration 39880 - cost=9.221476\n",
      "Iteration 39890 - cost=8.421255\n",
      "Iteration 39900 - cost=8.266940\n",
      "Iteration 39910 - cost=9.239727\n",
      "Iteration 39920 - cost=9.623496\n",
      "Iteration 39930 - cost=10.791761\n",
      "Iteration 39940 - cost=9.142411\n",
      "Iteration 39950 - cost=9.128996\n",
      "Iteration 39960 - cost=11.390108\n",
      "Iteration 39970 - cost=9.357812\n",
      "Iteration 39980 - cost=8.572269\n",
      "Iteration 39990 - cost=9.341523\n",
      "Iteration 40000 - cost=8.559381\n",
      "\n",
      "=== For autograder ===\n",
      "[[-0.67131358 -0.25156749 -0.5112404   0.46609369  0.81964006 -0.17678717\n",
      "   0.04727608  0.91698403 -0.57413986 -0.02978244]\n",
      " [-0.68194618 -0.15229774 -0.51321841  0.39254603  0.79362069 -0.21699707\n",
      "  -0.01172248  0.80166188 -0.54150303 -0.22063975]\n",
      " [-0.50124453  0.01231413 -0.42058395  0.37085274  0.6478261  -0.04703697\n",
      "   0.04613347  0.61446384 -0.25082859 -0.0563656 ]\n",
      " [-0.5691748  -0.17675577 -0.41760259  0.3573051   0.61275163 -0.06743699\n",
      "   0.01619132  0.71738941 -0.31445712 -0.04710073]\n",
      " [-0.21333579 -0.00206362 -0.17378362  0.13142703  0.17503769  0.0060375\n",
      "  -0.02556432  0.15208457 -0.01253734 -0.0388439 ]\n",
      " [-0.58614977 -0.15229928 -0.40548632  0.43981577  0.63795691 -0.13161872\n",
      "  -0.03071489  0.64779522 -0.29058703 -0.07918343]\n",
      " [-0.65398113 -0.10053422 -0.53109336  0.42034709  0.7793295  -0.1049117\n",
      "  -0.03424799  0.84674949 -0.49451618 -0.15451428]]\n"
     ]
    }
   ],
   "source": [
    "# Train word vectors (this could take a while!)\n",
    "\n",
    "# Reset the random seed to make sure that everyone gets the same results\n",
    "random.seed(31415)\n",
    "np.random.seed(9265)\n",
    "wordVectors = np.concatenate(((np.random.rand(nWords, dimVectors) - .5) / dimVectors, \n",
    "                              np.zeros((nWords, dimVectors))), axis=0)\n",
    "#wordVectors0 = sgd(lambda vec: word2vec_sgd_wrapper(skipgram, tokens, vec, dataset, C, softmaxCostAndGradient), \n",
    "#                   wordVectors, 0.3, 40000, None, False, PRINT_EVERY=10)\n",
    "\n",
    "wordVectors0 = sgd(lambda vec: word2vec_sgd_wrapper(skipgram, tokens, vec, dataset, C, negSamplingCostAndGradient), \n",
    "                   wordVectors, 0.3, 40000, None, False, PRINT_EVERY=1000)\n",
    "# sanity check: cost at convergence should be around or below 10\n",
    "\n",
    "# sum the input and output word vectors\n",
    "wordVectors = (wordVectors0[:nWords,:] + wordVectors0[nWords:,:])\n",
    "\n",
    "print \"\\n=== For autograder ===\"\n",
    "checkWords = [\"the\", \"a\", \"an\", \"movie\", \"ordinary\", \"but\", \"and\"]\n",
    "checkIdx = [tokens[word] for word in checkWords]\n",
    "checkVecs = wordVectors[checkIdx, :]\n",
    "print checkVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.094697867987347889, 0.056050614063041189)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAmIAAAHiCAYAAABLDqCjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzs3XmcVmX9//HXNRsMI4hjogiEqBi5oRYuWbgB4hKYO7lX\n",
       "ZvpzxUxTQQR31Ewr0zTFb4pmmploiuZoliIigikgoqBiAjICss52/f7gZryBe4YZ7pk5M8Pr+XiU\n",
       "9zn3dc75nEnoPde5znWFGCOSJElqejlJFyBJkrSpMohJkiQlxCAmSZKUkLykC6hJ6BS6U0xBo5y8\n",
       "lLI4P85plHNLkiTVUbMNYhRTwBCWNcq5x1LUKOeVJEmqBx9NSpIkJaT1BrFr+AsPsisAVzOBCXRM\n",
       "uCJJkqS1tN4gBrGGz5IkSc1C8x0jtsYtnE0OK7mI+7iREZTzTa7kBO5hf+ZzIlvxZz7j50AbcpnN\n",
       "0VxEL1YkXbYkSdKGNP8esa14jRXsA0AZvYm0o5RcvmAf2jCNeVzIiZzAMAbShqk8xVkJVyxJklQn\n",
       "zb9H7DDe5k52522KCKwinyk8RW9WsTdFPEslO/EwfwMgUkA+byRcsSRJUp00/yC2FRXk8BHPczxt\n",
       "mEgR05jP/lSyHYV8zApe5nL+X9JlSpIk1VfzfzQJ0IbXWcLZbMFr7MoElnEqebzNbkyinD48SXcA\n",
       "plPIE/RIuFpJkqQ6CTE2zxcKQ6/QkyEs4xbmUgGsADYDArAUKEj9pwJYlXZgG1b38y1Pfc5NtS9K\n",
       "HQuwEihviruQJEmbmhhj2HCr1Zr/o0mAS+nSoOcbS1GcHmfW97AQwogY44gGraWF8mfxFX8Wq/lz\n",
       "+Io/i6/4s/iKP4uvtOafRQihXj1cLePRpCRJUitkEJMkSUpI8300WUoZYyliJQ2/SHcpZRt5ZElD\n",
       "ltHClSRdQDNSknQBzURJ0gU0IyVJF9CMlCRdQDNSknQBzUhJ0gU0F812sP4aIYRYn0FvkiRJSalv\n",
       "bvHRpCRJUkIMYpIkSQkxiEmSJCXEICZJkpQQg5gkSVJCDGKSJEkJab7ziKnVCp1Cd4opqLVRKWVx\n",
       "fpzTRCVJkpQIg5iaXjEFDGFZrW0aehJfSZKaIR9NSpIkJcQgJkmSlBCDmCRJUkIcI6ZkXcu9VLEt\n",
       "kTZszj1cwENJlyRJUlMxiClZAxhKHxbzAW35E+OYwNPsw6Kky5IkqSkYxJSsEn7CMxwKQBWdmUEP\n",
       "9mFywlVJktQkHCOm5NzLfqzku5zG9xnOAPJ4h4oNzC8mSVIrYhBTcsppTw6L6M4qHmMHKtgr6ZIk\n",
       "SWpKBjElZzAvAnmMpITpXE4ek5IuSZKkpuQYMSWnM+VcwSlJlyFJUlLsEZMkSUqIQUySJCkhPppU\n",
       "0yulbIOLepdS1kTVSJKUmBBjTLqGWoUQYowxJF2HJEnShtQ3t/hoUpIkKSEGMUmSpIQ4RkySpCYQ\n",
       "OoXuFDfh6iGllMX5cU6TXU8bxSAmSVJTKKaAISxrsutt6KUoNQs+mpQkSUqIQUySpJZuHF0ZyQtJ\n",
       "l6H6M4hJkiQlxDFikiQ1tZu5kOUcTWAhuXxKW6bSmVd4nxuItCWXOQxkKN9iCWPZJeP+B9mNWdwK\n",
       "RNryUtK3pI1jj5gkSU3p/+jNCg7jTA7hGE6igt0BmMltdGUUw+lPAdN4nqGp/b/OuH8Wv6IblzOc\n",
       "AYndi7JmEJMkqSktoA9teZbOlLMzy2nDeKpoR2RzzuB1AHrxKGXsyxQ2I9Jhvf2TaZ/aPxGA7jyW\n",
       "2P0oKwYxSZKaVgRqXwIn1vB9ffer2TOISZLUlDoxkZX05xMKeJd2rKIfOSwnsIj76APADI6lgP/Q\n",
       "m6UZ9+/JlwQWc39q/0ccndj9KCsO1pckqSmdzFRG8xx/5Hly+Jw8ppPLYnpyIe9zAyMpJJc5HM5F\n",
       "ADXu34GLmMWtjCLShpdZ3dOmFibE2Lz/d6vvKuaSJDVHoVfoWT2z/nQK6cUKZtKWh3mcHbmEIbzT\n",
       "oBccS1GcHmc26Dm1QfXNLfaISZLU1B5nNJX0JNKWIh5p8BCmFsMgJklSU7ucc5MuQc1D1kEshDAQ\n",
       "uA3IBe6JMd6Yoc3twGHAcuD0GOPktO9ygTeAT2KM38+2HkmSmqVSypp0Ie5SyprsWtpoWQWxVIj6\n",
       "DdAPmAtMDCE8GWOcltbmcGDHGGPPEMI+wJ3AvmmnuQB4F2ifTS2SpIYROoXuFFOwwYallMX5cU4T\n",
       "lNQq+LNSJtn2iO0NvB9jnA0QQngYGAxMS2szCBgDEGOcEELoGELYOsY4L4TQFTgcuBZSMwVLkpJV\n",
       "TEH1oPLaNGXvjtRKZTuPWBfg47TtT1L76trmV8AlQFWWdUiSJLU42faI1XXui3Vf4wwhhCOB+THG\n",
       "ySGEA2s9OIQRaZslMcaSOlcoSZLUSFIZ5sCNPT7bIDYX6Ja23Y3VPV61tema2ncMMCg1hqwt0CGE\n",
       "8ECM8dR1LxJjHJFlnZIkSQ0u1TlUsmY7hHBVfY7P9tHkG0DPEMJ2IYQC4ATgyXXaPAmcmipuX2BR\n",
       "jPGzGOPlMcZuMcYewInAPzOFMEmSpNYqqx6xGGNFCOFc4FlWT19xb4xxWgjhrNT3d8UYnw4hHB5C\n",
       "eB9YBpxR0+myqUWSJKmlcYkjSdJa1lqKpzYuoSOtxyWOJEkN4zZO40t+CECglEgx+UzhMn6RcGVS\n",
       "q2EQkyRldiFjSM0DKalxZDtYX5IkSRvJICZJkpQQg5gkSVJCDGKSJEkJcbC+JGltpZTVaUHvUsqa\n",
       "oBqpVXMeMUmSpAZS39zio0lJkqSEGMQkSZIS4hgxSUoTOoXuFFPQICcrpSzOj3Ma5FySWiWDmCSl\n",
       "K6agTuss1kVdBrxL2qT5aFKSMplMe27jVADuZT+u5f5kC5LUGhnEJCmTT9mcJZyWdBmSWjcfTUpS\n",
       "JlO4nCq2YxTPAhUElnMdd1FBL/KYyuWcB8CD7MaHXEWkiEAp+3MhB7Eg2eIltRT2iElSJntwLTnM\n",
       "ZhiH0oVRVLArezOcX3IAlXyd++nDAvL4gGs4hDMZxmFswSO8xmVJly6p5bBHTJIyiYS1PufxFv2Y\n",
       "B0A+7/AlXXmRJVTyDZ7nYZ4HIrnkpNpIylqDvsXcVPIh9Ao9M36X4U1qg5gk1UVgVdpWFTH192cu\n",
       "MxjG4GSKklq5hnyLuancAjXWnOFNah9NSlImxSwjslmN3wciBzGLyJY8wF4ALCCPR8n8m7AkZWAQ\n",
       "k6RM9uML8pnISF7gU64E1l+Ydysq6MlP+YgrGMlz3MlzfMq3mr5YSWu5jZO5g2Ma9JzX8BceZLf1\n",
       "9t/O8dzANRt7Wh9NSlJNLufcjPsv48rqz0N4Fxr4L3xJ2bmQPzXCWdf/Zaz2/XViEJMkSc3fHRzN\n",
       "In4E5JPPZM7hcm5lBkX8gRX0I7CSAziDvixkNBeTy1KGchdj2YX3uYFIW3KZw0CGMpctmMJdDGMg\n",
       "AE/Qg7e5k2EM5GYuYgX9iLSlgDe4jEura/iEYxnFzUTy6MFQTmHKWjW+QjErgFGMA6AbV3E6b9R2\n",
       "Wz6alCRJzdtf2JElfJ8LGMQwDgUqGcPRQCEdmMRwBtCGCbzOSakjImt6qmbya7oyiuH0p4BpPM9Q\n",
       "BjGHwBLGsjMA73ECm/EwAAfwR4ZxBMM5hEhbfk+/1DkDkbYM41C68Us+5Nbq/Wu8zCjygWEcwbc5\n",
       "k4+4eUO3Zo+YJElq3j7me1SwO7/mGYBU79ZCoIyzeAGAIqayhL5rHTeFzYh04AxeB6AXj/IWdwPQ\n",
       "kYf4iBNYzghW8n0O4nAAJrI//+BsIoVEOrKMGZCaoGYrngDgDF7natozmfZrXa+c71EBqYmgIVLE\n",
       "TNrSk5U13ZpBTJLSlVLWYIt1l1LWIOeRBIU8yi+4Ya19I/hZ9edAFZBb6znS5wf8Ps8whqE8wL/J\n",
       "Yyp9WMwc2rCA6/gOA+nPZ4xmKJE2NZ4vj6p19gTaAT/n0LrelkFMktKsO9mipGagG//iXe7jFe7m\n",
       "u5QygY4srMMvTL1Zyt9YxH304QwmMoNjKeA/AHRnFW14iXlcT2eGAvB5KnTtxBe8SztWcCTt+Hvq\n",
       "bIEFDAJe5T76EFjMbizjxbTr5fMS5fygenssuzCEd2or0SAmSZIaRCPMhL8db7Kc7ankc+6nhMd5\n",
       "kUCggu7cSiDwJj0AyGUrctiMN+lBLh3JpYA36UFPRjOLaxlFG/KYyx6MqD57Z/7KhwzkDF4C4Fss\n",
       "4Z88yBj+SWAB+UxOqyUSWMUoniWSy/ap8LZ6/+rxaAcxjBf4ASMZD+RRwKvA5bXdYIgxq7cuG10I\n",
       "IcYYw4ZbSpKkJIVeoWeDzoT/Kj3Yj+X1Pu5X/IKOvMsZPLXed2/Sjr34EIBb+BlVFHEJt2Rd6xq3\n",
       "MJeL6ZLxu7EUxelxZvoue8QkSVLrcQdns4JdGMSdtba7lnuppBuHcnwTVZaRQUzrSXyR1QyLokqS\n",
       "WpBxdGUSYxjOIbW2G83FbMFr/IR/cw1/oQcjOIn/cjUTGJga8H47f+R8flTna5/HnZAKYQ9zJLvz\n",
       "Gjvz+XrtruDHdb+hxmMQ0/qSXmS1od5YkyQ1X8sJ6zwSjOt9LqeMPpzLq7TbqGt8xGAq+YTFaY83\n",
       "Z9OOGY34/zMrqfn/xzK8SW0QkyRJjSGP67iDCnYjjxmcyAX8Hy9RyN9YRV+K+R1LOIjNGc85PJ3x\n",
       "DH2ZywhmMoKevEs7HuePRDoSyaMTN/Eznkv1vj1IARMo49vk8BmncAbj6MdyejGLK/iAFZzKILqz\n",
       "itnrj9NqSCEE6nN+Z9ZX3Y3mYm7lrKzPU9PCqZKk1qOKHejC/QznQAJL+SunA5FcShnGQP4fT5I+\n",
       "A37NVn/flZUM5scMYyCHcBzzGZ52re3YjvsYzsHksJgnOZxzGEceU9iBcxjGoXRnVSPdaVbsEVN9\n",
       "NNQrts37VV1JUvYCn3IakwDoxGPM41wKyGUHJvNqasqJAjYjj068Sg8KaANsy6sso4BcSvk6r7IF\n",
       "+QRepQfl5PIG5/EUexCoIpfOPMWelNGWNnxKd1byKj1ozydEdudV3kqdswuvrjXcpl3otZGTMTTC\n",
       "GGaDmGp3M+eznGMJLCSXT8llKtfwKD0YyUm8zb/Zgud5hqvYl9s5ni8ZSKSQSnrQgd8TKWAZxwCr\n",
       "GMgp9GExsOGFUyVJLV1M+xTIZ3Xq6E0pPVJjtqZQwZasYj+W8wZVbMtK9mM5rwG9WEEPlvMfYD+W\n",
       "8zDfp5D2/D9OpA1V/Iqn6EYlVazgI8qqp7mYyUoqKUw754q1psBoA+y1keOgG2EMs48mVbMH2Y3l\n",
       "DOI0+nMUJ1NB77RvM/dqVbITx/Ij+nEYi7mUXJYxjEMpYBL/4thUq5oWTpUktRaRLjzAXgAs4AcU\n",
       "MjWr81VQRB5f0IYqnubbVNG5ltaru7xyWM4KNsvquo3MIKaazWMfCnmG7qxiN5bRhuc2eEwB/6EX\n",
       "K9ifLwh8ya6MB6CQ6ZTTLdVq7YVTI+2Z0rz/oEiS6iEQyWEWczmdkZQQac/Oqb/362/1L/778Qwr\n",
       "+Ca/5hE+4ghy+WCt62U6Zhue5D2u4HYe4u/szm1cspE1NBofTao2NY3lqqQqtbDqUtqu8136q7lV\n",
       "bFa9XUWs5d+3HMeNSVKrcThzOZwD1tr3Kj24iCPX2vczrq7+fF7ay2Dp7S7mewDswGLO54yM19uT\n",
       "E6o/n8qfqj8fw4uw1mqQU3lzI6fCaCQGMdVsGybwPr9iDr9hCXmsoj/5/IlcPmYhuwNTeIcj6ni2\n",
       "sNbnTAunSpI2DTdxC+VsTaQNnXmIH/NXrubfFPMgS+hLYCWDuYhd+IJbuJpclrKcnalkS3rwa07m\n",
       "BSqB33AhS/kOEPk693AK47mZkWzLC/wwtX7kzVzLtjxHW5Yyk1Poz+WM5mIq2JZKvk4VXWjPH7iI\n",
       "+1LtL2Q5R1ePjW7LVIZyV2P9KHw0qZr9kP/SjicZw3ie4E/k8RYQ+Qa/ZwmnMopnqWQLvuo5i+t0\n",
       "D6/9OazVbvXCqR9zPdtzcVPcjiSpmTiGEVzByZzFyXzGEGbSgUhbtmIqV3Aim/EmJRxd3b6cLbmc\n",
       "M/geFzCb8wEYyyGsYCcu43iO4mfM5kLeZkt24Ak+YRAAs9mMFezOsby8Xg0V7MBZDKE/R7CEi1lC\n",
       "Dv9Hb1ZwGGdyCMdwEhXsTiO/6W+PmGr3c+4A7lhv/9H0T9saDcD5PAo8Wr33Kvar/pz+3ZUc1wiV\n",
       "SpKSVkpZLW8WtqNN6lMJp7GMvgBUsTWvsRNQzk68yZu0o4APWEIf3qQdFeTSgf/wJu3owDwq2ZI3\n",
       "acdn9KE9LzCFdsAqCpjCa+zFt/g3/2U7nqUz73EQhbzEfylkMW2pIpcyyoBIO55nKyrYii8Yz+dM\n",
       "oBML6ENbnqUz5XSmnDaMZ+0nOg3OICZJkhpEbXNshV5h9bQR97Ify9iVUxlAd1ZxDY9SzkKgnL34\n",
       "EIDX+IxKlrMXH/IsXxKZW/3dk0T24kPGs4hKFlbvf5ZlVPIZe/EhL/IQ79CHZRzMzlzIXnzIZLah\n",
       "iuXsy1z+BQTK08qrpJxcVvd+rT2UppH5aFKSJDWdctqTwyK6s4q/sCMVqSku6qsDE1jCIJYTeIVi\n",
       "ytiHnZkMQB8e4UvOBCLHMCvD0esHrECkExNZSX8+oYB3accqDsFHk2pytXctN831JUmt02Be5I+c\n",
       "wkhKyGUWeanZ99df9LvmMccAZ/MPbuJb3MzzQORrjKIvCwHoy0Je5j3a80z1UWGtc2ZeWulkpjKa\n",
       "5/gjz5PD5+QxnVyWZHW/GxBibN6zBoQQYoyx0bsGJUlS4wm9Qk+GNNEb8jNpy1he4AcMqPdb+dMp\n",
       "pBcrmElbHuZxduQShvAOAGM3vGB4fXOLPWKSJKn1uIfvMZeb6cBdGzU10uOMppKeRNpSxCPVIayR\n",
       "2CMmidApdKeYgia/cCMsoCupeWrSHrHGYo+YpEZRTEEif0EmORZRUtNKevxxQ2iEMcwGMUmS1Ojs\n",
       "/c7M6SskNb47GcBf2DHpMiSpuck6iIUQBoYQpocQZoYQLq2hze2p76eEEPZM7esWQngxhPBOCOG/\n",
       "IYTzs61FUhNYshF/byziMOazUyNUI0ktWlaPJkMIucBvgH7AXGBiCOHJGOO0tDaHAzvGGHuGEPYB\n",
       "7gT2BcqBi2KMb4UQNgMmhRDGpx8rKQGZFrxdTj/yeYcy9qaIv7I1r/EhVxEpIlDK/lzIQSzg1/yQ\n",
       "JZxEJJ88ZnMi5/Myu1JGfxawL6O4gD04k+/zUdK3KUnNQbZjxPYG3o8xzgYIITwMDAbSw9QgYAxA\n",
       "jHFCCKFjCGHrGONnwGep/UtDCNOAbdc5VlJTSl/w9gvy+QvPAlMBiOQxjMMpJZff8jj9OJ39+ILf\n",
       "MojXuIyDuJh9eZp9eAiA0VzC3xjCRdzH9TzH5oznnLTJFSVJWQexLsDHadufAPvUoU1XYN6aHSGE\n",
       "7YA9gQlZ1iMpG5kXvF1ta54E4Hl2pJJv8DwPp+azziUn9ef5HXrxHJcSaU+kiDa8mHZ2p6GRpHVk\n",
       "G8TqOgnZun8BVx+Xeiz5F+CCGOPSjAeHMCJtsyTGWFKPGiXV3boL3n6lgOWpFoFcZjCMweu1+Zjb\n",
       "6MXpnMB0buc4lrHfOueWpFYlhHAgcODGHp9tEJsLdEvb7sbqHq/a2nRN7SOEkA88BvwpxvhETReJ\n",
       "MY7Isk5JddGJiXzITXzCHSwhj1X0I58HU9+uDmh9mcUMtuQB9uJU3mQBeZTQg+OYCRTRhfksII8l\n",
       "HEPu6j/r5LCMCto35a0kNkltNpzgVmpxUp1DJWu2QwhX1ef4bIPYG0DP1KPFT4ETgCHrtHkSOBd4\n",
       "OISwL7AoxjgvhBCAe4F3Y4y3ZVmHpIZQ84K3Xy2Q25lyevJTZjGKkbQH8ticu4GZbM5NvMA4XmQh\n",
       "BUyminYAbM3f+IjRjOJH7MFPm2SwflKT1GajpU92Kanesl7iKIRwGHAbkAvcG2O8PoRwFkCM8a5U\n",
       "m98AA4FlwBkxxjdDCN8FXmb1QOA1RfwyxviPdc7vEkdSI1tr6ZHaFrxtaHVYLmRjtcjlVBrx5yGp\n",
       "aTT5Ekcxxmdg7Teh1gSwtO1zMxz3Ck4oKzU/TbzgbasyiicYxlFJlyGp5XCJI0lru5z1fnFSHRnC\n",
       "JNWTQUxScovxNsICuhldy71UsS2RNmzOPVzAQ4xgJu24n5UcQg7z6c4NzOFKqtiWTlzFzxjPOLoy\n",
       "mduJqbFuX+cKTmMSo/k5K+kPQBVfo4ASfsnFjGAmI+jJvezH/7iYHBZSQS/ymMrlnAfAXRzMPK4i\n",
       "sJwC3qCCblzB6U3yc5DU7BjEJLX+xXgHMJQ+LOYD2vInxjGBp4FCOvIKP+VaruUe5vALzud4nuYb\n",
       "zOQ2YDzf5HN6cyJdKeMJevA2vwUO5xJuBm5mMu35O3+lO/elrvTVoNsKduG7HMgBzOMG/sb9fJuD\n",
       "eJvPuJE+HMXhzOU6fksrnNZjg2+s+naoVM0gJqn1K+EnPMOhAFTRmRn0AMr4KS8BUMA0clhFB6oY\n",
       "xHRuSk25s5h8/sG1lLMzgUoq2aH6nOXA0/yGjtzFD/nvetfM4y36pSa6zecdvqQb/2EFuczh8NS0\n",
       "HsU8wUJOasQ7T8aG3lj17VCpmoPlJbVu97IfK/kup/F9hjOAPN6hgjZARVqrSKAcgHZE1vyS+jw/\n",
       "JZd5DKcfF3AYkF99xG1cTC5zOZ9HM143sCptq4pIHuv3fvlGuLSJs0dMUutWTntyWER3VvEXdqSC\n",
       "vep8bBWbkc//ALif41g9TQ/8nv6s5Hv8jGPrfK5A5DvM4j268zRdOJy5lDKIVvhostpj7MC73EJk\n",
       "M3JYxCGcyX58kXRZUnNij5ik1m0wLwJ5jKSEGfySPCalvlk3AMX1PvdiDEs5jpE8x0p2gNTjts85\n",
       "kyq25veMYxTPMpqLazxHuu6sYmt+yRs8xCieIYcvCWRc2q1VCMBenMtw+lHAG/ybU5IuSWpusp7Q\n",
       "tbE5oaukjdFsJ3RdM2EuwA1cSwEfMJR7gVYzoWvGn/2NXEU+/2Mod7eW+5QyafIJXSVJ9fA0J/Eo\n",
       "xxEpIJ+3OYY/JV1So7ubA1jFQQzkyKRLkZobg5gkNaWh3APck3QZTWY5gf9xM3tyLL1b8WNYaSMZ\n",
       "xCS1TklNUpuNpprgtin9i20ILGEQzhsmZWAQk9QqOWFoM7E9XzCHkUmXITVXvjUpSWo8c9icz/lh\n",
       "0mVIzZU9YpKkxtOPefTjrKTLkJorg5ikZmO9NQpXsC0BaMuniRXluoiSGpFBTFLzse4aha+mFiPa\n",
       "K8H5wFragH9JLYpBTJLUsDb0xmprfDtU2kgGMUmbljsZwFZ8wLG8n3QprZWPcqW6861JSZuWRRzG\n",
       "fHZKugxJAnvEJLUEt3A2OazkIu7jRkZQzje5khO4h/2Zz4nk8CXl7EGkLYWM4xJuAeAmLmcl/YEK\n",
       "2vISW/MMZfRnAfsyigvYk59QRQ5TuZbIlgRWsDOXcDSzkr1hSZsKg5ik5m8rXuMTzgLuo4zeQB6l\n",
       "5PIF+1DEq3yHcfRhMUvI4XYe4RF68XXmsZKBDKcvAFPYjN4s5XqeY3PGcw7PAHANj7AblzKY2TzA\n",
       "nrzLdRzNCcndrKRNiUFMUvN3GG9zJ7vzNkUEVpHPFJ6iN6vYmx5cyb8ZxD84iUguka35nJ4cxnuM\n",
       "ZyXXcwsdGc+xPJ92xgDAu7Sjgm8zlbuYmvompk2fIUmNzCAmqfnbigpy+IjnOZ42TKSIacxnfyrZ\n",
       "jkJWsoSz+D6HsSdfcj23UklbOlDFmRzBk3yXUo7kLs7gyuqerghAOTkEFjOMQ5O7OUmbMgfrS2oZ\n",
       "2vA6SzibLXiNXZnAMk4lj7f5kvbAcnblS0r4GmUcTCAynUJm0oGzeJGBjKCSXQDIYRkVtAegN0vJ\n",
       "4SN+xxEAlAMP882E7lDSJsgeMUnNz7U8wHe4mLZp+7ZgAss4j4OZxPaspIQVFDKBE5nG9fyX63mZ\n",
       "HD4ln9cB+B+b8Qr3UUIbIFDMVQBszd/4iNGM4kfsyZnsxblM5gZGcgGQTzueAKY19S1L2jSFGGPS\n",
       "NdQqhBBjjCHpOiQ1vtAr9FxnZv0eqZn1P0ysqLEUxelxZmLXl9Si1De3+GhSkiQpIQYxSZKkhDhG\n",
       "TFLzse4ahSvIIwAzElx423URJTUix4hJkiQ1EMeISZIktRAGMUmSpIQYxCRJkhJiEJMkSUqIQUyS\n",
       "JCkhBjFJkqSEGMQkSZISYhCTJElKiEFMkiQpIQYxSZKkhLjWpCRJUpZCp9CdYgrIh9Ar9FyvQSll\n",
       "cX6cs+5ug5gkSVK2iilgCMu4BRjCsvW+H0tRpsN8NClJkpQQg5gkSVJCDGKSJEkNZWnqn+PoyjU8\n",
       "uqHmjhGTWojqgaAbo4ZBopKkZBnEpJZizUDQjVHDIFFJUgMLqX/mUkUOX2youUFMkiSpoaz5tXcg\n",
       "nzKQn26ouWPEJEmSEmKPmKTEZTX+rSE5lk5SE8s6iIUQBgK3AbnAPTHGGzO0uR04DFgOnB5jnFzX\n",
       "YyVlcC33UsW2RNqwOfdwAQ8xgpkU8QdW0I/ASg7gDPqyMOlS6ySb8W8NybF0kppYVo8mQwi5wG+A\n",
       "gcDOwJAQwjfXaXM4sGOMsSfwU+DOuh4rqQYDGMowDuNkDmcxP2YCHYFCOjCJ4QygDRN4nZOSLrPe\n",
       "xtGVkbyw0ceP5mLu4bsNWJEkNapse8T2Bt6PMc4GCCE8DAwGpqW1GQSMAYgxTgghdAwhbAP0qMOx\n",
       "kjIp4Sc8w6EAVNGZGfQAyjgrFWKKmMoS+iZYYdNbTuASbkm6DEmqj2yDWBfg47TtT4B96tCmC7Bt\n",
       "HY6VtK572Y+VfJfT+D7dWcU1PEoFbYCK6jaBKlY/8m+J8riOO6hgN/KYwYlcwD/5Nv9jGJFc8pnC\n",
       "6VxGZ8q5mgkU8jdW0ZdifscSDmJzxnMOT3M1E2jHn1lJfyJ57MpZHM0sXqGYEn5HFZ3IZxJl9GUg\n",
       "h7IPi5K+cUmbnmyDWKxju7DhJrUcHMKItM2SGGNJNueTWrRy2pPDIrqzir+wIxXslXRJDaqKHejC\n",
       "UE5jEtdzC49zFss4mT04jsHM5npuYyynMpR7gUgupQxjIADXcyBf/b0UyWMhwxjIbZzKDH4GXMIr\n",
       "DKWQl7lHirjWAAAeG0lEQVSY33E3B/ApQ5K5UUmtQQjhQOBA8ticG8mlgszjTUspy3R8tkFsLtAt\n",
       "bbsbq3u2amvTNdUmvw7HAhBjHJFlnVLrMZgX+SOnMJIScplFHpNS36T/YhSp+y9KzUvgU05L3VMn\n",
       "HuN/XEgucxjMbAC24lHmcTpwLwC78GSN59qdpwEo5m0+4nAAyunD7vwIgJ/yElfbEyZp46U6h0rW\n",
       "bIcQzovT48y6Hp9tEHsD6BlC2A74FDgB1vvt8kngXODhEMK+wKIY47wQwsI6HCtpXZ0p5wpOyfDN\n",
       "N6o/ncPTkAohLU9M+xQILCGyRdr3gZDWZguW13imzVK/geZQSfqj2phdL70kNZSs3pqMMVawOmQ9\n",
       "C7wLPBJjnBZCOCuEcFaqzdPAByGE94G7gHNqOzabeiS1ApEuPJB63LqAH9CGKVTSjSfpntp3DIW8\n",
       "utHnz2ci0xkEwB/oS6Rj9kVL0sbJeh6xGOMzwDPr7Ltrne1z63qspE1YIJLDLOZyOiO5lTxmcBx3\n",
       "M543mcLdvEUu+bzFyfxf6oi6PX4NaY9qv8utlPA7RnIMBUwiMJ/tWdo4NyRJtQsxNu9hJCGEGGP0\n",
       "MYI2eVnNPt/MZ4wPvULPJpvQ9X/kU0QlHahiDN/iI65jWGoqkLEU1WdshyStq765xSWOpBaiOQep\n",
       "FuV1ujCVu1Ljz8rZnp8nXZKkTZdBTNKmZTCzGZzqAZOkhGU1WF+SJEkbzx4xSckrpaxZLLhdw4SL\n",
       "ktRYHKwvSZLUQOqbW3w0KUmSlBCDmCRJUkIMYpIkSQkxiEmSJCXEICZJkpQQg5gkSVJCDGKSJEkJ\n",
       "MYhJkiQlxCAmSZKUEIOYJElSQgxikiRJCTGISZIkJcQgJkmSlBCDmCRJUkIMYpIkSQkxiEmSJCXE\n",
       "ICZJkpQQg5gkSVJCDGKSJEkJMYhJkiQlxCAmSZKUkLykC5CkxhQ6he4UU7DWzlLK4vw4J6GSJKma\n",
       "QUxS61ZMAUNYtta+sRQlVI0krcVHk5IkSQkxiEmSJCXEICZJkpQQg5gkSVJCDGKSJEkJMYhJkiQl\n",
       "xCAmSZKUEIOYpE3HNTzCC3RKugxJWsMgJmnTsJxAJdvxDRYlXYokrWEQk7RpeIqetOUpulKWdCmS\n",
       "tIZLHEnaNBzPe8CopMuQpHT2iEmSJCXEHjFJrVspZest8l3q40lJzUOIMSZdQ61CCDHGGJKuQ5Ik\n",
       "aUPqm1t8NClJkpQQg5gkSVJCDGKSJEkJMYhJkiQlxCAmSZKUEIOYJElSQgxikiRJCckqiIUQikMI\n",
       "40MI74UQngshdKyh3cAQwvQQwswQwqVp+0eHEKaFEKaEEB4PIWyeTT2SJEktSbY9YpcB42OMOwEv\n",
       "pLbXEkLIBX4DDAR2BoaEEL6Z+vo5YJcYY2/gPeCXWdYjSZLUYmQbxAYBY1KfxwBHZWizN/B+jHF2\n",
       "jLEceBgYDBBjHB9jrEq1mwB0zbIeSZKkFiPbILZ1jHFe6vM8YOsMbboAH6dtf5Lat64fAU9nWY8k\n",
       "SVKLscFFv0MI44FtMnx1RfpGjDGGEDItXLnBxSxDCFcAZTHGhzbUVpIkqbXYYBCLMfav6bsQwrwQ\n",
       "wjYxxs9CCJ2B+RmazQW6pW13Y3Wv2JpznA4cDhxSy3VGpG2WxBhLNlS3JElSYwshHAgcuNHHx7jB\n",
       "DqvaLn4TsDDGeGMI4TKgY4zxsnXa5AEzWB20PgVeB4bEGKeFEAYCtwAHxBg/r+Ea9VrFXGptQqfQ\n",
       "nWIKkq6jwZRSFufHOUmXIUmNob65JdsgVgz8Gfg6MBs4Psa4KISwLfCHGOMRqXaHAbcBucC9Mcbr\n",
       "U/tnAgVAaeqUr8YYz8nmhqTWJvQKPRnCsqTraDBjKYrT48yky5CkxtCkQawpGMS0qTOISVLLUd/c\n",
       "4sz6klYbQf3D0W85kpGUcA2P1NruaiYwgYwTPkvSpmyDg/UlbTLq3j1eDpQT+IIhfJ2fczpvNNi5\n",
       "JWkTYhCTWopbOJscVnIR93EjIyjnm1zJCdzD/sznRDrwPKWcBwTa8gK/4DpgdU9XEX9gBf0IrOQA\n",
       "zqAvC3mKbkzmt0TaUchz611rOUcSKaCQf3AJtzCOrkziIfJ5k3J2px1/p4I+fMSt3MSztOU9ltOb\n",
       "y7gSgGsZQ2d+x4+Y0NQ/KklqKXw0KbUUW/EaK9gHgDJ6E2lHKbl8wT4U8AELuYL+HMeF9KeM3tzJ\n",
       "gNSRhXRgEsMZQBsm8DonATCFkXTkfobTj3zmVV/nD/SlnO0YxhH8nAGUsRv3sTcAVfSgK/cznIP5\n",
       "Ob8ijynswDn8gmszVGwvmCRtgEFMaikO420q2J23KSKwigIm8RS9WcXe5LKYAv7NfnxBB6rowF9Z\n",
       "wr6pI8s4ixcAKGIq5al5/Srow2k8AcBBPFZ9nVIOYBUHMIpnuYV/UMkOfEkPAAKfcApvNd1NS1Lr\n",
       "5qNJqaXYigpy+IjnOZ42TKSIacxnfyrZjkI+YSW7V7eNaf8NFdX7A1Wsnkamdh25gwt4cK194+hK\n",
       "YHmNxwQqgK/eFIq03fBNSdKmzSAmtSRteJ0lnE0XLmInpvMiV5PHW3yDybzMKF5lC3ZhMV9yFF/j\n",
       "3lrPlcdExjCY8/grL3J09f5iSviMXzCdx+nFCsazDYWUbbC29nzCIk6jHHiBbalgj2xvV6qLRCc9\n",
       "doJiZckgJrUkWzCBZZzHwUxie1ZSwgoKmcBBLOAdrmM8jzKeQFue52eMTx2VPlYrVm/vwTDe5LeM\n",
       "5P9RyLPV+8/kX/yKnvyZvwMQWMqenEdIOzaT05nIdXzM9bxELjPJY2qD37+USTEFic21N5aiRK6r\n",
       "VsMJXaVmzgldpdo1+J+RW/kJR/EntmclsPrN4xH0zNjWf5+1Did0lSRpYy0hhy/5CfMoTNvbvHss\n",
       "1KL5aFKS1DpkM9deIQ+wiu/RjqeJbM14HuUFFnIlJwAwml+sNxef1AAMYlJzV0pZqxqHUlqHgf/S\n",
       "xtiK1/iEs4D7KKM3kLfeXHsDOJRdWMztjOVOBnA2zwGFtOdNLmUUAFdzIodyLPuwKHXmdnRgEpdw\n",
       "EzdxBa9zEn25PaG7VCtjEJOaOd/IkuroMN7mzrS59vKZUj3XXhHPVc+1B6TNtfccUMmZjKvlzGvP\n",
       "xbeEvo1+L9pkOEZMktQ6rDvXXnteX2uuvbXnufvqv2EV+bWeuf5z8Ul1ZBCTJLUea+ba24LX2JUJ\n",
       "LONU8nibbzCZMvbjVbZIDcg/is15LeM5Akv5nM2auHJtogxikqTWYwsmENmKg5lEXxYS0uba2zI1\n",
       "195tjKeAKTXMtQfteZBJPMQ1PJLh+9rn05PqyXnEJEktWqJz7TmPmNbhPGKSJEkthEFMkiQpIQYx\n",
       "SZKkhDiPmCSpZUty0mMnKFaWHKwvSZLUQBysL0mS1EIYxCRJkhJiEJMkSUqIQUySJCkhBjFJkqSE\n",
       "GMQkSZISYhCTJElKiEFMkiQpIQYxSZKkhBjEJEmSEmIQkyRJSohBTJIkKSEGMUmSpIQYxCRJkhJi\n",
       "EJMkSUqIQUySJCkhBjFJkqSEGMQkSZISYhCTJElKiEFMkiQpIQYxSZKkhBjEJEmSEmIQkyRJSohB\n",
       "TJIkKSF5SRcgSWq9QqfQnWIKEi2ilLI4P85JtAapBgYxSVLjKaaAISxLtIaxFCV6fakWPpqUJElK\n",
       "iEFMktQ6/JF9GcO3ki5Dqg8fTUqSWoeF7E8uS4FJSZci1dVGB7EQQjHwCNAdmA0cH2NclKHdQOA2\n",
       "IBe4J8Z44zrfXwyMBr4WYyzd2HokSc3YdAp5jLuoZBsglyIeYyV7cgVncicDmMednM9OfEkeY3iR\n",
       "4XyHJ+nOVK4lsiWBFezMJRzNLF6hmJe5gUq6ANCNq+jE/1jOyUAloziarlzJGUxM9J6lOsimR+wy\n",
       "YHyM8aYQwqWp7cvSG4QQcoHfAP2AucDEEMKTMcZpqe+7Af0B32aRpNbsnxxELp9xBacCMIXN+Bsn\n",
       "A7CEfchlGk+yJ1XkkcebAEzlJnbjUgYzmwfYk3e5jqM5gZcZxbb8gdOZyDNsy0Qe4nQO5B3+j1yW\n",
       "MpS7E7tPqZ6yCWKDgANSn8cAJawTxIC9gfdjjLMBQggPA4OBaanvbwV+AfwtizokSc3dtkxjAcO5\n",
       "icvZivGcwUT+zhweYwfK2YNi7mYh+xDJpR0TmE4hFXybqdzF1NQ5YmoajHK+x8fsyKjq/UVMpzC1\n",
       "FZr61qRsZBPEto4xzkt9ngdsnaFNF+DjtO1PgH0AQgiDgU9ijFND8M+NJLVqR/Eh3RjAfziEuVzK\n",
       "zbxCW15jDocA5ezBvyjh10Ry2ImRrCKXwGKGcWiGswV+wpF0pnytvX9vkjuRGlStb02GEMaHEN7O\n",
       "8J9B6e1ijBGIGU6RaR8hhELgcuCq9N211DEi7T8H1lazJKkZeoFOfI1VnMdf+Rq/ZxW7UcwEvuRM\n",
       "2vAG+/MFVWxBFdtzPO/Rm6Xk8BG/4wgAyoGH+SYA+bzEQ/y4+txj2QWAXJZSyWZNfm/apIUQDkzP\n",
       "KfU9vtYesRhj/1ouPC+EsE2M8bMQQmdgfoZmc4FuadvdWN0rtgOwHTAl1RvWFZgUQtg7xrjeeWKM\n",
       "IzZwH5Kk5uwDevFvhhGoAirYnkvZj/d5gC3ZggkA5PMulWxVfcxenMtkbmAkFwD5tOMJYBoHMYwX\n",
       "uZaRjAfyKOBV4HK2ZzxTuZtRDKAbV3K6g/XV+GKMJawengVACOGqGhtnEFZ3ZtVfCOEmYGGM8cYQ\n",
       "wmVAxxjjuoP184AZwCHAp8DrwJA1g/XT2n0IfCvTW5MhhBhj9NmlJLVAoVfo2Rxm1o/T48xEa9Am\n",
       "o765JZsJXW8A+ocQ3gMOTm0TQtg2hDAOIMZYAZwLPAu8CzyybghL2bg0KEmS1IJtdI9YU7FHTJJa\n",
       "LnvEtKmpb25xZn1JUuMppSzxRbdLKUv0+lIt7BGTJElqIE05RkySJElZMIhJkiQlxCAmSZKUEIOY\n",
       "JElSQgxikiRJCTGISZIkJcQgJkmSlBCDmCRJUkIMYpIkSQkxiEmSJCXEICZJkpQQg5gkSVJC8pIu\n",
       "QJKk5ip0Ct0ppqBRTl5KWZwf5zTKudViGMQkSapJMQUMYVmjnHssRY1yXrUoPpqUJElKiEFMkqSm\n",
       "MJqLuZWzki5DzYtBTJKkphGTLkDNj2PEJEmqizs4li84C4jk8y69Gc2b/IoqtiCHhXyboQzkU8bR\n",
       "lcncut5+KQN7xCRJ2pA/sxNfcD6HchzDGUA/rmIy17I5jzCc/nTgr0xiFABvcU3G/VIGBjFJkjZk\n",
       "LvtTyN/Zh0UA9GExFXyL0/grAEN4jAr2Bqhxv5SBQUySpLoJ6+2pyLCvtv3SOgxikiRtSFdeYQVH\n",
       "MoGOAEygI3m8wYMMBmAsR5PHawA17s8U5LTJc7C+JEkbchwzuYPbeZbHeJZK8nmbvbiCSfyKkZxN\n",
       "Dgvpw0UANe5f/dakb05qLSHG5v3vRAghxhj9LUKS1ORCr9CzMWfWj9PjzEY5txJT39zio0lJkqSE\n",
       "GMQkSZIS4hgxSZJqUkpZoy3OXUpZo5xXLYpjxCRJkhqIY8QkSZJaCIOYJElSQgxikiRJCTGISZIk\n",
       "JcQgJkmSlBCDmCRJUkIMYpIkSQkxiEmSJCXEICZJkpQQg5gkSVJCDGKSJEkJMYhJkiQlxCAmSZKU\n",
       "EIOYJElSQgxikiRJCTGISZIkJcQgJkmSlBCDmCRJUkIMYpIkSQkxiEmSJCVko4NYCKE4hDA+hPBe\n",
       "COG5EELHGtoNDCFMDyHMDCFcus5354UQpoUQ/htCuHFja5EkSWqJsukRuwwYH2PcCXghtb2WEEIu\n",
       "8BtgILAzMCSE8M3UdwcBg4DdY4y7AjdnUYskSVKLk00QGwSMSX0eAxyVoc3ewPsxxtkxxnLgYWBw\n",
       "6ruzgetT+4kxLsiiFkmSpBYnmyC2dYxxXurzPGDrDG26AB+nbX+S2gfQE+gbQngthFASQvh2FrVI\n",
       "kiS1OHm1fRlCGA9sk+GrK9I3YowxhBAztMu0L/3aW8QY9w0h9AH+DGxfQx0j0jZLYowltdUtSZLU\n",
       "FEIIBwIHbuzxtQaxGGP/Wi48L4SwTYzxsxBCZ2B+hmZzgW5p291Y3StG6p+Pp64zMYRQFULYMsa4\n",
       "MEMdI2q/DUmSpKaX6hwqWbMdQriqPsdn82jySeC01OfTgCcytHkD6BlC2C6EUACckDqOVPuDAUII\n",
       "OwEFmUKYJElSa5VNELsB6B9CeI/VgeoGgBDCtiGEcQAxxgrgXOBZ4F3gkRjjtNTxfwS2DyG8DYwF\n",
       "Ts2iFkmSpBYnxFjbMK7khRBijDEkXYckSdKG1De3OLO+JElSQgxikiRJCTGISZIkJcQgJkmSlBCD\n",
       "mCRJUkIMYpIkSQkxiEmSJCXEICZJkpQQg5gkSVJCal30W1LzFzqF7hRTUKfGpZTF+XFOI5ckSaoj\n",
       "g5jU0hVTwBCW1antWIoauRpJUj34aFJqLUrJ5Roe5FF6ZtyWJDU7BjGptSimkgM5j/e4nFJy19pe\n",
       "4p91SWqOQowx6RpqVd9VzKVNTegVetbn0WScHmc2ckmStMmqb27xt2RJkqSEGMQkSZISYhCTJElK\n",
       "iEFMkiQpIQYxSZKkhBjEJEmSEmIQkyRJSohBTJIkKSEGMUmSpIS46LfU0pVSVufFvEspa+RqJEn1\n",
       "4BJHkiSlCZ1Cd4opaNCTllIW58c5DXpONUv1zS32iEmSlK6Ygjqv31pXde211ibHMWKSJEkJMYhJ\n",
       "kpTJOLoykhea/FhtUgxikiRJCXGMmCRJNcvjOu6ggt3IYwYncgGPczYr6EekLQW8wWVcCsCD7MYs\n",
       "bgUibXkp2bLVUtgjJklSTarYgS7cz3AOJLCUJziNA/gjwziC4RxCpC2/px8As/gV3bic4QxIuGq1\n",
       "IPaISZJUk8CnnMYkADrxGJ/xYybyMf/gHCJtiXRkGTOYxOtEOnAGEwHozmPM4OAkS1fLYI+YJEk1\n",
       "i2mfAhBZwHXsy08YTj/a8RCRNuQQ1znK+S9VJwYxSZJqEunCA+wFwAJ+QCGvA7ATX/Au7VjBkQDs\n",
       "yZcEFnM/fQD4iKOTKVgtjY8mJUnKJBDJYRZzOZ2R3EoeMziKB3iMzRnDPwksIJ/J1e134CJmcSuj\n",
       "iPz/9u4tVq6yDOP4/5G2nojUGi1yUNCUgDcCUQRR2aLGggZIDKI3YLwhEg8EooAk6B0ng2iMFyoY\n",
       "PIdUJBiNUhXijZiqBUWolCjIIS3EpiYaSTF9vZhVO7vslr3n9M20/18y6Zq1vrX3u9797emzZ62Z\n",
       "eSG/Bqb7o2s0FfyII0mS+uTYrBnHO+vXpto80q+pqbTU3OKpSUmSpEYMYpIkSY14jZgkSf22sWPk\n",
       "H9K9jR0j/Xrab3iNmCRJ0oh4jZgkSdKMMIhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOYJElSIwYx\n",
       "SZKkRgxikiRJjRjEJEmSGjGISZIkNTJwEEuyKsn6JA8luTPJyr2MW5tkU5LNSS7rW398knuSbEyy\n",
       "IcmbB61FkiRpFg3zjNjlwPqqOgb4ZXd/niQHAV8B1gJvAD6c5Lhu83XA56rqBOCq7r4kSdIBY5gg\n",
       "dhZwS7d8C3DOAmNOAh6uqkeq6lngB8DZ3badwCHd8krgiSFqkSRJmjnLhth3dVVt7Za3AqsXGHM4\n",
       "8Fjf/ceBt3TLFwM/T/IFeoHwlCFqkSRJmjn7DGJJ1gOHLrDpyv47VVVJaoFxC63b5SLg4qr6UZJz\n",
       "gZuB9+yljs/33b27qu7eV92SJEmTkGQOmBt4/6p9ZaV9fuNNwFxVbUnyauCuqjp2jzEnA5+vqrXd\n",
       "/SuAnVV1bZLtVbWyWx9ge1Udsse3IUlVVQYqUpIkaYKWmluGuUbsDuCCbvkC4PYFxvwOWJPkqCQr\n",
       "gPO6/QCeTHJat3w68NAQtUiSJM2cYZ4RWwXcCrwGeAT4YFVtT3IY8PWqel837gzgRuAg4Kaqurpb\n",
       "fyrwJXqnR/8DXFRVGxf4Pj4jJkmSZsJSc8vAQWxSDGKSJGlWTPLUpCRJkoZgEJMkSWrEICZJktSI\n",
       "QUySJKkRg5gkSVIjBjFJkqRGDGKSJEmNGMQkSZIaMYhJkiQ1YhCTJElqxCAmSZLUiEFMkiSpEYOY\n",
       "JElSIwYxSZKkRgxikiRJjRjEJEmSGjGISZIkNWIQkyRJasQgJkmS1IhBTJIkqRGDmCRJUiMGMUmS\n",
       "pEYMYpIkSY0YxCRJkhoxiEmSJDViEJMkSWrEICZJktSIQUySJKkRg5gkSVIjy1oXoNmQV+W1rGLF\n",
       "vJXb2FFP1aONSpIkaeYZxLQ4q1jBh/n3vHXf56WNqpEkab/gqUlJkqRGDGJamuu5lBu4sHUZkiTt\n",
       "DwxiWqpqXYAkSfsLg5gkSVIjBrElSDLXuoap8X1OaV3CtHBe9NiH3ezFbvZiN3uxm73YzSC2NHOt\n",
       "C5gSxXbe2rqIKTLXuoApMde6gCky17qAKTLXuoApMte6gCky17qAaWEQ09J8mhu4hK+1LkOSpP2B\n",
       "QUySJKmRVE33i+CSTHeBB4rlwIuAHUC6+88Az7YsSpKk6VNVWezYqQ9img45NmsWemf92lSbG5Uk\n",
       "SdLM89SkJElSIwYxSZKkRvzQby3ONnY850O+t7GjUTWSJO0XfEasT5JVSdYneSjJnUlW7mXc2iSb\n",
       "kmxOclnf+uOT3JNkY5INSd48uepHa89e8DT/rE21ed7tqXp0b73ovsYnkjyY5P4k17Y6lmENOy/6\n",
       "tl+aZGeSVeOvejxG8DtyfTcn7ktyW5JDJlf9aDzfz7kb8+Vu+31JTljKvrNk0F4kOTLJXUn+3D0+\n",
       "fHKylY/eMPOi23ZQ93/HjydT8XgM+fuxMsm67jHigSQnT67yhqrKW3cDrgM+0y1fBlyzwJiDgIeB\n",
       "o+i9dvBe4Lhu253Ae7vlM4C7Wh9Tw168E1gPLO/uv7L1MbXqRbf9SOBnwN+AVa2PqeG8eA/wgm75\n",
       "moX2n+bb8/2cuzFnAj/tlt8C3LPYfWfpNmQvDgWO75YPBv5yoPaib/slwHeBO1ofT6s+ALcAH+2W\n",
       "lwGHtD6mSdx8Rmy+s+hNBLp/z1lgzEnAw1X1SFU9C/wAOLvbthPY9Rf+SuCJMdY6bsP24mPA1d16\n",
       "qurpMdc7TsP2AuAG4DNjrXIyhupFVa2vqp3duN8CR4y53lF7vp8z9PWoqn4LrExy6CL3nSWD9mJ1\n",
       "VW2pqnu79f8CHgQOm1zpIzdwLwCSHEEvoHyD3hsEzaqB+9A9O/72qrq52/bfqvrnBGtvxiA23+qq\n",
       "2totbwVWLzDmcOCxvvuPd+sALgauT/J34HrginEVOgHD9mIN8I7uVO3dSd40vlLHbqheJDkbeLyq\n",
       "/jjWKidj2HnR76PAT0db3tgt5tj2NuawRew7SwbtxbzwneQo4AR6wXxWDTMvAL4IfJreH/OzbJg5\n",
       "cTTwdJJvJvlDkq8neclYq50SB9zF+knW03tafE9X9t+pqtrLm8nu643XLgIurqofJTkXuJneqZip\n",
       "NOZeLANeXlUnd9fK3Qq8buBix2xcvUjyYuCzzJ8HU/0X75jnxa7vcSWwo6q+N1iVzSz2jRen+mc8\n",
       "IoP24v/7JTkYWAd8qntmbFYN2oskeT/wVFVtzOx/EPYwc2IZcCLw8arakORG4HLgqhHWN5UOuCBW\n",
       "VXsNRkm2Jjm0qrYkeTXw1ALDnqB3vc8uR9JL9ADnV9Wui07X0XuaeWqNuRePA7d132dDd5H6K6rq\n",
       "HyMqf6TG2IvX07te4r4k0PvL7/dJTqqqhb5Oc2OeFyT5CL3TMO8aTcUTtc9j28uYI7oxyxex7ywZ\n",
       "tBdPACRZDvwQ+E5V3T7GOidhmF58ADgryZn0Pr/kZUm+VVXnj7HecRmmD6F35mBDt34dvSC23/PU\n",
       "5Hx3ABd0yxcACz04/A5Yk+SoJCuA87r9AJ5Mclq3fDrw0DiLHbNhe3E7vR6Q5BhgxbSGsEUYuBdV\n",
       "dX9Vra6qo6vqaHoPSidOawhbhKHmRZK19E7BnF1Vz0yg3lHb15zf5Q7gfIDuVV/bu9O5i9l3lgzc\n",
       "i/T+KrkJeKCqbpxk0WMyaC+2VNVnq+rI7vHhQ8CvZjSEwRBzoqq2AI91/18AvBv484Tqbqv1qwWm\n",
       "6QasAn5BL0DdCazs1h8G/KRv3Bn0XuXzMHBF3/pT6U3Ee4HfACe0PqaGvVgOfBv4E/B7YK71MbXq\n",
       "xR5f66/M9qsmh50Xm4FHgY3d7autj2mAHjzn2IALgQv7xnyl234fveC96DkyS7dBewG8jd71UPf2\n",
       "zYW1rY+n1bzo234aM/yqyWH7ALwR2NCtv40D5FWTftakJElSI56alCRJasQgJkmS1IhBTJIkqRGD\n",
       "mCRJUiMGMUmSpEYMYpIkSY0YxCRJkhr5H+HGy2iEXcZUAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bbfe470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the word vectors you trained\n",
    "\n",
    "_, wordVectors0, _ = load_saved_params()\n",
    "wordVectors = (wordVectors0[:nWords,:] + wordVectors0[nWords:,:])\n",
    "visualizeWords = [\"the\", \"a\", \"an\", \",\", \".\", \"?\", \"!\", \"``\", \"''\", \"--\", \"good\", \"great\", \"cool\", \"brilliant\", \"wonderful\", \"well\", \"amazing\", \"worth\", \"sweet\", \"enjoyable\", \"boring\", \"bad\", \"waste\", \"dumb\", \"annoying\"]\n",
    "visualizeIdx = [tokens[word] for word in visualizeWords]\n",
    "visualizeVecs = wordVectors[visualizeIdx, :]\n",
    "temp = (visualizeVecs - np.mean(visualizeVecs, axis=0))\n",
    "covariance = 1.0 / len(visualizeIdx) * temp.T.dot(temp)\n",
    "U,S,V = np.linalg.svd(covariance)\n",
    "coord = temp.dot(U[:,0:2]) \n",
    "\n",
    "for i in xrange(len(visualizeWords)):\n",
    "    plt.text(coord[i,0], coord[i,1], visualizeWords[i], bbox=dict(facecolor='green', alpha=0.1))\n",
    "    \n",
    "plt.xlim((np.min(coord[:,0]), np.max(coord[:,0])))\n",
    "plt.ylim((np.min(coord[:,1]), np.max(coord[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "\n",
    "Now, with the word vectors you trained, we are going to perform a simple sentiment analysis.\n",
    "\n",
    "For each sentence in the Stanford Sentiment Treebank dataset, we are going to use the average of all the word vectors in that sentence as its feature, and try to predict the sentiment level of the said sentence. The sentiment level of the phrases are represented as real values in the original dataset, here we'll just use five classes:\n",
    "\n",
    "    \"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"\n",
    "    \n",
    "which are represented by 0 to 4 in the code, respectively.\n",
    "\n",
    "For this part, you will learn to train a softmax regressor with SGD, and perform train/dev validation to improve generalization of your regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malaa: Softmax Regression\n",
    "\n",
    "- Probability: is the softmax \n",
    "$$ P(y_n = k | x_n) = softmax(x_n^T W) = \\frac{\\exp(x_n^T w_k)}{\\sum_l \\exp(x_n^T w_l)} $$ where\n",
    " * $y_n$ is the prediction label for sentence $n$ \n",
    " * $x_n$ is the feature vector for sentence $n$\n",
    " * Weights $W$ has dimension $D \\times L$ where $D$ is the dimensionality of the word vectors and $L$ is the number of classes (labels)\n",
    "  \n",
    "\n",
    "- Unregularized (Cross Entropy) Cost: $$cost = \\frac{1}{N} \\sum_n - \\log P(y_n == k|x_n) = -\\frac{1}{N} \\sum_n \\log \\frac{\\exp(x_n^T w_k)}{\\sum_l \\exp(x_n^T w_l)} = -\\frac{1}{N} \\sum_n \\left( x_n^T w_k +   \\log \\sum_l \\exp(x_n^T w_l) \\right)$$ where\n",
    "\n",
    " * $k=label[n]$ is ground truth label for sentence $n$\n",
    " * $w_l$ is the weight vector for label $l$\n",
    "  \n",
    "  \n",
    "- Gradient of entropy wrt weight $w_k$ for class $k$:\n",
    " $$\\nabla_{w_k} = -\\sum_n 1\\{label[n]=k\\} + \\sum_n \\frac{\\exp(x_n^T w_k)}{\\sum_l \\exp(x_n^T w_l)} x_n = -\\sum_n 1\\{label[n]=k\\} x_n + \\sum_n P(y_n == k) x_n $$\n",
    "  \n",
    "\n",
    "- With $\\ell_2$ regularization, we simply add $w_k$ to the gradient wrt $w_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, implement some helper functions\n",
    "\n",
    "def getSentenceFeature(tokens, wordVectors, sentence):\n",
    "    \"\"\" Obtain the sentence feature for sentiment analysis by averaging its word vectors \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement computation for the sentence features given a         #\n",
    "    # sentence.                                                       #\n",
    "    # Inputs:                                                         #\n",
    "    #   - tokens: a dictionary that maps words to their indices in    #\n",
    "    #             the word vector list                                #\n",
    "    #   - wordVectors: word vectors for all tokens                    #\n",
    "    #   - sentence: a list of words in the sentence of interest       #\n",
    "    # Output:                                                         #\n",
    "    #   - sentVector: feature vector for the sentence                 #\n",
    "    ###################################################################\n",
    "    \n",
    "    sentVector = np.zeros((wordVectors.shape[1],))\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    # get token ids\n",
    "    idx = [tokens[w] for w in sentence]\n",
    "    # sum the feature vectors for these words\n",
    "    sentVector = np.sum(wordVectors[idx,:], axis=0)\n",
    "    # check we have the right dimensions\n",
    "    assert sentVector.shape[0] == wordVectors.shape[1]\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return sentVector\n",
    "\n",
    "def softmaxRegression(features, labels, weights, regularization = 0.0, nopredictions = False):\n",
    "    \"\"\" Softmax Regression \"\"\"\n",
    "    ###################################################################\n",
    "    # Implement softmax regression with weight regularization.        #\n",
    "    # Inputs:                                                         #\n",
    "    #   - features: feature vectors, each row is a feature vector     #\n",
    "    #   - labels: labels corresponding to the feature vectors         #\n",
    "    #   - weights: weights of the regressor                           #\n",
    "    #   - regularization: L2 regularization constant                  #\n",
    "    # Output:                                                         #\n",
    "    #   - cost: cost of the regressor                                 #\n",
    "    #   - grad: gradient of the regressor cost with respect to its    #\n",
    "    #           weights                                               #\n",
    "    #   - pred: label predictions of the regressor (you might find    #\n",
    "    #           np.argmax helpful)                                    #\n",
    "    ###################################################################\n",
    "    \n",
    "    prob = softmax(features.dot(weights))\n",
    "    if len(features.shape) > 1:\n",
    "        N = features.shape[0]\n",
    "    else:\n",
    "        N = 1\n",
    "    # A vectorized implementation of    1/N * sum(cross_entropy(x_i, y_i)) + 1/2*|w|^2\n",
    "    cost = np.sum(-np.log(prob[range(N), labels])) / N \n",
    "    cost += 0.5 * regularization * np.sum(weights ** 2)\n",
    "    \n",
    "    ### YOUR CODE HERE: compute the gradients and predictions\n",
    "    \n",
    "    # Gradient\n",
    "    #\n",
    "    grad = np.zeros_like(weights)\n",
    "    # loop over labels\n",
    "    K = weights.shape[1]\n",
    "    for k in xrange(K):\n",
    "        # add features for sentences with that label\n",
    "        grad[:,k] = -np.sum(features[labels == k,:], axis=0) / N\n",
    "        # add features multiplied by their probabilities for that class k\n",
    "        grad[:,k] += prob[:,k].T.dot(features) / N\n",
    "        # add regularization term\n",
    "        grad[:,k] += regularization * weights[:,k]\n",
    "        \n",
    "    # predictions\n",
    "    #\n",
    "    pred = np.argmax(prob, axis=1)\n",
    "    assert len(pred) == N\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    if nopredictions:\n",
    "        return cost, grad\n",
    "    else:\n",
    "        return cost, grad, pred\n",
    "\n",
    "def precision(y, yhat):\n",
    "    \"\"\" Precision for classifier \"\"\"\n",
    "    assert(y.shape == yhat.shape)\n",
    "    return np.sum(y == yhat) * 100.0 / y.size\n",
    "\n",
    "def softmax_wrapper(features, labels, weights, regularization = 0.0):\n",
    "    cost, grad, _ = softmaxRegression(features, labels, weights, regularization)\n",
    "    return cost, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Gradient check for softmax regression ====\n",
      "Gradient check passed!\n",
      "\n",
      "=== For autograder ===\n",
      "(1.860236526028717, array([[ 0.19681335,  0.02770233,  0.0260005 ,  0.14181608,  0.03890777],\n",
      "       [-0.08949778, -0.07034781,  0.01266276,  0.08383501,  0.00127673],\n",
      "       [ 0.03769924, -0.04649311, -0.02012287, -0.02272177, -0.0672628 ],\n",
      "       [ 0.02570717,  0.22870052,  0.04034267, -0.07099323,  0.00735295],\n",
      "       [ 0.01712713,  0.03824675,  0.02584286,  0.01329124, -0.16151958],\n",
      "       [ 0.06809465, -0.01820912,  0.22861521,  0.12082694,  0.07826769],\n",
      "       [-0.14327708, -0.16284651, -0.26175963, -0.10714052,  0.07148386],\n",
      "       [ 0.0392178 ,  0.03687071,  0.00357005,  0.12103097, -0.07178527],\n",
      "       [-0.15368542,  0.18513118,  0.02419089,  0.08195616, -0.02956875],\n",
      "       [-0.04176299,  0.00442014,  0.11458221, -0.09046411,  0.10922473]]), array([4, 3, 0, 3, 4, 2, 2, 3, 3, 1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Gradient check always comes first\n",
    "random.seed(314159)\n",
    "np.random.seed(265)\n",
    "dummy_weights = 0.1 * np.random.randn(dimVectors, 5)\n",
    "dummy_features = np.zeros((10, dimVectors))\n",
    "dummy_labels = np.zeros((10,), dtype=np.int32)    \n",
    "for i in xrange(10):\n",
    "    words, dummy_labels[i] = dataset.getRandomTrainSentence()\n",
    "    dummy_features[i, :] = getSentenceFeature(tokens, wordVectors, words)\n",
    "print \"==== Gradient check for softmax regression ====\"\n",
    "gradcheck_naive(lambda weights: softmaxRegression(dummy_features, dummy_labels, weights, 1.0, nopredictions = True), dummy_weights)\n",
    "\n",
    "print \"\\n=== For autograder ===\"\n",
    "print softmaxRegression(dummy_features, dummy_labels, dummy_weights, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 - cost=1.591031\n",
      "Iteration 2000 - cost=1.585071\n",
      "Iteration 3000 - cost=1.583996\n",
      "Iteration 4000 - cost=1.583769\n",
      "Iteration 5000 - cost=1.583716\n",
      "Iteration 6000 - cost=1.583703\n",
      "Iteration 7000 - cost=1.583699\n",
      "Iteration 8000 - cost=1.583698\n",
      "Iteration 9000 - cost=1.583698\n",
      "Iteration 10000 - cost=1.583698\n",
      "Iteration 11000 - cost=1.583698\n",
      "Iteration 12000 - cost=1.583698\n",
      "Iteration 13000 - cost=1.583698\n",
      "Iteration 14000 - cost=1.583698\n",
      "Iteration 15000 - cost=1.583698\n",
      "Iteration 16000 - cost=1.583698\n",
      "Iteration 17000 - cost=1.583698\n",
      "Iteration 18000 - cost=1.583698\n",
      "Iteration 19000 - cost=1.583698\n",
      "Iteration 20000 - cost=1.583698\n",
      "Iteration 21000 - cost=1.583698\n",
      "Iteration 22000 - cost=1.583698\n",
      "Iteration 23000 - cost=1.583698\n",
      "Iteration 24000 - cost=1.583698\n",
      "Iteration 25000 - cost=1.583698\n",
      "Iteration 26000 - cost=1.583698\n",
      "Iteration 27000 - cost=1.583698\n",
      "Iteration 28000 - cost=1.583698\n",
      "Iteration 29000 - cost=1.583698\n",
      "Iteration 30000 - cost=1.583698\n",
      "Iteration 31000 - cost=1.583698\n",
      "Iteration 32000 - cost=1.583698\n",
      "Iteration 33000 - cost=1.583698\n",
      "Iteration 34000 - cost=1.583698\n",
      "Iteration 35000 - cost=1.583698\n",
      "Iteration 36000 - cost=1.583698\n",
      "Iteration 37000 - cost=1.583698\n",
      "Iteration 38000 - cost=1.583698\n",
      "Iteration 39000 - cost=1.583698\n",
      "Iteration 40000 - cost=1.583698\n",
      "Reg: 0.000000 and Dev precision (%): 25.068120\n",
      "Iteration 1000 - cost=1.591104\n",
      "Iteration 2000 - cost=1.585151\n",
      "Iteration 3000 - cost=1.584083\n",
      "Iteration 4000 - cost=1.583858\n",
      "Iteration 5000 - cost=1.583806\n",
      "Iteration 6000 - cost=1.583793\n",
      "Iteration 7000 - cost=1.583789\n",
      "Iteration 8000 - cost=1.583788\n",
      "Iteration 9000 - cost=1.583787\n",
      "Iteration 10000 - cost=1.583787\n",
      "Iteration 11000 - cost=1.583787\n",
      "Iteration 12000 - cost=1.583786\n",
      "Iteration 13000 - cost=1.583786\n",
      "Iteration 14000 - cost=1.583786\n",
      "Iteration 15000 - cost=1.583785\n",
      "Iteration 16000 - cost=1.583785\n",
      "Iteration 17000 - cost=1.583785\n",
      "Iteration 18000 - cost=1.583785\n",
      "Iteration 19000 - cost=1.583784\n",
      "Iteration 20000 - cost=1.583784\n",
      "Iteration 21000 - cost=1.583784\n",
      "Iteration 22000 - cost=1.583784\n",
      "Iteration 23000 - cost=1.583784\n",
      "Iteration 24000 - cost=1.583783\n",
      "Iteration 25000 - cost=1.583783\n",
      "Iteration 26000 - cost=1.583783\n",
      "Iteration 27000 - cost=1.583783\n",
      "Iteration 28000 - cost=1.583783\n",
      "Iteration 29000 - cost=1.583783\n",
      "Iteration 30000 - cost=1.583783\n",
      "Iteration 31000 - cost=1.583783\n",
      "Iteration 32000 - cost=1.583782\n",
      "Iteration 33000 - cost=1.583782\n",
      "Iteration 34000 - cost=1.583782\n",
      "Iteration 35000 - cost=1.583782\n",
      "Iteration 36000 - cost=1.583782\n",
      "Iteration 37000 - cost=1.583782\n",
      "Iteration 38000 - cost=1.583782\n",
      "Iteration 39000 - cost=1.583781\n",
      "Iteration 40000 - cost=1.583781\n",
      "Reg: 0.000010 and Dev precision (%): 24.977293\n",
      "Iteration 1000 - cost=1.591247\n",
      "Iteration 2000 - cost=1.585306\n",
      "Iteration 3000 - cost=1.584251\n",
      "Iteration 4000 - cost=1.584029\n",
      "Iteration 5000 - cost=1.583976\n",
      "Iteration 6000 - cost=1.583961\n",
      "Iteration 7000 - cost=1.583956\n",
      "Iteration 8000 - cost=1.583952\n",
      "Iteration 9000 - cost=1.583950\n",
      "Iteration 10000 - cost=1.583947\n",
      "Iteration 11000 - cost=1.583945\n",
      "Iteration 12000 - cost=1.583943\n",
      "Iteration 13000 - cost=1.583941\n",
      "Iteration 14000 - cost=1.583938\n",
      "Iteration 15000 - cost=1.583936\n",
      "Iteration 16000 - cost=1.583934\n",
      "Iteration 17000 - cost=1.583932\n",
      "Iteration 18000 - cost=1.583930\n",
      "Iteration 19000 - cost=1.583928\n",
      "Iteration 20000 - cost=1.583926\n",
      "Iteration 21000 - cost=1.583925\n",
      "Iteration 22000 - cost=1.583924\n",
      "Iteration 23000 - cost=1.583923\n",
      "Iteration 24000 - cost=1.583922\n",
      "Iteration 25000 - cost=1.583921\n",
      "Iteration 26000 - cost=1.583920\n",
      "Iteration 27000 - cost=1.583920\n",
      "Iteration 28000 - cost=1.583919\n",
      "Iteration 29000 - cost=1.583918\n",
      "Iteration 30000 - cost=1.583917\n",
      "Iteration 31000 - cost=1.583916\n",
      "Iteration 32000 - cost=1.583915\n",
      "Iteration 33000 - cost=1.583914\n",
      "Iteration 34000 - cost=1.583913\n",
      "Iteration 35000 - cost=1.583913\n",
      "Iteration 36000 - cost=1.583912\n",
      "Iteration 37000 - cost=1.583911\n",
      "Iteration 38000 - cost=1.583910\n",
      "Iteration 39000 - cost=1.583909\n",
      "Iteration 40000 - cost=1.583908\n",
      "Reg: 0.000030 and Dev precision (%): 24.886467\n",
      "Iteration 1000 - cost=1.591724\n",
      "Iteration 2000 - cost=1.585812\n",
      "Iteration 3000 - cost=1.584782\n",
      "Iteration 4000 - cost=1.584556\n",
      "Iteration 5000 - cost=1.584488\n",
      "Iteration 6000 - cost=1.584456\n",
      "Iteration 7000 - cost=1.584432\n",
      "Iteration 8000 - cost=1.584412\n",
      "Iteration 9000 - cost=1.584393\n",
      "Iteration 10000 - cost=1.584375\n",
      "Iteration 11000 - cost=1.584359\n",
      "Iteration 12000 - cost=1.584343\n",
      "Iteration 13000 - cost=1.584329\n",
      "Iteration 14000 - cost=1.584315\n",
      "Iteration 15000 - cost=1.584302\n",
      "Iteration 16000 - cost=1.584290\n",
      "Iteration 17000 - cost=1.584278\n",
      "Iteration 18000 - cost=1.584268\n",
      "Iteration 19000 - cost=1.584257\n",
      "Iteration 20000 - cost=1.584248\n",
      "Iteration 21000 - cost=1.584243\n",
      "Iteration 22000 - cost=1.584239\n",
      "Iteration 23000 - cost=1.584234\n",
      "Iteration 24000 - cost=1.584230\n",
      "Iteration 25000 - cost=1.584226\n",
      "Iteration 26000 - cost=1.584222\n",
      "Iteration 27000 - cost=1.584218\n",
      "Iteration 28000 - cost=1.584215\n",
      "Iteration 29000 - cost=1.584211\n",
      "Iteration 30000 - cost=1.584208\n",
      "Iteration 31000 - cost=1.584204\n",
      "Iteration 32000 - cost=1.584201\n",
      "Iteration 33000 - cost=1.584198\n",
      "Iteration 34000 - cost=1.584195\n",
      "Iteration 35000 - cost=1.584192\n",
      "Iteration 36000 - cost=1.584189\n",
      "Iteration 37000 - cost=1.584186\n",
      "Iteration 38000 - cost=1.584183\n",
      "Iteration 39000 - cost=1.584180\n",
      "Iteration 40000 - cost=1.584178\n",
      "Reg: 0.000100 and Dev precision (%): 24.886467\n",
      "Iteration 1000 - cost=1.592893\n",
      "Iteration 2000 - cost=1.586977\n",
      "Iteration 3000 - cost=1.585929\n",
      "Iteration 4000 - cost=1.585625\n",
      "Iteration 5000 - cost=1.585470\n",
      "Iteration 6000 - cost=1.585360\n",
      "Iteration 7000 - cost=1.585272\n",
      "Iteration 8000 - cost=1.585200\n",
      "Iteration 9000 - cost=1.585139\n",
      "Iteration 10000 - cost=1.585089\n",
      "Iteration 11000 - cost=1.585047\n",
      "Iteration 12000 - cost=1.585011\n",
      "Iteration 13000 - cost=1.584982\n",
      "Iteration 14000 - cost=1.584958\n",
      "Iteration 15000 - cost=1.584937\n",
      "Iteration 16000 - cost=1.584920\n",
      "Iteration 17000 - cost=1.584906\n",
      "Iteration 18000 - cost=1.584894\n",
      "Iteration 19000 - cost=1.584884\n",
      "Iteration 20000 - cost=1.584875\n",
      "Iteration 21000 - cost=1.584872\n",
      "Iteration 22000 - cost=1.584868\n",
      "Iteration 23000 - cost=1.584865\n",
      "Iteration 24000 - cost=1.584863\n",
      "Iteration 25000 - cost=1.584860\n",
      "Iteration 26000 - cost=1.584858\n",
      "Iteration 27000 - cost=1.584856\n",
      "Iteration 28000 - cost=1.584854\n",
      "Iteration 29000 - cost=1.584852\n",
      "Iteration 30000 - cost=1.584850\n",
      "Iteration 31000 - cost=1.584849\n",
      "Iteration 32000 - cost=1.584848\n",
      "Iteration 33000 - cost=1.584846\n",
      "Iteration 34000 - cost=1.584845\n",
      "Iteration 35000 - cost=1.584844\n",
      "Iteration 36000 - cost=1.584843\n",
      "Iteration 37000 - cost=1.584842\n",
      "Iteration 38000 - cost=1.584842\n",
      "Iteration 39000 - cost=1.584841\n",
      "Iteration 40000 - cost=1.584840\n",
      "Reg: 0.000300 and Dev precision (%): 25.068120\n",
      "Iteration 1000 - cost=1.595320\n",
      "Iteration 2000 - cost=1.589154\n",
      "Iteration 3000 - cost=1.587953\n",
      "Iteration 4000 - cost=1.587508\n",
      "Iteration 5000 - cost=1.587289\n",
      "Iteration 6000 - cost=1.587172\n",
      "Iteration 7000 - cost=1.587109\n",
      "Iteration 8000 - cost=1.587074\n",
      "Iteration 9000 - cost=1.587055\n",
      "Iteration 10000 - cost=1.587044\n",
      "Iteration 11000 - cost=1.587038\n",
      "Iteration 12000 - cost=1.587035\n",
      "Iteration 13000 - cost=1.587033\n",
      "Iteration 14000 - cost=1.587032\n",
      "Iteration 15000 - cost=1.587032\n",
      "Iteration 16000 - cost=1.587032\n",
      "Iteration 17000 - cost=1.587031\n",
      "Iteration 18000 - cost=1.587031\n",
      "Iteration 19000 - cost=1.587031\n",
      "Iteration 20000 - cost=1.587031\n",
      "Iteration 21000 - cost=1.587031\n",
      "Iteration 22000 - cost=1.587031\n",
      "Iteration 23000 - cost=1.587031\n",
      "Iteration 24000 - cost=1.587031\n",
      "Iteration 25000 - cost=1.587031\n",
      "Iteration 26000 - cost=1.587031\n",
      "Iteration 27000 - cost=1.587031\n",
      "Iteration 28000 - cost=1.587031\n",
      "Iteration 29000 - cost=1.587031\n",
      "Iteration 30000 - cost=1.587031\n",
      "Iteration 31000 - cost=1.587031\n",
      "Iteration 32000 - cost=1.587031\n",
      "Iteration 33000 - cost=1.587031\n",
      "Iteration 34000 - cost=1.587031\n",
      "Iteration 35000 - cost=1.587031\n",
      "Iteration 36000 - cost=1.587031\n",
      "Iteration 37000 - cost=1.587031\n",
      "Iteration 38000 - cost=1.587031\n",
      "Iteration 39000 - cost=1.587031\n",
      "Iteration 40000 - cost=1.587031\n",
      "Reg: 0.001000 and Dev precision (%): 25.703906\n",
      "Iteration 1000 - cost=1.596440\n",
      "Iteration 2000 - cost=1.591848\n",
      "Iteration 3000 - cost=1.591417\n",
      "Iteration 4000 - cost=1.591356\n",
      "Iteration 5000 - cost=1.591346\n",
      "Iteration 6000 - cost=1.591345\n",
      "Iteration 7000 - cost=1.591345\n",
      "Iteration 8000 - cost=1.591345\n",
      "Iteration 9000 - cost=1.591344\n",
      "Iteration 10000 - cost=1.591344\n",
      "Iteration 11000 - cost=1.591344\n",
      "Iteration 12000 - cost=1.591344\n",
      "Iteration 13000 - cost=1.591344\n",
      "Iteration 14000 - cost=1.591344\n",
      "Iteration 15000 - cost=1.591344\n",
      "Iteration 16000 - cost=1.591344\n",
      "Iteration 17000 - cost=1.591344\n",
      "Iteration 18000 - cost=1.591344\n",
      "Iteration 19000 - cost=1.591344\n",
      "Iteration 20000 - cost=1.591344\n",
      "Iteration 21000 - cost=1.591344\n",
      "Iteration 22000 - cost=1.591344\n",
      "Iteration 23000 - cost=1.591344\n",
      "Iteration 24000 - cost=1.591344\n",
      "Iteration 25000 - cost=1.591344\n",
      "Iteration 26000 - cost=1.591344\n",
      "Iteration 27000 - cost=1.591344\n",
      "Iteration 28000 - cost=1.591344\n",
      "Iteration 29000 - cost=1.591344\n",
      "Iteration 30000 - cost=1.591344\n",
      "Iteration 31000 - cost=1.591344\n",
      "Iteration 32000 - cost=1.591344\n",
      "Iteration 33000 - cost=1.591344\n",
      "Iteration 34000 - cost=1.591344\n",
      "Iteration 35000 - cost=1.591344\n",
      "Iteration 36000 - cost=1.591344\n",
      "Iteration 37000 - cost=1.591344\n",
      "Iteration 38000 - cost=1.591344\n",
      "Iteration 39000 - cost=1.591344\n",
      "Iteration 40000 - cost=1.591344\n",
      "Reg: 0.003000 and Dev precision (%): 26.067212\n",
      "Iteration 1000 - cost=1.598558\n",
      "Iteration 2000 - cost=1.598346\n",
      "Iteration 3000 - cost=1.598346\n",
      "Iteration 4000 - cost=1.598346\n",
      "Iteration 5000 - cost=1.598346\n",
      "Iteration 6000 - cost=1.598346\n",
      "Iteration 7000 - cost=1.598346\n",
      "Iteration 8000 - cost=1.598346\n",
      "Iteration 9000 - cost=1.598346\n",
      "Iteration 10000 - cost=1.598346\n",
      "Iteration 11000 - cost=1.598346\n",
      "Iteration 12000 - cost=1.598346\n",
      "Iteration 13000 - cost=1.598346\n",
      "Iteration 14000 - cost=1.598346\n",
      "Iteration 15000 - cost=1.598346\n",
      "Iteration 16000 - cost=1.598346\n",
      "Iteration 17000 - cost=1.598346\n",
      "Iteration 18000 - cost=1.598346\n",
      "Iteration 19000 - cost=1.598346\n",
      "Iteration 20000 - cost=1.598346\n",
      "Iteration 21000 - cost=1.598346\n",
      "Iteration 22000 - cost=1.598346\n",
      "Iteration 23000 - cost=1.598346\n",
      "Iteration 24000 - cost=1.598346\n",
      "Iteration 25000 - cost=1.598346\n",
      "Iteration 26000 - cost=1.598346\n",
      "Iteration 27000 - cost=1.598346\n",
      "Iteration 28000 - cost=1.598346\n",
      "Iteration 29000 - cost=1.598346\n",
      "Iteration 30000 - cost=1.598346\n",
      "Iteration 31000 - cost=1.598346\n",
      "Iteration 32000 - cost=1.598346\n",
      "Iteration 33000 - cost=1.598346\n",
      "Iteration 34000 - cost=1.598346\n",
      "Iteration 35000 - cost=1.598346\n",
      "Iteration 36000 - cost=1.598346\n",
      "Iteration 37000 - cost=1.598346\n",
      "Iteration 38000 - cost=1.598346\n",
      "Iteration 39000 - cost=1.598346\n",
      "Iteration 40000 - cost=1.598346\n",
      "Reg: 0.010000 and Dev precision (%): 25.431426\n",
      "Iteration 1000 - cost=1.604101\n",
      "Iteration 2000 - cost=1.604101\n",
      "Iteration 3000 - cost=1.604101\n",
      "Iteration 4000 - cost=1.604101\n",
      "Iteration 5000 - cost=1.604101\n",
      "Iteration 6000 - cost=1.604101\n",
      "Iteration 7000 - cost=1.604101\n",
      "Iteration 8000 - cost=1.604101\n",
      "Iteration 9000 - cost=1.604101\n",
      "Iteration 10000 - cost=1.604101\n",
      "Iteration 11000 - cost=1.604101\n",
      "Iteration 12000 - cost=1.604101\n",
      "Iteration 13000 - cost=1.604101\n",
      "Iteration 14000 - cost=1.604101\n",
      "Iteration 15000 - cost=1.604101\n",
      "Iteration 16000 - cost=1.604101\n",
      "Iteration 17000 - cost=1.604101\n",
      "Iteration 18000 - cost=1.604101\n",
      "Iteration 19000 - cost=1.604101\n",
      "Iteration 20000 - cost=1.604101\n",
      "Iteration 21000 - cost=1.604101\n",
      "Iteration 22000 - cost=1.604101\n",
      "Iteration 23000 - cost=1.604101\n",
      "Iteration 24000 - cost=1.604101\n",
      "Iteration 25000 - cost=1.604101\n",
      "Iteration 26000 - cost=1.604101\n",
      "Iteration 27000 - cost=1.604101\n",
      "Iteration 28000 - cost=1.604101\n",
      "Iteration 29000 - cost=1.604101\n",
      "Iteration 30000 - cost=1.604101\n",
      "Iteration 31000 - cost=1.604101\n",
      "Iteration 32000 - cost=1.604101\n",
      "Iteration 33000 - cost=1.604101\n",
      "Iteration 34000 - cost=1.604101\n",
      "Iteration 35000 - cost=1.604101\n",
      "Iteration 36000 - cost=1.604101\n",
      "Iteration 37000 - cost=1.604101\n",
      "Iteration 38000 - cost=1.604101\n",
      "Iteration 39000 - cost=1.604101\n",
      "Iteration 40000 - cost=1.604101\n",
      "Reg: 0.030000 and Dev precision (%): 25.158946\n",
      "Reg: 0.000000 -> Prec: 25.068120\n",
      "Reg: 0.000300 -> Prec: 25.068120\n",
      "Reg: 0.000010 -> Prec: 24.977293\n",
      "Reg: 0.001000 -> Prec: 25.703906\n",
      "Reg: 0.000100 -> Prec: 24.886467\n",
      "Reg: 0.030000 -> Prec: 25.158946\n",
      "Reg: 0.003000 -> Prec: 26.067212\n",
      "Reg: 0.000030 -> Prec: 24.886467\n",
      "Reg: 0.010000 -> Prec: 25.431426\n"
     ]
    }
   ],
   "source": [
    "# Try different regularizations and pick the best!\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "#regularization = 0.0 # try 0.0, 0.00001, 0.00003, 0.0001, 0.0003, 0.001, 0.003, 0.01 and pick the best\n",
    "precisions = dict()    \n",
    "for regularization in [0, .00001, .00003, .0001, .0003, .001, .003, .01, .03]:\n",
    "### END YOUR CODE\n",
    "\n",
    "    random.seed(3141)\n",
    "    np.random.seed(59265)\n",
    "    weights = np.random.randn(dimVectors, 5)\n",
    "    \n",
    "    trainset = dataset.getTrainSentences()\n",
    "    nTrain = len(trainset)\n",
    "    trainFeatures = np.zeros((nTrain, dimVectors))\n",
    "    trainLabels = np.zeros((nTrain,), dtype=np.int32)\n",
    "    \n",
    "    for i in xrange(nTrain):\n",
    "        words, trainLabels[i] = trainset[i]\n",
    "        trainFeatures[i, :] = getSentenceFeature(tokens, wordVectors, words)\n",
    "        \n",
    "    # We will do batch optimization\n",
    "    weights = sgd(lambda weights: softmax_wrapper(trainFeatures, trainLabels, weights, regularization), weights, 0.3, 40000, PRINT_EVERY=1000)\n",
    "    \n",
    "    # Prepare dev set features\n",
    "    devset = dataset.getDevSentences()\n",
    "    nDev = len(devset)\n",
    "    devFeatures = np.zeros((nDev, dimVectors))\n",
    "    devLabels = np.zeros((nDev,), dtype=np.int32)\n",
    "    \n",
    "    for i in xrange(nDev):\n",
    "        words, devLabels[i] = devset[i]\n",
    "        devFeatures[i, :] = getSentenceFeature(tokens, wordVectors, words)\n",
    "        \n",
    "    _, _, pred = softmaxRegression(devFeatures, devLabels, weights)\n",
    "    print \"Reg: %f and Dev precision (%%): %f\" % (regularization, precision(devLabels, pred))\n",
    "    precisions[regularization] = precision(devLabels, pred)\n",
    "    \n",
    "for (k,v) in precisions.iteritems():\n",
    "    print \"Reg: %f -> Prec: %f\" % (k,v)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write down the best regularization and accuracy you found\n",
    "# sanity check: your accuracy should be around or above 30%\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "BEST_REGULARIZATION = 1\n",
    "BEST_ACCURACY = 0.0\n",
    "\n",
    "### END YOUR CODE\n",
    "\n",
    "print \"=== For autograder ===\\n%g\\t%g\" % (BEST_REGULARIZATION, BEST_ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For autograder ===\n",
      "Test precision (%): 23.031674\n"
     ]
    }
   ],
   "source": [
    "# Test your findings on the test set\n",
    "\n",
    "testset = dataset.getTestSentences()\n",
    "nTest = len(testset)\n",
    "testFeatures = np.zeros((nTest, dimVectors))\n",
    "testLabels = np.zeros((nTest,), dtype=np.int32)\n",
    "\n",
    "for i in xrange(nTest):\n",
    "    words, testLabels[i] = testset[i]\n",
    "    testFeatures[i, :] = getSentenceFeature(tokens, wordVectors, words)\n",
    "    \n",
    "_, _, pred = softmaxRegression(testFeatures, testLabels, weights)\n",
    "print \"=== For autograder ===\\nTest precision (%%): %f\" % precision(testLabels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Credit\n",
    "\n",
    "Train your own classifier for sentiment analysis! We will not provide any starter code for this part, but you can feel free to reuse the code you've written before, or write some new code for this task. Also feel free to refer to the code we provided you with to see how we scaffolded training for you.\n",
    "\n",
    "Try to contain all of your code in one code block. You could start by using multiple blocks, then paste code together and remove unnecessary blocks. Report, as the last two lines of the output of your block, the dev set accuracy and test set accuracy you achieved, in the format we used above.\n",
    "\n",
    "*Note: no credits will be given for this part if you use the dev or test sets for training, or if you fine-tune your regularization or other hyperparameters on the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "### END YOU CODE\n",
    "\n",
    "\n",
    "_, _, pred = softmaxRegression(devFeatures, devLabels, weights)\n",
    "print \"=== For autograder ===\\nDev precision (%%): %f\" % precision(devLabels, pred)\n",
    "_, _, pred = softmaxRegression(testFeatures, testLabels, weights)\n",
    "print \"Test precision (%%): %f\" % precision(testLabels, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
